{"version":3,"file":"296.bundle.js","mappings":";;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA","sources":["./node_modules/@remotion/media-parser/dist/esm/worker-web-entry.mjs"],"sourcesContent":["// src/errors.ts\nclass IsAnImageError extends Error {\n  imageType;\n  dimensions;\n  mimeType;\n  sizeInBytes;\n  fileName;\n  constructor({\n    dimensions,\n    imageType,\n    message,\n    mimeType,\n    sizeInBytes,\n    fileName\n  }) {\n    super(message);\n    this.name = \"IsAnImageError\";\n    this.imageType = imageType;\n    this.dimensions = dimensions;\n    this.mimeType = mimeType;\n    this.sizeInBytes = sizeInBytes;\n    this.fileName = fileName;\n    if (Error.captureStackTrace) {\n      Error.captureStackTrace(this, IsAnImageError);\n    }\n  }\n}\n\nclass IsAPdfError extends Error {\n  mimeType;\n  sizeInBytes;\n  fileName;\n  constructor({\n    message,\n    mimeType,\n    sizeInBytes,\n    fileName\n  }) {\n    super(message);\n    this.name = \"IsAPdfError\";\n    this.mimeType = mimeType;\n    this.sizeInBytes = sizeInBytes;\n    this.fileName = fileName;\n    if (Error.captureStackTrace) {\n      Error.captureStackTrace(this, IsAPdfError);\n    }\n  }\n}\n\nclass IsAnUnsupportedFileTypeError extends Error {\n  mimeType;\n  sizeInBytes;\n  fileName;\n  constructor({\n    message,\n    mimeType,\n    sizeInBytes,\n    fileName\n  }) {\n    super(message);\n    this.name = \"IsAnUnsupportedFileTypeError\";\n    this.mimeType = mimeType;\n    this.sizeInBytes = sizeInBytes;\n    this.fileName = fileName;\n    if (Error.captureStackTrace) {\n      Error.captureStackTrace(this, IsAnUnsupportedFileTypeError);\n    }\n  }\n}\n\nclass MediaParserAbortError extends Error {\n  constructor(message) {\n    super(message);\n    this.name = \"MediaParserAbortError\";\n    this.cause = undefined;\n  }\n}\n\n// src/log.ts\nvar logLevels = [\"trace\", \"verbose\", \"info\", \"warn\", \"error\"];\nvar getNumberForLogLevel = (level) => {\n  return logLevels.indexOf(level);\n};\nvar isEqualOrBelowLogLevel = (currentLevel, level) => {\n  return getNumberForLogLevel(currentLevel) <= getNumberForLogLevel(level);\n};\nvar Log = {\n  trace: (logLevel, ...args) => {\n    if (isEqualOrBelowLogLevel(logLevel, \"trace\")) {\n      return console.log(...args);\n    }\n  },\n  verbose: (logLevel, ...args) => {\n    if (isEqualOrBelowLogLevel(logLevel, \"verbose\")) {\n      return console.log(...args);\n    }\n  },\n  info: (logLevel, ...args) => {\n    if (isEqualOrBelowLogLevel(logLevel, \"info\")) {\n      return console.log(...args);\n    }\n  },\n  warn: (logLevel, ...args) => {\n    if (isEqualOrBelowLogLevel(logLevel, \"warn\")) {\n      return console.warn(...args);\n    }\n  },\n  error: (...args) => {\n    return console.error(...args);\n  }\n};\n\n// src/readers/fetch/get-body-and-reader.ts\nvar getLengthAndReader = async ({\n  canLiveWithoutContentLength,\n  res,\n  ownController,\n  requestedWithoutRange\n}) => {\n  const length = res.headers.get(\"content-length\");\n  const contentLength = length === null ? null : parseInt(length, 10);\n  if (requestedWithoutRange || canLiveWithoutContentLength && contentLength === null) {\n    const buffer = await res.arrayBuffer();\n    const encoded = new Uint8Array(buffer);\n    let streamCancelled = false;\n    const stream = new ReadableStream({\n      start(controller) {\n        if (ownController.signal.aborted) {\n          return;\n        }\n        if (streamCancelled) {\n          return;\n        }\n        try {\n          controller.enqueue(encoded);\n          controller.close();\n        } catch {}\n      },\n      cancel() {\n        streamCancelled = true;\n      }\n    });\n    return {\n      contentLength: encoded.byteLength,\n      reader: {\n        reader: stream.getReader(),\n        abort: () => {\n          ownController.abort();\n          return Promise.resolve();\n        }\n      },\n      needsContentRange: false\n    };\n  }\n  if (!res.body) {\n    throw new Error(\"No body\");\n  }\n  const reader = res.body.getReader();\n  return {\n    reader: {\n      reader,\n      abort: () => {\n        ownController.abort();\n        return Promise.resolve();\n      }\n    },\n    contentLength,\n    needsContentRange: true\n  };\n};\n\n// src/readers/fetch/resolve-url.ts\nvar resolveUrl = (src) => {\n  try {\n    const resolvedUrl = typeof window !== \"undefined\" && typeof window.location !== \"undefined\" ? new URL(src, window.location.origin) : new URL(src);\n    return resolvedUrl;\n  } catch {\n    return src;\n  }\n};\n\n// src/readers/from-fetch.ts\nfunction parseContentRange(input) {\n  const matches = input.match(/^(\\w+) ((\\d+)-(\\d+)|\\*)\\/(\\d+|\\*)$/);\n  if (!matches)\n    return null;\n  const [, unit, , start, end, size] = matches;\n  const range = {\n    unit,\n    start: start != null ? Number(start) : null,\n    end: end != null ? Number(end) : null,\n    size: size === \"*\" ? null : Number(size)\n  };\n  if (range.start === null && range.end === null && range.size === null) {\n    return null;\n  }\n  return range;\n}\nvar validateContentRangeAndDetectIfSupported = ({\n  requestedRange,\n  parsedContentRange,\n  statusCode\n}) => {\n  if (statusCode === 206) {\n    return { supportsContentRange: true };\n  }\n  if (typeof requestedRange === \"number\" && parsedContentRange?.start !== requestedRange) {\n    if (requestedRange === 0) {\n      return { supportsContentRange: false };\n    }\n    throw new Error(`Range header (${requestedRange}) does not match content-range header (${parsedContentRange?.start})`);\n  }\n  if (requestedRange !== null && typeof requestedRange !== \"number\" && (parsedContentRange?.start !== requestedRange[0] || parsedContentRange?.end !== requestedRange[1])) {\n    throw new Error(`Range header (${requestedRange}) does not match content-range header (${parsedContentRange?.start})`);\n  }\n  return { supportsContentRange: true };\n};\nvar makeFetchRequest = async ({\n  range,\n  src,\n  controller\n}) => {\n  const resolvedUrl = resolveUrl(src);\n  const resolvedUrlString = resolvedUrl.toString();\n  if (!resolvedUrlString.startsWith(\"https://\") && !resolvedUrlString.startsWith(\"blob:\") && !resolvedUrlString.startsWith(\"http://\")) {\n    return Promise.reject(new Error(`${resolvedUrlString} is not a URL - needs to start with http:// or https:// or blob:. If you want to read a local file, pass \\`reader: nodeReader\\` to parseMedia().`));\n  }\n  const ownController = new AbortController;\n  const cache = typeof navigator !== \"undefined\" && navigator.userAgent.includes(\"Cloudflare-Workers\") ? undefined : \"no-store\";\n  const requestedRange = range === null ? 0 : range;\n  const asString = typeof resolvedUrl === \"string\" ? resolvedUrl : resolvedUrl.pathname;\n  const requestWithoutRange = asString.endsWith(\".m3u8\");\n  const canLiveWithoutContentLength = asString.endsWith(\".m3u8\") || asString.endsWith(\".ts\");\n  const headers = requestedRange === 0 && requestWithoutRange ? {} : typeof requestedRange === \"number\" ? {\n    Range: `bytes=${requestedRange}-`\n  } : {\n    Range: `bytes=${`${requestedRange[0]}-${requestedRange[1]}`}`\n  };\n  const res = await fetch(resolvedUrl, {\n    headers,\n    signal: ownController.signal,\n    cache\n  });\n  const contentRange = res.headers.get(\"content-range\");\n  const parsedContentRange = contentRange ? parseContentRange(contentRange) : null;\n  if (!res.ok) {\n    throw new Error(`Server returned status code ${res.status} for ${resolvedUrl} and range ${requestedRange}`);\n  }\n  const { supportsContentRange } = validateContentRangeAndDetectIfSupported({\n    requestedRange,\n    parsedContentRange,\n    statusCode: res.status\n  });\n  if (controller) {\n    controller._internals.signal.addEventListener(\"abort\", () => {\n      ownController.abort(new MediaParserAbortError(\"Aborted by user\"));\n    }, { once: true });\n  }\n  const contentDisposition = res.headers.get(\"content-disposition\");\n  const name = contentDisposition?.match(/filename=\"([^\"]+)\"/)?.[1];\n  const { contentLength, needsContentRange, reader } = await getLengthAndReader({\n    canLiveWithoutContentLength,\n    res,\n    ownController,\n    requestedWithoutRange: requestWithoutRange\n  });\n  const contentType = res.headers.get(\"content-type\");\n  return {\n    contentLength,\n    needsContentRange,\n    reader,\n    name,\n    contentType,\n    supportsContentRange\n  };\n};\nvar cacheKey = ({\n  src,\n  range\n}) => {\n  return `${src}-${JSON.stringify(range)}`;\n};\nvar makeFetchRequestOrGetCached = ({\n  range,\n  src,\n  controller,\n  logLevel,\n  prefetchCache\n}) => {\n  const key = cacheKey({ src, range });\n  const cached = prefetchCache.get(key);\n  if (cached) {\n    Log.verbose(logLevel, `Reading from preload cache for ${key}`);\n    return cached;\n  }\n  Log.verbose(logLevel, `Fetching ${key}`);\n  const result = makeFetchRequest({ range, src, controller });\n  prefetchCache.set(key, result);\n  return result;\n};\nvar fetchReadContent = async ({\n  src,\n  range,\n  controller,\n  logLevel,\n  prefetchCache\n}) => {\n  if (typeof src !== \"string\" && src instanceof URL === false) {\n    throw new Error(\"src must be a string when using `fetchReader`\");\n  }\n  const fallbackName = src.toString().split(\"/\").pop();\n  const res = makeFetchRequestOrGetCached({\n    range,\n    src,\n    controller,\n    logLevel,\n    prefetchCache\n  });\n  const key = cacheKey({ src, range });\n  prefetchCache.delete(key);\n  const {\n    reader,\n    contentLength,\n    needsContentRange,\n    name,\n    supportsContentRange,\n    contentType\n  } = await res;\n  if (controller) {\n    controller._internals.signal.addEventListener(\"abort\", () => {\n      reader.reader.cancel().catch(() => {});\n    }, { once: true });\n  }\n  return {\n    reader,\n    contentLength,\n    contentType,\n    name: name ?? fallbackName,\n    supportsContentRange,\n    needsContentRange\n  };\n};\nvar fetchPreload = ({\n  src,\n  range,\n  logLevel,\n  prefetchCache\n}) => {\n  if (typeof src !== \"string\" && src instanceof URL === false) {\n    throw new Error(\"src must be a string when using `fetchReader`\");\n  }\n  const key = cacheKey({ src, range });\n  if (prefetchCache.has(key)) {\n    return prefetchCache.get(key);\n  }\n  makeFetchRequestOrGetCached({\n    range,\n    src,\n    controller: null,\n    logLevel,\n    prefetchCache\n  });\n};\nvar fetchReadWholeAsText = async (src) => {\n  if (typeof src !== \"string\" && src instanceof URL === false) {\n    throw new Error(\"src must be a string when using `fetchReader`\");\n  }\n  const res = await fetch(src);\n  if (!res.ok) {\n    throw new Error(`Failed to fetch ${src} (HTTP code: ${res.status})`);\n  }\n  return res.text();\n};\nvar fetchCreateAdjacentFileSource = (relativePath, src) => {\n  if (typeof src !== \"string\" && src instanceof URL === false) {\n    throw new Error(\"src must be a string or URL when using `fetchReader`\");\n  }\n  return new URL(relativePath, src).toString();\n};\n\n// src/readers/from-web-file.ts\nvar webFileReadContent = ({ src, range, controller }) => {\n  if (typeof src === \"string\" || src instanceof URL) {\n    throw new Error(\"`inputTypeFileReader` only supports `File` objects\");\n  }\n  const part = range === null ? src : typeof range === \"number\" ? src.slice(range) : src.slice(range[0], range[1] + 1);\n  const stream = part.stream();\n  const streamReader = stream.getReader();\n  if (controller) {\n    controller._internals.signal.addEventListener(\"abort\", () => {\n      streamReader.cancel();\n    }, { once: true });\n  }\n  return Promise.resolve({\n    reader: {\n      reader: streamReader,\n      async abort() {\n        try {\n          await streamReader.cancel();\n        } catch {}\n        return Promise.resolve();\n      }\n    },\n    contentLength: src.size,\n    name: src instanceof File ? src.name : src.toString(),\n    supportsContentRange: true,\n    contentType: src.type,\n    needsContentRange: true\n  });\n};\nvar webFileReadWholeAsText = () => {\n  throw new Error(\"`webFileReader` cannot read auxiliary files.\");\n};\nvar webFileCreateAdjacentFileSource = () => {\n  throw new Error(\"`webFileReader` cannot create adjacent file sources.\");\n};\n\n// src/readers/web.ts\nvar webReader = {\n  read: (params) => {\n    if (params.src instanceof Blob) {\n      return webFileReadContent(params);\n    }\n    return fetchReadContent(params);\n  },\n  createAdjacentFileSource: (relativePath, src) => {\n    if (src instanceof Blob) {\n      return webFileCreateAdjacentFileSource(relativePath, src);\n    }\n    return fetchCreateAdjacentFileSource(relativePath, src);\n  },\n  readWholeAsText: (src) => {\n    if (src instanceof Blob) {\n      return webFileReadWholeAsText(src);\n    }\n    return fetchReadWholeAsText(src);\n  },\n  preload: ({ range, src, logLevel, prefetchCache }) => {\n    if (src instanceof Blob) {\n      return;\n    }\n    return fetchPreload({ range, src, logLevel, prefetchCache });\n  }\n};\n\n// src/containers/m3u/select-stream.ts\nvar selectAssociatedPlaylists = async ({\n  playlists,\n  fn,\n  skipAudioTracks\n}) => {\n  if (playlists.length < 1) {\n    return Promise.resolve([]);\n  }\n  const streams = await fn({ associatedPlaylists: playlists });\n  if (!Array.isArray(streams)) {\n    throw new Error(\"Expected an array of associated playlists\");\n  }\n  const selectedStreams = [];\n  for (const stream of streams) {\n    if (stream.isAudio && skipAudioTracks) {\n      continue;\n    }\n    if (!playlists.find((playlist) => playlist.src === stream.src)) {\n      throw new Error(`The associated playlist ${JSON.stringify(streams)} cannot be selected because it was not in the list of selectable playlists`);\n    }\n    selectedStreams.push(stream);\n  }\n  return selectedStreams;\n};\nvar defaultSelectM3uAssociatedPlaylists = ({ associatedPlaylists }) => {\n  if (associatedPlaylists.length === 1) {\n    return associatedPlaylists;\n  }\n  return associatedPlaylists.filter((playlist) => playlist.default);\n};\nvar selectStream = async ({\n  streams,\n  fn\n}) => {\n  if (streams.length < 1) {\n    throw new Error(\"No streams found\");\n  }\n  const selectedStreamId = await fn({ streams });\n  const selectedStream = streams.find((stream) => stream.id === selectedStreamId);\n  if (!selectedStream) {\n    throw new Error(`No stream with the id ${selectedStreamId} found`);\n  }\n  return Promise.resolve(selectedStream);\n};\nvar defaultSelectM3uStreamFn = ({ streams }) => {\n  return Promise.resolve(streams[0].id);\n};\n\n// src/with-resolvers.ts\nvar withResolvers = function() {\n  let resolve;\n  let reject;\n  const promise = new Promise((res, rej) => {\n    resolve = res;\n    reject = rej;\n  });\n  return { promise, resolve, reject };\n};\n\n// src/controller/emitter.ts\nclass MediaParserEmitter {\n  listeners = {\n    pause: [],\n    resume: [],\n    abort: [],\n    seek: []\n  };\n  readyPromise;\n  #markAsReady;\n  constructor() {\n    const { promise, resolve } = withResolvers();\n    this.readyPromise = promise;\n    this.#markAsReady = resolve;\n  }\n  markAsReady = () => {\n    this.#markAsReady();\n  };\n  addEventListener = (name, callback) => {\n    this.listeners[name].push(callback);\n  };\n  removeEventListener = (name, callback) => {\n    this.listeners[name] = this.listeners[name].filter((l) => l !== callback);\n  };\n  dispatchEvent(dispatchName, context) {\n    this.listeners[dispatchName].forEach((callback) => {\n      callback({ detail: context });\n    });\n  }\n  dispatchPause = () => {\n    this.readyPromise = this.readyPromise.then(() => {\n      this.dispatchEvent(\"pause\", undefined);\n    });\n  };\n  dispatchResume = () => {\n    this.readyPromise = this.readyPromise.then(() => {\n      this.dispatchEvent(\"resume\", undefined);\n    });\n  };\n  dispatchAbort = (reason) => {\n    this.readyPromise = this.readyPromise.then(() => {\n      this.dispatchEvent(\"abort\", { reason });\n    });\n  };\n  dispatchSeek = (seek) => {\n    this.readyPromise = this.readyPromise.then(() => {\n      this.dispatchEvent(\"seek\", { seek });\n    });\n  };\n}\n\n// src/controller/pause-signal.ts\nvar makePauseSignal = (emitter) => {\n  const waiterFns = [];\n  let paused = false;\n  return {\n    pause: () => {\n      if (paused) {\n        return;\n      }\n      emitter.dispatchPause();\n      paused = true;\n    },\n    resume: () => {\n      if (!paused) {\n        return;\n      }\n      paused = false;\n      for (const waiterFn of waiterFns) {\n        waiterFn();\n      }\n      waiterFns.length = 0;\n      emitter.dispatchResume();\n    },\n    waitUntilResume: () => {\n      return new Promise((resolve) => {\n        if (!paused) {\n          resolve();\n        } else {\n          waiterFns.push(resolve);\n        }\n      });\n    }\n  };\n};\n\n// src/controller/performed-seeks-stats.ts\nvar performedSeeksStats = () => {\n  const performedSeeks = [];\n  const markLastSeekAsUserInitiated = () => {\n    if (performedSeeks.length > 0) {\n      performedSeeks[performedSeeks.length - 1].type = \"user-initiated\";\n    }\n  };\n  return {\n    recordSeek: (seek) => {\n      performedSeeks.push(seek);\n    },\n    getPerformedSeeks: () => {\n      return performedSeeks;\n    },\n    markLastSeekAsUserInitiated\n  };\n};\n\n// src/controller/seek-signal.ts\nvar makeSeekSignal = (emitter) => {\n  let seek = null;\n  return {\n    seek: (seekRequest) => {\n      seek = seekRequest;\n      emitter.dispatchSeek(seekRequest);\n    },\n    getSeek() {\n      return seek;\n    },\n    clearSeekIfStillSame(previousSeek) {\n      if (seek === previousSeek) {\n        seek = null;\n        return { hasChanged: false };\n      }\n      return { hasChanged: true };\n    }\n  };\n};\n\n// src/controller/media-parser-controller.ts\nvar mediaParserController = () => {\n  const abortController = new AbortController;\n  const emitter = new MediaParserEmitter;\n  const pauseSignal = makePauseSignal(emitter);\n  const seekSignal = makeSeekSignal(emitter);\n  const performedSeeksSignal = performedSeeksStats();\n  const checkForAbortAndPause = async () => {\n    if (abortController.signal.aborted) {\n      const err = new MediaParserAbortError(\"Aborted\");\n      if (abortController.signal.reason) {\n        err.cause = abortController.signal.reason;\n      }\n      throw err;\n    }\n    await pauseSignal.waitUntilResume();\n  };\n  let seekingHintResolution = null;\n  let simulateSeekResolution = null;\n  const getSeekingHints = () => {\n    if (!seekingHintResolution) {\n      throw new Error(\"The mediaParserController() was not yet used in a parseMedia() call\");\n    }\n    return seekingHintResolution();\n  };\n  const simulateSeek = (seekInSeconds) => {\n    if (!simulateSeekResolution) {\n      throw new Error(\"The mediaParserController() was not yet used in a parseMedia() call\");\n    }\n    return simulateSeekResolution(seekInSeconds);\n  };\n  const attachSeekingHintResolution = (callback) => {\n    if (seekingHintResolution) {\n      throw new Error(\"The mediaParserController() was used in multiple parseMedia() calls. Create a separate controller for each call.\");\n    }\n    seekingHintResolution = callback;\n  };\n  const attachSimulateSeekResolution = (callback) => {\n    if (simulateSeekResolution) {\n      throw new Error(\"The mediaParserController() was used in multiple parseMedia() calls. Create a separate controller for each call.\");\n    }\n    simulateSeekResolution = callback;\n  };\n  return {\n    abort: (reason) => {\n      abortController.abort(reason);\n      emitter.dispatchAbort(reason);\n    },\n    seek: seekSignal.seek,\n    simulateSeek,\n    pause: pauseSignal.pause,\n    resume: pauseSignal.resume,\n    addEventListener: emitter.addEventListener,\n    removeEventListener: emitter.removeEventListener,\n    getSeekingHints,\n    _internals: {\n      signal: abortController.signal,\n      checkForAbortAndPause,\n      seekSignal,\n      markAsReadyToEmitEvents: emitter.markAsReady,\n      performedSeeksSignal,\n      attachSeekingHintResolution,\n      attachSimulateSeekResolution\n    }\n  };\n};\n\n// src/containers/m3u/get-streams.ts\nvar isIndependentSegments = (structure) => {\n  if (structure === null || structure.type !== \"m3u\") {\n    return false;\n  }\n  return structure.boxes.some((box) => box.type === \"m3u-independent-segments\" || box.type === \"m3u-stream-info\");\n};\nvar getM3uStreams = ({\n  structure,\n  originalSrc,\n  readerInterface\n}) => {\n  if (structure === null || structure.type !== \"m3u\") {\n    return null;\n  }\n  const boxes = [];\n  for (let i = 0;i < structure.boxes.length; i++) {\n    const str = structure.boxes[i];\n    if (str.type === \"m3u-stream-info\") {\n      const next = structure.boxes[i + 1];\n      if (next.type !== \"m3u-text-value\") {\n        throw new Error(\"Expected m3u-text-value\");\n      }\n      const associatedPlaylists = [];\n      if (str.audio) {\n        const match = structure.boxes.filter((box) => {\n          return box.type === \"m3u-media-info\" && box.groupId === str.audio;\n        });\n        for (const audioTrack of match) {\n          associatedPlaylists.push({\n            autoselect: audioTrack.autoselect,\n            channels: audioTrack.channels,\n            default: audioTrack.default,\n            groupId: audioTrack.groupId,\n            language: audioTrack.language,\n            name: audioTrack.name,\n            src: readerInterface.createAdjacentFileSource(audioTrack.uri, originalSrc),\n            id: associatedPlaylists.length,\n            isAudio: true\n          });\n        }\n      }\n      boxes.push({\n        src: readerInterface.createAdjacentFileSource(next.value, originalSrc),\n        averageBandwidthInBitsPerSec: str.averageBandwidthInBitsPerSec,\n        bandwidthInBitsPerSec: str.bandwidthInBitsPerSec,\n        codecs: str.codecs,\n        dimensions: str.dimensions,\n        associatedPlaylists\n      });\n    }\n  }\n  if (boxes.length === 0) {\n    return null;\n  }\n  const sorted = boxes.slice().sort((a, b) => {\n    const aResolution = a.dimensions ? a.dimensions.width * a.dimensions.height : 0;\n    const bResolution = b.dimensions ? b.dimensions.width * b.dimensions.height : 0;\n    if (aResolution === bResolution) {\n      const bandwidthA = a.averageBandwidthInBitsPerSec ?? a.bandwidthInBitsPerSec ?? 0;\n      const bandwidthB = b.averageBandwidthInBitsPerSec ?? b.bandwidthInBitsPerSec ?? 0;\n      return bandwidthB - bandwidthA;\n    }\n    return bResolution - aResolution;\n  });\n  return sorted.map((box, index) => ({ ...box, id: index }));\n};\nvar m3uHasStreams = (state) => {\n  const structure = state.structure.getStructureOrNull();\n  if (!structure) {\n    return false;\n  }\n  if (structure.type !== \"m3u\") {\n    return true;\n  }\n  return state.m3u.hasFinishedManifest();\n};\n\n// src/state/iso-base-media/precomputed-moof.ts\nvar precomputedMoofState = () => {\n  let moofBoxes = [];\n  return {\n    getMoofBoxes: () => moofBoxes,\n    setMoofBoxes: (boxes) => {\n      moofBoxes = boxes;\n    }\n  };\n};\nvar toMoofBox = (box) => {\n  if (box.type !== \"regular-box\") {\n    throw new Error(\"expected regular bpx\");\n  }\n  return {\n    offset: box.offset,\n    trafBoxes: box.children.filter((c) => c.type === \"regular-box\" && c.boxType === \"traf\"),\n    size: box.boxSize\n  };\n};\nvar deduplicateMoofBoxesByOffset = (moofBoxes) => {\n  return moofBoxes.filter((m, i, arr) => i === arr.findIndex((t) => t.offset === m.offset));\n};\n\n// src/containers/iso-base-media/traversal.ts\nvar getMoovFromFromIsoStructure = (structure) => {\n  const moovBox = structure.boxes.find((s) => s.type === \"moov-box\");\n  if (!moovBox || moovBox.type !== \"moov-box\") {\n    return null;\n  }\n  return moovBox;\n};\nvar getMoovBoxFromState = ({\n  structureState,\n  isoState,\n  mp4HeaderSegment,\n  mayUsePrecomputed\n}) => {\n  const got = isoState.moov.getMoovBoxAndPrecomputed();\n  if (got && (mayUsePrecomputed || !got.precomputed)) {\n    return got.moovBox;\n  }\n  if (mp4HeaderSegment) {\n    return getMoovFromFromIsoStructure(mp4HeaderSegment);\n  }\n  const structure = structureState.getIsoStructure();\n  return getMoovFromFromIsoStructure(structure);\n};\nvar getMoofBoxes = (main) => {\n  const moofBoxes = main.filter((s) => s.type === \"regular-box\" && s.boxType === \"moof\");\n  return moofBoxes.map((m) => toMoofBox(m));\n};\nvar getMvhdBox = (moovBox) => {\n  const mvHdBox = moovBox.children.find((s) => s.type === \"mvhd-box\");\n  if (!mvHdBox || mvHdBox.type !== \"mvhd-box\") {\n    return null;\n  }\n  return mvHdBox;\n};\nvar getTraks = (moovBox) => {\n  return moovBox.children.filter((s) => s.type === \"trak-box\");\n};\nvar getTkhdBox = (trakBox) => {\n  const tkhdBox = trakBox.children.find((s) => s.type === \"tkhd-box\");\n  return tkhdBox;\n};\nvar getMdiaBox = (trakBox) => {\n  const mdiaBox = trakBox.children.find((s) => s.type === \"regular-box\" && s.boxType === \"mdia\");\n  if (!mdiaBox || mdiaBox.type !== \"regular-box\") {\n    return null;\n  }\n  return mdiaBox;\n};\nvar getMdhdBox = (trakBox) => {\n  const mdiaBox = getMdiaBox(trakBox);\n  if (!mdiaBox) {\n    return null;\n  }\n  const mdhdBox = mdiaBox.children.find((c) => c.type === \"mdhd-box\");\n  return mdhdBox;\n};\nvar getStblBox = (trakBox) => {\n  const mdiaBox = getMdiaBox(trakBox);\n  if (!mdiaBox) {\n    return null;\n  }\n  const minfBox = mdiaBox.children.find((s) => s.type === \"regular-box\" && s.boxType === \"minf\");\n  if (!minfBox || minfBox.type !== \"regular-box\") {\n    return null;\n  }\n  const stblBox = minfBox.children.find((s) => s.type === \"regular-box\" && s.boxType === \"stbl\");\n  if (!stblBox || stblBox.type !== \"regular-box\") {\n    return null;\n  }\n  return stblBox;\n};\nvar getStsdBox = (trakBox) => {\n  const stblBox = getStblBox(trakBox);\n  if (!stblBox || stblBox.type !== \"regular-box\") {\n    return null;\n  }\n  const stsdBox = stblBox.children.find((s) => s.type === \"stsd-box\");\n  return stsdBox;\n};\nvar getVideoDescriptors = (trakBox) => {\n  const stsdBox = getStsdBox(trakBox);\n  if (!stsdBox) {\n    return null;\n  }\n  const descriptors = stsdBox.samples.map((s) => {\n    return s.type === \"video\" ? s.descriptors.map((d) => {\n      return d.type === \"avcc-box\" ? d.privateData : d.type === \"hvcc-box\" ? d.privateData : null;\n    }) : [];\n  });\n  return descriptors.flat(1).filter(Boolean)[0] ?? null;\n};\nvar getStcoBox = (trakBox) => {\n  const stblBox = getStblBox(trakBox);\n  if (!stblBox || stblBox.type !== \"regular-box\") {\n    return null;\n  }\n  const stcoBox = stblBox.children.find((s) => s.type === \"stco-box\");\n  return stcoBox;\n};\nvar getSttsBox = (trakBox) => {\n  const stblBox = getStblBox(trakBox);\n  if (!stblBox || stblBox.type !== \"regular-box\") {\n    return null;\n  }\n  const sttsBox = stblBox.children.find((s) => s.type === \"stts-box\");\n  return sttsBox;\n};\nvar getCttsBox = (trakBox) => {\n  const stblBox = getStblBox(trakBox);\n  if (!stblBox || stblBox.type !== \"regular-box\") {\n    return null;\n  }\n  const cttsBox = stblBox.children.find((s) => s.type === \"ctts-box\");\n  return cttsBox;\n};\nvar getStszBox = (trakBox) => {\n  const stblBox = getStblBox(trakBox);\n  if (!stblBox || stblBox.type !== \"regular-box\") {\n    return null;\n  }\n  const stszBox = stblBox.children.find((s) => s.type === \"stsz-box\");\n  return stszBox;\n};\nvar getStscBox = (trakBox) => {\n  const stblBox = getStblBox(trakBox);\n  if (!stblBox || stblBox.type !== \"regular-box\") {\n    return null;\n  }\n  const stcoBox = stblBox.children.find((b) => b.type === \"stsc-box\");\n  return stcoBox;\n};\nvar getStssBox = (trakBox) => {\n  const stblBox = getStblBox(trakBox);\n  if (!stblBox || stblBox.type !== \"regular-box\") {\n    return null;\n  }\n  const stssBox = stblBox.children.find((b) => b.type === \"stss-box\");\n  return stssBox;\n};\nvar getTfdtBox = (segment) => {\n  if (segment.type !== \"regular-box\" || segment.boxType !== \"traf\") {\n    throw new Error(\"Expected traf-box\");\n  }\n  const tfhdBox = segment.children.find((c) => c.type === \"tfdt-box\");\n  if (!tfhdBox || tfhdBox.type !== \"tfdt-box\") {\n    throw new Error(\"Expected tfhd-box\");\n  }\n  return tfhdBox;\n};\nvar getTfhdBox = (segment) => {\n  if (segment.type !== \"regular-box\" || segment.boxType !== \"traf\") {\n    throw new Error(\"Expected traf-box\");\n  }\n  const tfhdBox = segment.children.find((c) => c.type === \"tfhd-box\");\n  if (!tfhdBox || tfhdBox.type !== \"tfhd-box\") {\n    throw new Error(\"Expected tfhd-box\");\n  }\n  return tfhdBox;\n};\nvar getTrunBoxes = (segment) => {\n  if (segment.type !== \"regular-box\" || segment.boxType !== \"traf\") {\n    throw new Error(\"Expected traf-box\");\n  }\n  const trunBoxes = segment.children.filter((c) => c.type === \"trun-box\");\n  return trunBoxes;\n};\nvar getMvexBox = (moovAtom) => {\n  const mvexBox = moovAtom.children.find((s) => s.type === \"regular-box\" && s.boxType === \"mvex\");\n  if (!mvexBox || mvexBox.type !== \"regular-box\") {\n    return null;\n  }\n  return mvexBox;\n};\nvar getTrexBoxes = (moovAtom) => {\n  const mvexBox = getMvexBox(moovAtom);\n  if (!mvexBox) {\n    return [];\n  }\n  const trexBoxes = mvexBox.children.filter((c) => c.type === \"trex-box\");\n  return trexBoxes;\n};\nvar getTfraBoxesFromMfraBoxChildren = (mfraBoxChildren) => {\n  const tfraBoxes = mfraBoxChildren.filter((b) => b.type === \"tfra-box\");\n  return tfraBoxes;\n};\nvar getTfraBoxes = (structure) => {\n  const mfraBox = structure.find((b) => b.type === \"regular-box\" && b.boxType === \"mfra\");\n  if (!mfraBox) {\n    return [];\n  }\n  return getTfraBoxesFromMfraBoxChildren(mfraBox.children);\n};\nvar getTrakBoxByTrackId = (moovBox, trackId) => {\n  const trakBoxes = getTraks(moovBox);\n  return trakBoxes.find((t) => {\n    const tkhd = getTkhdBox(t);\n    if (!tkhd) {\n      return false;\n    }\n    return tkhd.trackId === trackId;\n  }) ?? null;\n};\nvar getElstBox = (trakBox) => {\n  const edtsBox = trakBox.children.find((s) => s.type === \"regular-box\" && s.boxType === \"edts\");\n  if (!edtsBox || edtsBox.type !== \"regular-box\") {\n    return null;\n  }\n  const elstBox = edtsBox.children.find((s) => s.type === \"elst-box\");\n  return elstBox;\n};\n\n// src/containers/riff/traversal.ts\nvar isRiffAvi = (structure) => {\n  return structure.boxes.some((box) => box.type === \"riff-header\" && box.fileType === \"AVI\");\n};\nvar getHdlrBox = (structure) => {\n  return structure.boxes.find((box) => box.type === \"list-box\" && box.listType === \"hdrl\");\n};\nvar getAvihBox = (structure) => {\n  const hdlrBox = getHdlrBox(structure);\n  if (!hdlrBox) {\n    return null;\n  }\n  return hdlrBox.children.find((box) => box.type === \"avih-box\");\n};\nvar getStrlBoxes = (structure) => {\n  const hdlrBox = getHdlrBox(structure);\n  if (!hdlrBox) {\n    return [];\n  }\n  return hdlrBox.children.filter((box) => box.type === \"list-box\" && box.listType === \"strl\");\n};\nvar getStrhBox = (strlBoxChildren) => {\n  return strlBoxChildren.find((box) => box.type === \"strh-box\");\n};\n\n// src/is-audio-structure.ts\nvar isAudioStructure = (structure) => {\n  if (structure.type === \"mp3\") {\n    return true;\n  }\n  if (structure.type === \"wav\") {\n    return true;\n  }\n  if (structure.type === \"aac\") {\n    return true;\n  }\n  if (structure.type === \"flac\") {\n    return true;\n  }\n  if (structure.type === \"iso-base-media\") {\n    return false;\n  }\n  if (structure.type === \"matroska\") {\n    return false;\n  }\n  if (structure.type === \"transport-stream\") {\n    return false;\n  }\n  if (structure.type === \"riff\") {\n    return false;\n  }\n  if (structure.type === \"m3u\") {\n    return false;\n  }\n  throw new Error(`Unhandled structure type: ${structure}`);\n};\n\n// src/get-fps.ts\nvar calculateFps = ({\n  sttsBox,\n  timeScale,\n  durationInSamples\n}) => {\n  let totalSamples = 0;\n  for (const sample of sttsBox.sampleDistribution) {\n    totalSamples += sample.sampleCount;\n  }\n  if (totalSamples === 0) {\n    return null;\n  }\n  const durationInSeconds = durationInSamples / timeScale;\n  const fps = totalSamples / durationInSeconds;\n  return fps;\n};\nvar trakBoxContainsAudio = (trakBox) => {\n  const stsd = getStsdBox(trakBox);\n  if (!stsd) {\n    return false;\n  }\n  const videoSample = stsd.samples.find((s) => s.type === \"audio\");\n  if (!videoSample || videoSample.type !== \"audio\") {\n    return false;\n  }\n  return true;\n};\nvar trakBoxContainsVideo = (trakBox) => {\n  const stsd = getStsdBox(trakBox);\n  if (!stsd) {\n    return false;\n  }\n  const videoSample = stsd.samples.find((s) => s.type === \"video\");\n  if (!videoSample || videoSample.type !== \"video\") {\n    return false;\n  }\n  return true;\n};\nvar getTimescaleAndDuration = (trakBox) => {\n  const mdhdBox = getMdhdBox(trakBox);\n  if (mdhdBox) {\n    return { timescale: mdhdBox.timescale, duration: mdhdBox.duration };\n  }\n  return null;\n};\nvar getFpsFromMp4TrakBox = (trakBox) => {\n  const timescaleAndDuration = getTimescaleAndDuration(trakBox);\n  if (!timescaleAndDuration) {\n    return null;\n  }\n  const sttsBox = getSttsBox(trakBox);\n  if (!sttsBox) {\n    return null;\n  }\n  return calculateFps({\n    sttsBox,\n    timeScale: timescaleAndDuration.timescale,\n    durationInSamples: timescaleAndDuration.duration\n  });\n};\nvar getFpsFromIsoMaseMedia = (state) => {\n  const moovBox = getMoovBoxFromState({\n    structureState: state.structure,\n    isoState: state.iso,\n    mp4HeaderSegment: state.m3uPlaylistContext?.mp4HeaderSegment ?? null,\n    mayUsePrecomputed: true\n  });\n  if (!moovBox) {\n    return null;\n  }\n  const trackBoxes = getTraks(moovBox);\n  const trackBox = trackBoxes.find(trakBoxContainsVideo);\n  if (!trackBox) {\n    return null;\n  }\n  return getFpsFromMp4TrakBox(trackBox);\n};\nvar getFpsFromAvi = (structure) => {\n  const strl = getStrlBoxes(structure);\n  for (const s of strl) {\n    const strh = getStrhBox(s.children);\n    if (!strh) {\n      throw new Error(\"No strh box\");\n    }\n    if (strh.fccType === \"auds\") {\n      continue;\n    }\n    return strh.rate;\n  }\n  return null;\n};\nvar getFps = (state) => {\n  const segments = state.structure.getStructure();\n  if (segments.type === \"iso-base-media\") {\n    return getFpsFromIsoMaseMedia(state);\n  }\n  if (segments.type === \"riff\") {\n    return getFpsFromAvi(segments);\n  }\n  if (segments.type === \"matroska\") {\n    return null;\n  }\n  if (segments.type === \"transport-stream\") {\n    return null;\n  }\n  if (segments.type === \"m3u\") {\n    return null;\n  }\n  if (segments.type === \"mp3\" || segments.type === \"wav\" || segments.type === \"flac\" || segments.type === \"aac\") {\n    return null;\n  }\n  throw new Error(\"Cannot get fps, not implemented: \" + segments);\n};\nvar hasFpsSuitedForSlowFps = (state) => {\n  try {\n    return getFps(state) !== null;\n  } catch {\n    return false;\n  }\n};\nvar hasFps = (state) => {\n  const structure = state.structure.getStructure();\n  if (isAudioStructure(structure)) {\n    return true;\n  }\n  if (structure.type === \"matroska\") {\n    return true;\n  }\n  if (structure.type === \"transport-stream\") {\n    return true;\n  }\n  if (structure.type === \"m3u\") {\n    return true;\n  }\n  return hasFpsSuitedForSlowFps(state);\n};\n\n// src/get-sample-aspect-ratio.ts\nvar getStsdVideoConfig = (trakBox) => {\n  const stsdBox = getStsdBox(trakBox);\n  if (!stsdBox) {\n    return null;\n  }\n  const videoConfig = stsdBox.samples.find((s) => s.type === \"video\");\n  if (!videoConfig || videoConfig.type !== \"video\") {\n    return null;\n  }\n  return videoConfig;\n};\nvar getAvccBox = (trakBox) => {\n  const videoConfig = getStsdVideoConfig(trakBox);\n  if (!videoConfig) {\n    return null;\n  }\n  const avccBox = videoConfig.descriptors.find((c) => c.type === \"avcc-box\");\n  if (!avccBox || avccBox.type !== \"avcc-box\") {\n    return null;\n  }\n  return avccBox;\n};\nvar getAv1CBox = (trakBox) => {\n  const videoConfig = getStsdVideoConfig(trakBox);\n  if (!videoConfig) {\n    return null;\n  }\n  const av1cBox = videoConfig.descriptors.find((c) => c.type === \"av1C-box\");\n  if (!av1cBox || av1cBox.type !== \"av1C-box\") {\n    return null;\n  }\n  return av1cBox;\n};\nvar getPaspBox = (trakBox) => {\n  const videoConfig = getStsdVideoConfig(trakBox);\n  if (!videoConfig) {\n    return null;\n  }\n  const paspBox = videoConfig.descriptors.find((c) => c.type === \"pasp-box\");\n  if (!paspBox || paspBox.type !== \"pasp-box\") {\n    return null;\n  }\n  return paspBox;\n};\nvar getHvccBox = (trakBox) => {\n  const videoConfig = getStsdVideoConfig(trakBox);\n  if (!videoConfig) {\n    return null;\n  }\n  const hvccBox = videoConfig.descriptors.find((c) => c.type === \"hvcc-box\");\n  if (!hvccBox || hvccBox.type !== \"hvcc-box\") {\n    return null;\n  }\n  return hvccBox;\n};\nvar getSampleAspectRatio = (trakBox) => {\n  const paspBox = getPaspBox(trakBox);\n  if (!paspBox) {\n    return {\n      numerator: 1,\n      denominator: 1\n    };\n  }\n  return {\n    numerator: paspBox.hSpacing,\n    denominator: paspBox.vSpacing\n  };\n};\nvar getColrBox = (videoSample) => {\n  const colrBox = videoSample.descriptors.find((c) => c.type === \"colr-box\");\n  if (!colrBox || colrBox.type !== \"colr-box\") {\n    return null;\n  }\n  return colrBox;\n};\nvar applyTkhdBox = (aspectRatioApplied, tkhdBox) => {\n  if (tkhdBox === null || tkhdBox.rotation === 0) {\n    return {\n      displayAspectWidth: aspectRatioApplied.width,\n      displayAspectHeight: aspectRatioApplied.height,\n      width: aspectRatioApplied.width,\n      height: aspectRatioApplied.height,\n      rotation: 0\n    };\n  }\n  return {\n    width: tkhdBox.width,\n    height: tkhdBox.height,\n    rotation: tkhdBox.rotation,\n    displayAspectWidth: aspectRatioApplied.width,\n    displayAspectHeight: aspectRatioApplied.height\n  };\n};\nvar applyAspectRatios = ({\n  dimensions,\n  sampleAspectRatio,\n  displayAspectRatio\n}) => {\n  if (displayAspectRatio.numerator === 0) {\n    return dimensions;\n  }\n  if (displayAspectRatio.denominator === 0) {\n    return dimensions;\n  }\n  const newWidth = Math.round(dimensions.width * sampleAspectRatio.numerator / sampleAspectRatio.denominator);\n  const newHeight = Math.floor(newWidth / (displayAspectRatio.numerator / displayAspectRatio.denominator));\n  return {\n    width: Math.floor(newWidth),\n    height: newHeight\n  };\n};\nfunction gcd(a, b) {\n  return b === 0 ? a : gcd(b, a % b);\n}\nfunction reduceFraction(numerator, denominator) {\n  const greatestCommonDivisor = gcd(Math.abs(numerator), Math.abs(denominator));\n  return {\n    numerator: numerator / greatestCommonDivisor,\n    denominator: denominator / greatestCommonDivisor\n  };\n}\nvar getDisplayAspectRatio = ({\n  sampleAspectRatio,\n  nativeDimensions\n}) => {\n  const num = Math.round(nativeDimensions.width * sampleAspectRatio.numerator);\n  const den = Math.round(nativeDimensions.height * sampleAspectRatio.denominator);\n  return reduceFraction(num, den);\n};\n\n// src/containers/avc/color.ts\nvar getMatrixCoefficientsFromIndex = (index) => {\n  if (index === 0) {\n    return \"rgb\";\n  }\n  if (index === 1) {\n    return \"bt709\";\n  }\n  if (index === 5) {\n    return \"bt470bg\";\n  }\n  if (index === 6) {\n    return \"smpte170m\";\n  }\n  if (index === 9) {\n    return \"bt2020-ncl\";\n  }\n  return null;\n};\nvar getTransferCharacteristicsFromIndex = (index) => {\n  if (index === 1) {\n    return \"bt709\";\n  }\n  if (index === 6) {\n    return \"smpte170m\";\n  }\n  if (index === 8) {\n    return \"linear\";\n  }\n  if (index === 13) {\n    return \"iec61966-2-1\";\n  }\n  if (index === 16) {\n    return \"pq\";\n  }\n  if (index === 18) {\n    return \"hlg\";\n  }\n  return null;\n};\nvar getPrimariesFromIndex = (index) => {\n  if (index === 1) {\n    return \"bt709\";\n  }\n  if (index === 5) {\n    return \"bt470bg\";\n  }\n  if (index === 6) {\n    return \"smpte170m\";\n  }\n  if (index === 9) {\n    return \"bt2020\";\n  }\n  if (index === 12) {\n    return \"smpte432\";\n  }\n  return null;\n};\n\n// src/containers/webm/segments/all-segments.ts\nvar matroskaElements = {\n  Header: \"0x1a45dfa3\",\n  EBMLMaxIDLength: \"0x42f2\",\n  EBMLVersion: \"0x4286\",\n  EBMLReadVersion: \"0x42f7\",\n  EBMLMaxSizeLength: \"0x42f3\",\n  DocType: \"0x4282\",\n  DocTypeVersion: \"0x4287\",\n  DocTypeReadVersion: \"0x4285\",\n  Segment: \"0x18538067\",\n  SeekHead: \"0x114d9b74\",\n  Seek: \"0x4dbb\",\n  SeekID: \"0x53ab\",\n  SeekPosition: \"0x53ac\",\n  Info: \"0x1549a966\",\n  SegmentUUID: \"0x73a4\",\n  SegmentFilename: \"0x7384\",\n  PrevUUID: \"0x3cb923\",\n  PrevFilename: \"0x3c83ab\",\n  NextUUID: \"0x3eb923\",\n  NextFilename: \"0x3e83bb\",\n  SegmentFamily: \"0x4444\",\n  ChapterTranslate: \"0x6924\",\n  ChapterTranslateID: \"0x69a5\",\n  ChapterTranslateCodec: \"0x69bf\",\n  ChapterTranslateEditionUID: \"0x69fc\",\n  TimestampScale: \"0x2ad7b1\",\n  Duration: \"0x4489\",\n  DateUTC: \"0x4461\",\n  Title: \"0x7ba9\",\n  MuxingApp: \"0x4d80\",\n  WritingApp: \"0x5741\",\n  Cluster: \"0x1f43b675\",\n  Timestamp: \"0xe7\",\n  SilentTracks: \"0x5854\",\n  SilentTrackNumber: \"0x58d7\",\n  Position: \"0xa7\",\n  PrevSize: \"0xab\",\n  SimpleBlock: \"0xa3\",\n  BlockGroup: \"0xa0\",\n  Block: \"0xa1\",\n  BlockVirtual: \"0xa2\",\n  BlockAdditions: \"0x75a1\",\n  BlockMore: \"0xa6\",\n  BlockAdditional: \"0xa5\",\n  BlockAddID: \"0xee\",\n  BlockDuration: \"0x9b\",\n  ReferencePriority: \"0xfa\",\n  ReferenceBlock: \"0xfb\",\n  ReferenceVirtual: \"0xfd\",\n  CodecState: \"0xa4\",\n  DiscardPadding: \"0x75a2\",\n  Slices: \"0x8e\",\n  TimeSlice: \"0xe8\",\n  LaceNumber: \"0xcc\",\n  FrameNumber: \"0xcd\",\n  BlockAdditionID: \"0xcb\",\n  Delay: \"0xce\",\n  SliceDuration: \"0xcf\",\n  ReferenceFrame: \"0xc8\",\n  ReferenceOffset: \"0xc9\",\n  ReferenceTimestamp: \"0xca\",\n  EncryptedBlock: \"0xaf\",\n  Tracks: \"0x1654ae6b\",\n  TrackEntry: \"0xae\",\n  TrackNumber: \"0xd7\",\n  TrackUID: \"0x73c5\",\n  TrackType: \"0x83\",\n  FlagEnabled: \"0xb9\",\n  FlagDefault: \"0x88\",\n  FlagForced: \"0x55aa\",\n  FlagHearingImpaired: \"0x55ab\",\n  FlagVisualImpaired: \"0x55ac\",\n  FlagTextDescriptions: \"0x55ad\",\n  FlagOriginal: \"0x55ae\",\n  FlagCommentary: \"0x55af\",\n  FlagLacing: \"0x9c\",\n  MinCache: \"0x6de7\",\n  MaxCache: \"0x6df8\",\n  DefaultDuration: \"0x23e383\",\n  DefaultDecodedFieldDuration: \"0x234e7a\",\n  TrackTimestampScale: \"0x23314f\",\n  TrackOffset: \"0x537f\",\n  MaxBlockAdditionID: \"0x55ee\",\n  BlockAdditionMapping: \"0x41e4\",\n  BlockAddIDValue: \"0x41f0\",\n  BlockAddIDName: \"0x41a4\",\n  BlockAddIDType: \"0x41e7\",\n  BlockAddIDExtraData: \"0x41ed\",\n  Name: \"0x536e\",\n  Language: \"0x22b59c\",\n  LanguageBCP47: \"0x22b59d\",\n  CodecID: \"0x86\",\n  CodecPrivate: \"0x63a2\",\n  CodecName: \"0x258688\",\n  AttachmentLink: \"0x7446\",\n  CodecSettings: \"0x3a9697\",\n  CodecInfoURL: \"0x3b4040\",\n  CodecDownloadURL: \"0x26b240\",\n  CodecDecodeAll: \"0xaa\",\n  TrackOverlay: \"0x6fab\",\n  CodecDelay: \"0x56aa\",\n  SeekPreRoll: \"0x56bb\",\n  TrackTranslate: \"0x6624\",\n  TrackTranslateTrackID: \"0x66a5\",\n  TrackTranslateCodec: \"0x66bf\",\n  TrackTranslateEditionUID: \"0x66fc\",\n  Video: \"0xe0\",\n  FlagInterlaced: \"0x9a\",\n  FieldOrder: \"0x9d\",\n  StereoMode: \"0x53b8\",\n  AlphaMode: \"0x53c0\",\n  OldStereoMode: \"0x53b9\",\n  PixelWidth: \"0xb0\",\n  PixelHeight: \"0xba\",\n  PixelCropBottom: \"0x54aa\",\n  PixelCropTop: \"0x54bb\",\n  PixelCropLeft: \"0x54cc\",\n  PixelCropRight: \"0x54dd\",\n  DisplayWidth: \"0x54b0\",\n  DisplayHeight: \"0x54ba\",\n  DisplayUnit: \"0x54b2\",\n  AspectRatioType: \"0x54b3\",\n  UncompressedFourCC: \"0x2eb524\",\n  GammaValue: \"0x2fb523\",\n  FrameRate: \"0x2383e3\",\n  Colour: \"0x55b0\",\n  MatrixCoefficients: \"0x55b1\",\n  BitsPerChannel: \"0x55b2\",\n  ChromaSubsamplingHorz: \"0x55b3\",\n  ChromaSubsamplingVert: \"0x55b4\",\n  CbSubsamplingHorz: \"0x55b5\",\n  CbSubsamplingVert: \"0x55b6\",\n  ChromaSitingHorz: \"0x55b7\",\n  ChromaSitingVert: \"0x55b8\",\n  Range: \"0x55b9\",\n  TransferCharacteristics: \"0x55ba\",\n  Primaries: \"0x55bb\",\n  MaxCLL: \"0x55bc\",\n  MaxFALL: \"0x55bd\",\n  MasteringMetadata: \"0x55d0\",\n  PrimaryRChromaticityX: \"0x55d1\",\n  PrimaryRChromaticityY: \"0x55d2\",\n  PrimaryGChromaticityX: \"0x55d3\",\n  PrimaryGChromaticityY: \"0x55d4\",\n  PrimaryBChromaticityX: \"0x55d5\",\n  PrimaryBChromaticityY: \"0x55d6\",\n  WhitePointChromaticityX: \"0x55d7\",\n  WhitePointChromaticityY: \"0x55d8\",\n  LuminanceMax: \"0x55d9\",\n  LuminanceMin: \"0x55da\",\n  Projection: \"0x7670\",\n  ProjectionType: \"0x7671\",\n  ProjectionPrivate: \"0x7672\",\n  ProjectionPoseYaw: \"0x7673\",\n  ProjectionPosePitch: \"0x7674\",\n  ProjectionPoseRoll: \"0x7675\",\n  Audio: \"0xe1\",\n  SamplingFrequency: \"0xb5\",\n  OutputSamplingFrequency: \"0x78b5\",\n  Channels: \"0x9f\",\n  ChannelPositions: \"0x7d7b\",\n  BitDepth: \"0x6264\",\n  Emphasis: \"0x52f1\",\n  TrackOperation: \"0xe2\",\n  TrackCombinePlanes: \"0xe3\",\n  TrackPlane: \"0xe4\",\n  TrackPlaneUID: \"0xe5\",\n  TrackPlaneType: \"0xe6\",\n  TrackJoinBlocks: \"0xe9\",\n  TrackJoinUID: \"0xed\",\n  TrickTrackUID: \"0xc0\",\n  TrickTrackSegmentUID: \"0xc1\",\n  TrickTrackFlag: \"0xc6\",\n  TrickMasterTrackUID: \"0xc7\",\n  TrickMasterTrackSegmentUID: \"0xc4\",\n  ContentEncodings: \"0x6d80\",\n  ContentEncoding: \"0x6240\",\n  ContentEncodingOrder: \"0x5031\",\n  ContentEncodingScope: \"0x5032\",\n  ContentEncodingType: \"0x5033\",\n  ContentCompression: \"0x5034\",\n  ContentCompAlgo: \"0x4254\",\n  ContentCompSettings: \"0x4255\",\n  ContentEncryption: \"0x5035\",\n  ContentEncAlgo: \"0x47e1\",\n  ContentEncKeyID: \"0x47e2\",\n  ContentEncAESSettings: \"0x47e7\",\n  AESSettingsCipherMode: \"0x47e8\",\n  ContentSignature: \"0x47e3\",\n  ContentSigKeyID: \"0x47e4\",\n  ContentSigAlgo: \"0x47e5\",\n  ContentSigHashAlgo: \"0x47e6\",\n  Cues: \"0x1c53bb6b\",\n  CuePoint: \"0xbb\",\n  CueTime: \"0xb3\",\n  CueTrackPositions: \"0xb7\",\n  CueTrack: \"0xf7\",\n  CueClusterPosition: \"0xf1\",\n  CueRelativePosition: \"0xf0\",\n  CueDuration: \"0xb2\",\n  CueBlockNumber: \"0x5378\",\n  CueCodecState: \"0xea\",\n  CueReference: \"0xdb\",\n  CueRefTime: \"0x96\",\n  CueRefCluster: \"0x97\",\n  CueRefNumber: \"0x535f\",\n  CueRefCodecState: \"0xeb\",\n  Attachments: \"0x1941a469\",\n  AttachedFile: \"0x61a7\",\n  FileDescription: \"0x467e\",\n  FileName: \"0x466e\",\n  FileMediaType: \"0x4660\",\n  FileData: \"0x465c\",\n  FileUID: \"0x46ae\",\n  FileReferral: \"0x4675\",\n  FileUsedStartTime: \"0x4661\",\n  FileUsedEndTime: \"0x4662\",\n  Chapters: \"0x1043a770\",\n  EditionEntry: \"0x45b9\",\n  EditionUID: \"0x45bc\",\n  EditionFlagHidden: \"0x45bd\",\n  EditionFlagDefault: \"0x45db\",\n  EditionFlagOrdered: \"0x45dd\",\n  EditionDisplay: \"0x4520\",\n  EditionString: \"0x4521\",\n  EditionLanguageIETF: \"0x45e4\",\n  ChapterAtom: \"0xb6\",\n  ChapterUID: \"0x73c4\",\n  ChapterStringUID: \"0x5654\",\n  ChapterTimeStart: \"0x91\",\n  ChapterTimeEnd: \"0x92\",\n  ChapterFlagHidden: \"0x98\",\n  ChapterFlagEnabled: \"0x4598\",\n  ChapterSegmentUUID: \"0x6e67\",\n  ChapterSkipType: \"0x4588\",\n  ChapterSegmentEditionUID: \"0x6ebc\",\n  ChapterPhysicalEquiv: \"0x63c3\",\n  ChapterTrack: \"0x8f\",\n  ChapterTrackUID: \"0x89\",\n  ChapterDisplay: \"0x80\",\n  ChapString: \"0x85\",\n  ChapLanguage: \"0x437c\",\n  ChapLanguageBCP47: \"0x437d\",\n  ChapCountry: \"0x437e\",\n  ChapProcess: \"0x6944\",\n  ChapProcessCodecID: \"0x6955\",\n  ChapProcessPrivate: \"0x450d\",\n  ChapProcessCommand: \"0x6911\",\n  ChapProcessTime: \"0x6922\",\n  ChapProcessData: \"0x6933\",\n  Tags: \"0x1254c367\",\n  Tag: \"0x7373\",\n  Targets: \"0x63c0\",\n  TargetTypeValue: \"0x68ca\",\n  TargetType: \"0x63ca\",\n  TagTrackUID: \"0x63c5\",\n  TagEditionUID: \"0x63c9\",\n  TagChapterUID: \"0x63c4\",\n  TagAttachmentUID: \"0x63c6\",\n  SimpleTag: \"0x67c8\",\n  TagName: \"0x45a3\",\n  TagLanguage: \"0x447a\",\n  TagLanguageBCP47: \"0x447b\",\n  TagDefault: \"0x4484\",\n  TagDefaultBogus: \"0x44b4\",\n  TagString: \"0x4487\",\n  TagBinary: \"0x4485\",\n  Void: \"0xec\",\n  Crc32: \"0xbf\"\n};\nvar matroskaIds = Object.values(matroskaElements);\nvar knownIdsWithOneLength = matroskaIds.filter((id) => id.length === 4);\nvar knownIdsWithTwoLength = matroskaIds.filter((id) => id.length === 6);\nvar knownIdsWithThreeLength = matroskaIds.filter((id) => id.length === 8);\nvar ebmlVersion = {\n  name: \"EBMLVersion\",\n  type: \"uint\"\n};\nvar ebmlReadVersion = {\n  name: \"EBMLReadVersion\",\n  type: \"uint\"\n};\nvar ebmlMaxIdLength = {\n  name: \"EBMLMaxIDLength\",\n  type: \"uint\"\n};\nvar ebmlMaxSizeLength = {\n  name: \"EBMLMaxSizeLength\",\n  type: \"uint\"\n};\nvar docType = {\n  name: \"DocType\",\n  type: \"string\"\n};\nvar docTypeVersion = {\n  name: \"DocTypeVersion\",\n  type: \"uint\"\n};\nvar docTypeReadVersion = {\n  name: \"DocTypeReadVersion\",\n  type: \"uint\"\n};\nvar voidEbml = {\n  name: \"Void\",\n  type: \"uint8array\"\n};\nvar matroskaHeader = {\n  name: \"Header\",\n  type: \"children\"\n};\nvar seekId = {\n  name: \"SeekID\",\n  type: \"hex-string\"\n};\nvar _name = {\n  name: \"Name\",\n  type: \"string\"\n};\nvar minCache = {\n  name: \"MinCache\",\n  type: \"uint\"\n};\nvar maxCache = {\n  name: \"MaxCache\",\n  type: \"uint\"\n};\nvar seekPosition = {\n  name: \"SeekPosition\",\n  type: \"uint\"\n};\nvar seek = {\n  name: \"Seek\",\n  type: \"children\"\n};\nvar seekHead = {\n  name: \"SeekHead\",\n  type: \"children\"\n};\nvar trackType = {\n  name: \"TrackType\",\n  type: \"uint\"\n};\nvar widthType = {\n  name: \"PixelWidth\",\n  type: \"uint\"\n};\nvar heightType = {\n  name: \"PixelHeight\",\n  type: \"uint\"\n};\nvar muxingApp = {\n  name: \"MuxingApp\",\n  type: \"string\"\n};\nvar duration = {\n  name: \"Duration\",\n  type: \"float\"\n};\nvar timestampScale = {\n  name: \"TimestampScale\",\n  type: \"uint\"\n};\nvar infoType = {\n  name: \"Info\",\n  type: \"children\"\n};\nvar titleType = {\n  name: \"Title\",\n  type: \"string\"\n};\nvar tagTrackUidType = {\n  name: \"TagTrackUID\",\n  type: \"hex-string\"\n};\nvar samplingFrequency = {\n  name: \"SamplingFrequency\",\n  type: \"float\"\n};\nvar channels = {\n  name: \"Channels\",\n  type: \"uint\"\n};\nvar alphaMode = {\n  name: \"AlphaMode\",\n  type: \"uint\"\n};\nvar interlaced = {\n  name: \"FlagInterlaced\",\n  type: \"uint\"\n};\nvar bitDepth = {\n  name: \"BitDepth\",\n  type: \"uint\"\n};\nvar displayWidth = {\n  name: \"DisplayWidth\",\n  type: \"uint\"\n};\nvar displayHeight = {\n  name: \"DisplayHeight\",\n  type: \"uint\"\n};\nvar displayUnit = {\n  name: \"DisplayUnit\",\n  type: \"uint\"\n};\nvar flagLacing = {\n  name: \"FlagLacing\",\n  type: \"uint\"\n};\nvar tagSegment = {\n  name: \"Tag\",\n  type: \"children\"\n};\nvar tags = {\n  name: \"Tags\",\n  type: \"children\"\n};\nvar trackNumber = {\n  name: \"TrackNumber\",\n  type: \"uint\"\n};\nvar trackUID = {\n  name: \"TrackUID\",\n  type: \"hex-string\"\n};\nvar color = {\n  name: \"Colour\",\n  type: \"children\"\n};\nvar transferCharacteristics = {\n  name: \"TransferCharacteristics\",\n  type: \"uint\"\n};\nvar matrixCoefficients = {\n  name: \"MatrixCoefficients\",\n  type: \"uint\"\n};\nvar primaries = {\n  name: \"Primaries\",\n  type: \"uint\"\n};\nvar range = {\n  name: \"Range\",\n  type: \"uint\"\n};\nvar ChromaSitingHorz = {\n  name: \"ChromaSitingHorz\",\n  type: \"uint\"\n};\nvar ChromaSitingVert = {\n  name: \"ChromaSitingVert\",\n  type: \"uint\"\n};\nvar language = {\n  name: \"Language\",\n  type: \"string\"\n};\nvar defaultDuration = {\n  name: \"DefaultDuration\",\n  type: \"uint\"\n};\nvar codecPrivate = {\n  name: \"CodecPrivate\",\n  type: \"uint8array\"\n};\nvar blockAdditionsSegment = {\n  name: \"BlockAdditions\",\n  type: \"uint8array\"\n};\nvar maxBlockAdditionIdSegment = {\n  name: \"MaxBlockAdditionID\",\n  type: \"uint\"\n};\nvar audioSegment = {\n  name: \"Audio\",\n  type: \"children\"\n};\nvar videoSegment = {\n  name: \"Video\",\n  type: \"children\"\n};\nvar flagDefault = {\n  name: \"FlagDefault\",\n  type: \"uint\"\n};\nvar referenceBlock = {\n  name: \"ReferenceBlock\",\n  type: \"uint\"\n};\nvar blockDurationSegment = {\n  name: \"BlockDuration\",\n  type: \"uint\"\n};\nvar codecName = {\n  name: \"CodecName\",\n  type: \"string\"\n};\nvar trackTimestampScale = {\n  name: \"TrackTimestampScale\",\n  type: \"float\"\n};\nvar trackEntry = {\n  name: \"TrackEntry\",\n  type: \"children\"\n};\nvar tracks = {\n  name: \"Tracks\",\n  type: \"children\"\n};\nvar block = {\n  name: \"Block\",\n  type: \"uint8array\"\n};\nvar simpleBlock = {\n  name: \"SimpleBlock\",\n  type: \"uint8array\"\n};\nvar blockGroup = {\n  name: \"BlockGroup\",\n  type: \"children\"\n};\nvar targetsType = {\n  name: \"Targets\",\n  type: \"children\"\n};\nvar simpleTagType = {\n  name: \"SimpleTag\",\n  type: \"children\"\n};\nvar tagNameType = {\n  name: \"TagName\",\n  type: \"string\"\n};\nvar tagStringType = {\n  name: \"TagString\",\n  type: \"string\"\n};\nvar ebmlMap = {\n  [matroskaElements.Header]: matroskaHeader,\n  [matroskaElements.DocType]: docType,\n  [matroskaElements.Targets]: targetsType,\n  [matroskaElements.SimpleTag]: simpleTagType,\n  [matroskaElements.TagName]: tagNameType,\n  [matroskaElements.TagString]: tagStringType,\n  [matroskaElements.DocTypeVersion]: docTypeVersion,\n  [matroskaElements.DocTypeReadVersion]: docTypeReadVersion,\n  [matroskaElements.EBMLVersion]: ebmlVersion,\n  [matroskaElements.EBMLReadVersion]: ebmlReadVersion,\n  [matroskaElements.EBMLMaxIDLength]: ebmlMaxIdLength,\n  [matroskaElements.EBMLMaxSizeLength]: ebmlMaxSizeLength,\n  [matroskaElements.Void]: voidEbml,\n  [matroskaElements.Cues]: {\n    name: \"Cues\",\n    type: \"children\"\n  },\n  [matroskaElements.CuePoint]: {\n    name: \"CuePoint\",\n    type: \"children\"\n  },\n  [matroskaElements.CueTime]: {\n    name: \"CueTime\",\n    type: \"uint\"\n  },\n  [matroskaElements.CueTrackPositions]: {\n    name: \"CueTrackPositions\",\n    type: \"children\"\n  },\n  [matroskaElements.CueClusterPosition]: {\n    name: \"CueClusterPosition\",\n    type: \"uint\"\n  },\n  [matroskaElements.CueRelativePosition]: {\n    name: \"CueRelativePosition\",\n    type: \"uint\"\n  },\n  [matroskaElements.CueBlockNumber]: {\n    name: \"CueBlockNumber\",\n    type: \"uint\"\n  },\n  [matroskaElements.CueTrack]: {\n    name: \"CueTrack\",\n    type: \"uint\"\n  },\n  [matroskaElements.DateUTC]: {\n    name: \"DateUTC\",\n    type: \"uint8array\"\n  },\n  [matroskaElements.TrackTimestampScale]: trackTimestampScale,\n  [matroskaElements.CodecDelay]: {\n    name: \"CodecDelay\",\n    type: \"uint8array\"\n  },\n  [matroskaElements.SeekPreRoll]: {\n    name: \"SeekPreRoll\",\n    type: \"uint8array\"\n  },\n  [matroskaElements.DiscardPadding]: {\n    name: \"DiscardPadding\",\n    type: \"uint8array\"\n  },\n  [matroskaElements.OutputSamplingFrequency]: {\n    name: \"OutputSamplingFrequency\",\n    type: \"uint8array\"\n  },\n  [matroskaElements.CodecName]: codecName,\n  [matroskaElements.Position]: {\n    name: \"Position\",\n    type: \"uint8array\"\n  },\n  [matroskaElements.SliceDuration]: {\n    name: \"SliceDuration\",\n    type: \"uint8array\"\n  },\n  [matroskaElements.TagTrackUID]: tagTrackUidType,\n  [matroskaElements.SeekHead]: seekHead,\n  [matroskaElements.Seek]: seek,\n  [matroskaElements.SeekID]: seekId,\n  [matroskaElements.Name]: _name,\n  [matroskaElements.MinCache]: minCache,\n  [matroskaElements.MaxCache]: maxCache,\n  [matroskaElements.SeekPosition]: seekPosition,\n  [matroskaElements.Crc32]: {\n    name: \"Crc32\",\n    type: \"uint8array\"\n  },\n  [matroskaElements.MuxingApp]: muxingApp,\n  [matroskaElements.WritingApp]: {\n    name: \"WritingApp\",\n    type: \"string\"\n  },\n  [matroskaElements.SegmentUUID]: {\n    name: \"SegmentUUID\",\n    type: \"string\"\n  },\n  [matroskaElements.Duration]: duration,\n  [matroskaElements.CodecID]: {\n    name: \"CodecID\",\n    type: \"string\"\n  },\n  [matroskaElements.TrackType]: trackType,\n  [matroskaElements.PixelWidth]: widthType,\n  [matroskaElements.PixelHeight]: heightType,\n  [matroskaElements.TimestampScale]: timestampScale,\n  [matroskaElements.Info]: infoType,\n  [matroskaElements.Title]: titleType,\n  [matroskaElements.SamplingFrequency]: samplingFrequency,\n  [matroskaElements.Channels]: channels,\n  [matroskaElements.AlphaMode]: alphaMode,\n  [matroskaElements.FlagInterlaced]: interlaced,\n  [matroskaElements.BitDepth]: bitDepth,\n  [matroskaElements.DisplayHeight]: displayHeight,\n  [matroskaElements.DisplayWidth]: displayWidth,\n  [matroskaElements.DisplayUnit]: displayUnit,\n  [matroskaElements.FlagLacing]: flagLacing,\n  [matroskaElements.Tags]: tags,\n  [matroskaElements.Tag]: tagSegment,\n  [matroskaElements.TrackNumber]: trackNumber,\n  [matroskaElements.TrackUID]: trackUID,\n  [matroskaElements.Colour]: color,\n  [matroskaElements.Language]: language,\n  [matroskaElements.DefaultDuration]: defaultDuration,\n  [matroskaElements.CodecPrivate]: codecPrivate,\n  [matroskaElements.BlockDuration]: blockDurationSegment,\n  [matroskaElements.BlockAdditions]: blockAdditionsSegment,\n  [matroskaElements.MaxBlockAdditionID]: maxBlockAdditionIdSegment,\n  [matroskaElements.Audio]: audioSegment,\n  [matroskaElements.Video]: videoSegment,\n  [matroskaElements.FlagDefault]: flagDefault,\n  [matroskaElements.ReferenceBlock]: referenceBlock,\n  [matroskaElements.TrackEntry]: trackEntry,\n  [matroskaElements.Timestamp]: {\n    name: \"Timestamp\",\n    type: \"uint\"\n  },\n  [matroskaElements.Tracks]: tracks,\n  [matroskaElements.Block]: block,\n  [matroskaElements.SimpleBlock]: simpleBlock,\n  [matroskaElements.BlockGroup]: blockGroup,\n  [matroskaElements.Segment]: {\n    name: \"Segment\",\n    type: \"children\"\n  },\n  [matroskaElements.Cluster]: {\n    name: \"Cluster\",\n    type: \"children\"\n  },\n  [matroskaElements.TransferCharacteristics]: transferCharacteristics,\n  [matroskaElements.MatrixCoefficients]: matrixCoefficients,\n  [matroskaElements.Primaries]: primaries,\n  [matroskaElements.Range]: range,\n  [matroskaElements.ChromaSitingHorz]: ChromaSitingHorz,\n  [matroskaElements.ChromaSitingVert]: ChromaSitingVert\n};\n\n// src/file-types/detect-file-type.ts\nvar webmPattern = new Uint8Array([26, 69, 223, 163]);\nvar matchesPattern = (pattern) => {\n  return (data) => {\n    return pattern.every((value, index) => data[index] === value);\n  };\n};\nvar isRiffAvi2 = (data) => {\n  const riffPattern = new Uint8Array([82, 73, 70, 70]);\n  if (!matchesPattern(riffPattern)(data.subarray(0, 4))) {\n    return false;\n  }\n  const fileType = data.subarray(8, 12);\n  const aviPattern = new Uint8Array([65, 86, 73, 32]);\n  return matchesPattern(aviPattern)(fileType);\n};\nvar isRiffWave = (data) => {\n  const riffPattern = new Uint8Array([82, 73, 70, 70]);\n  if (!matchesPattern(riffPattern)(data.subarray(0, 4))) {\n    return false;\n  }\n  const fileType = data.subarray(8, 12);\n  const wavePattern = new Uint8Array([87, 65, 86, 69]);\n  return matchesPattern(wavePattern)(fileType);\n};\nvar isWebm = (data) => {\n  return matchesPattern(webmPattern)(data.subarray(0, 4));\n};\nvar isIsoBaseMedia = (data) => {\n  const isoBaseMediaMp4Pattern = new TextEncoder().encode(\"ftyp\");\n  return matchesPattern(isoBaseMediaMp4Pattern)(data.subarray(4, 8));\n};\nvar isTransportStream = (data) => {\n  return data[0] === 71 && data[188] === 71;\n};\nvar isMp3 = (data) => {\n  const mpegPattern = new Uint8Array([255, 243]);\n  const mpegPattern2 = new Uint8Array([255, 251]);\n  const id3v4Pattern = new Uint8Array([73, 68, 51, 4]);\n  const id3v3Pattern = new Uint8Array([73, 68, 51, 3]);\n  const id3v2Pattern = new Uint8Array([73, 68, 51, 2]);\n  const subarray = data.subarray(0, 4);\n  return matchesPattern(mpegPattern)(subarray) || matchesPattern(mpegPattern2)(subarray) || matchesPattern(id3v4Pattern)(subarray) || matchesPattern(id3v3Pattern)(subarray) || matchesPattern(id3v2Pattern)(subarray);\n};\nvar isAac = (data) => {\n  const aacPattern = new Uint8Array([255, 241]);\n  return matchesPattern(aacPattern)(data.subarray(0, 2));\n};\nvar isFlac = (data) => {\n  const flacPattern = new Uint8Array([102, 76, 97, 67]);\n  return matchesPattern(flacPattern)(data.subarray(0, 4));\n};\nvar isM3u = (data) => {\n  return new TextDecoder(\"utf-8\").decode(data.slice(0, 7)) === \"#EXTM3U\";\n};\n\n// src/file-types/bmp.ts\nfunction getBmpDimensions(bmpData) {\n  if (bmpData.length < 26) {\n    return null;\n  }\n  const view = new DataView(bmpData.buffer, bmpData.byteOffset);\n  return {\n    width: view.getUint32(18, true),\n    height: Math.abs(view.getInt32(22, true))\n  };\n}\nvar isBmp = (data) => {\n  const bmpPattern = new Uint8Array([66, 77]);\n  if (matchesPattern(bmpPattern)(data.subarray(0, 2))) {\n    const bmp = getBmpDimensions(data);\n    return { dimensions: bmp, type: \"bmp\" };\n  }\n  return null;\n};\n\n// src/file-types/gif.ts\nvar getGifDimensions = (data) => {\n  const view = new DataView(data.buffer, data.byteOffset);\n  const width = view.getUint16(6, true);\n  const height = view.getUint16(8, true);\n  return { width, height };\n};\nvar isGif = (data) => {\n  const gifPattern = new Uint8Array([71, 73, 70, 56]);\n  if (matchesPattern(gifPattern)(data.subarray(0, 4))) {\n    return { type: \"gif\", dimensions: getGifDimensions(data) };\n  }\n  return null;\n};\n\n// src/file-types/jpeg.ts\nfunction getJpegDimensions(data) {\n  let offset = 0;\n  function readUint16BE(o) {\n    return data[o] << 8 | data[o + 1];\n  }\n  if (readUint16BE(offset) !== 65496) {\n    return null;\n  }\n  offset += 2;\n  while (offset < data.length) {\n    if (data[offset] === 255) {\n      const marker = data[offset + 1];\n      if (marker === 192 || marker === 194) {\n        const height = readUint16BE(offset + 5);\n        const width = readUint16BE(offset + 7);\n        return { width, height };\n      }\n      const length = readUint16BE(offset + 2);\n      offset += length + 2;\n    } else {\n      offset++;\n    }\n  }\n  return null;\n}\nvar isJpeg = (data) => {\n  const jpegPattern = new Uint8Array([255, 216]);\n  const jpeg = matchesPattern(jpegPattern)(data.subarray(0, 2));\n  if (!jpeg) {\n    return null;\n  }\n  const dim = getJpegDimensions(data);\n  return { dimensions: dim, type: \"jpeg\" };\n};\n\n// src/file-types/pdf.ts\nvar isPdf = (data) => {\n  if (data.length < 4) {\n    return null;\n  }\n  const pdfPattern = new Uint8Array([37, 80, 68, 70]);\n  return matchesPattern(pdfPattern)(data.subarray(0, 4)) ? { type: \"pdf\" } : null;\n};\n\n// src/file-types/png.ts\nfunction getPngDimensions(pngData) {\n  if (pngData.length < 24) {\n    return null;\n  }\n  const view = new DataView(pngData.buffer, pngData.byteOffset);\n  const pngSignature = [137, 80, 78, 71, 13, 10, 26, 10];\n  for (let i = 0;i < 8; i++) {\n    if (pngData[i] !== pngSignature[i]) {\n      return null;\n    }\n  }\n  return {\n    width: view.getUint32(16, false),\n    height: view.getUint32(20, false)\n  };\n}\nvar isPng = (data) => {\n  const pngPattern = new Uint8Array([137, 80, 78, 71]);\n  if (matchesPattern(pngPattern)(data.subarray(0, 4))) {\n    const png = getPngDimensions(data);\n    return { dimensions: png, type: \"png\" };\n  }\n  return null;\n};\n\n// src/file-types/webp.ts\nfunction getWebPDimensions(bytes) {\n  if (bytes.length < 30) {\n    return null;\n  }\n  if (bytes[0] !== 82 || bytes[1] !== 73 || bytes[2] !== 70 || bytes[3] !== 70 || bytes[8] !== 87 || bytes[9] !== 69 || bytes[10] !== 66 || bytes[11] !== 80) {\n    return null;\n  }\n  if (bytes[12] === 86 && bytes[13] === 80 && bytes[14] === 56) {\n    if (bytes[15] === 32) {\n      return {\n        width: bytes[26] | bytes[27] << 8 & 16383,\n        height: bytes[28] | bytes[29] << 8 & 16383\n      };\n    }\n  }\n  if (bytes[12] === 86 && bytes[13] === 80 && bytes[14] === 56 && bytes[15] === 76) {\n    return {\n      width: 1 + (bytes[21] | (bytes[22] & 63) << 8),\n      height: 1 + ((bytes[22] & 192) >> 6 | bytes[23] << 2 | (bytes[24] & 15) << 10)\n    };\n  }\n  if (bytes[12] === 86 && bytes[13] === 80 && bytes[14] === 56 && bytes[15] === 88) {\n    return {\n      width: 1 + (bytes[24] | bytes[25] << 8 | bytes[26] << 16),\n      height: 1 + (bytes[27] | bytes[28] << 8 | bytes[29] << 16)\n    };\n  }\n  return null;\n}\nvar isWebp = (data) => {\n  const webpPattern = new Uint8Array([82, 73, 70, 70]);\n  if (matchesPattern(webpPattern)(data.subarray(0, 4))) {\n    return {\n      type: \"webp\",\n      dimensions: getWebPDimensions(data)\n    };\n  }\n  return null;\n};\n\n// src/file-types/index.ts\nvar detectFileType = (data) => {\n  if (isRiffWave(data)) {\n    return { type: \"wav\" };\n  }\n  if (isRiffAvi2(data)) {\n    return { type: \"riff\" };\n  }\n  if (isAac(data)) {\n    return { type: \"aac\" };\n  }\n  if (isFlac(data)) {\n    return { type: \"flac\" };\n  }\n  if (isM3u(data)) {\n    return { type: \"m3u\" };\n  }\n  const webp = isWebp(data);\n  if (webp) {\n    return webp;\n  }\n  if (isWebm(data)) {\n    return { type: \"webm\" };\n  }\n  if (isIsoBaseMedia(data)) {\n    return { type: \"iso-base-media\" };\n  }\n  if (isTransportStream(data)) {\n    return { type: \"transport-stream\" };\n  }\n  if (isMp3(data)) {\n    return { type: \"mp3\" };\n  }\n  const gif = isGif(data);\n  if (gif) {\n    return gif;\n  }\n  const png = isPng(data);\n  if (png) {\n    return png;\n  }\n  const pdf = isPdf(data);\n  if (pdf) {\n    return pdf;\n  }\n  const bmp = isBmp(data);\n  if (bmp) {\n    return bmp;\n  }\n  const jpeg = isJpeg(data);\n  if (jpeg) {\n    return jpeg;\n  }\n  return { type: \"unknown\" };\n};\n\n// src/iterator/polyfilled-arraybuffer.ts\nclass ResizableBuffer {\n  buffer;\n  uintarray;\n  constructor(buffer) {\n    this.buffer = buffer;\n    this.uintarray = new Uint8Array(buffer);\n  }\n  resize(newLength) {\n    if (typeof this.buffer.resize === \"function\") {\n      this.buffer.resize(newLength);\n    } else {\n      const newBuffer = new ArrayBuffer(newLength);\n      new Uint8Array(newBuffer).set(new Uint8Array(this.buffer).subarray(0, Math.min(this.buffer.byteLength, newLength)));\n      this.buffer = newBuffer;\n      this.uintarray = new Uint8Array(newBuffer);\n    }\n  }\n}\n\n// src/iterator/buffer-manager.ts\nvar makeBufferWithMaxBytes = (initialData, maxBytes) => {\n  const maxByteLength = Math.min(maxBytes, 2 ** 31);\n  try {\n    const buf = new ArrayBuffer(initialData.byteLength, {\n      maxByteLength\n    });\n    return new ResizableBuffer(buf);\n  } catch (e) {\n    if (e instanceof RangeError && maxBytes > 2 ** 27) {\n      return new ResizableBuffer(new ArrayBuffer(initialData.byteLength, {\n        maxByteLength: 2 ** 27\n      }));\n    }\n    throw e;\n  }\n};\nvar bufferManager = ({\n  initialData,\n  maxBytes,\n  counter,\n  logLevel\n}) => {\n  const buf = makeBufferWithMaxBytes(initialData, maxBytes);\n  if (!buf.buffer.resize) {\n    Log.warn(logLevel, \"`ArrayBuffer.resize` is not supported in this Runtime. Using slow polyfill.\");\n  }\n  buf.uintarray.set(initialData);\n  let view = new DataView(buf.uintarray.buffer);\n  const destroy = () => {\n    buf.uintarray = new Uint8Array(0);\n    buf.resize(0);\n  };\n  const flushBytesRead = (force, mode) => {\n    const bytesToRemove = counter.getDiscardedOffset();\n    if (bytesToRemove < 3000000 && !force) {\n      return { bytesRemoved: 0, removedData: null };\n    }\n    if (view.byteLength < bytesToRemove && !force) {\n      return { bytesRemoved: 0, removedData: null };\n    }\n    counter.discardBytes(bytesToRemove);\n    const removedData = mode === \"download\" ? buf.uintarray.slice(0, bytesToRemove) : null;\n    const newData = buf.uintarray.slice(bytesToRemove);\n    buf.uintarray.set(newData);\n    buf.resize(newData.byteLength);\n    view = new DataView(buf.uintarray.buffer);\n    return { bytesRemoved: bytesToRemove, removedData };\n  };\n  const skipTo = (offset) => {\n    const becomesSmaller = offset < counter.getOffset();\n    if (becomesSmaller) {\n      const toDecrement = counter.getOffset() - offset;\n      if (toDecrement > counter.getDiscardedOffset()) {\n        throw new Error(\"Cannot count backwards, data has already been flushed\");\n      }\n      counter.decrement(toDecrement);\n    }\n    const currentOffset = counter.getOffset();\n    counter.increment(offset - currentOffset);\n  };\n  const addData = (newData) => {\n    const oldLength = buf.buffer.byteLength;\n    const newLength = oldLength + newData.byteLength;\n    if (newLength < oldLength) {\n      throw new Error(\"Cannot decrement size\");\n    }\n    if (newLength > (maxBytes ?? Infinity)) {\n      throw new Error(`Exceeded maximum byte length ${maxBytes} with ${newLength}`);\n    }\n    buf.resize(newLength);\n    buf.uintarray = new Uint8Array(buf.buffer);\n    buf.uintarray.set(newData, oldLength);\n    view = new DataView(buf.uintarray.buffer);\n  };\n  const replaceData = (newData, seekTo) => {\n    buf.resize(newData.byteLength);\n    buf.uintarray = new Uint8Array(buf.buffer);\n    buf.uintarray.set(newData);\n    view = new DataView(buf.uintarray.buffer);\n    counter.setDiscardedOffset(seekTo);\n    counter.decrement(counter.getOffset());\n    counter.increment(seekTo);\n  };\n  return {\n    getView: () => view,\n    getUint8Array: () => buf.uintarray,\n    destroy,\n    addData,\n    skipTo,\n    removeBytesRead: flushBytesRead,\n    replaceData\n  };\n};\n\n// src/iterator/offset-counter.ts\nvar makeOffsetCounter = (initial) => {\n  let offset = initial;\n  let discardedBytes = 0;\n  return {\n    getOffset: () => offset,\n    discardBytes: (bytes) => {\n      discardedBytes += bytes;\n    },\n    increment: (bytes) => {\n      if (bytes < 0) {\n        throw new Error(\"Cannot increment by a negative amount: \" + bytes);\n      }\n      offset += bytes;\n    },\n    getDiscardedBytes: () => discardedBytes,\n    setDiscardedOffset: (bytes) => {\n      discardedBytes = bytes;\n    },\n    getDiscardedOffset: () => offset - discardedBytes,\n    decrement: (bytes) => {\n      if (bytes < 0) {\n        throw new Error(\"Cannot decrement by a negative amount: \" + bytes);\n      }\n      offset -= bytes;\n    }\n  };\n};\n\n// src/iterator/buffer-iterator.ts\nvar getArrayBufferIterator = ({\n  initialData,\n  maxBytes,\n  logLevel\n}) => {\n  const counter = makeOffsetCounter(0);\n  const {\n    getUint8Array,\n    getView,\n    addData,\n    destroy,\n    removeBytesRead,\n    skipTo,\n    replaceData\n  } = bufferManager({ initialData, maxBytes, counter, logLevel });\n  const startCheckpoint = () => {\n    const checkpoint = counter.getOffset();\n    return {\n      returnToCheckpoint: () => {\n        counter.decrement(counter.getOffset() - checkpoint);\n      }\n    };\n  };\n  const getSlice = (amount) => {\n    const value = getUint8Array().slice(counter.getDiscardedOffset(), counter.getDiscardedOffset() + amount);\n    counter.increment(value.length);\n    return value;\n  };\n  const discard = (length) => {\n    counter.increment(length);\n  };\n  const readUntilNullTerminator = () => {\n    const bytes = [];\n    let byte;\n    while ((byte = getUint8()) !== 0) {\n      bytes.push(byte);\n    }\n    counter.decrement(1);\n    return new TextDecoder().decode(new Uint8Array(bytes));\n  };\n  const readUntilLineEnd = () => {\n    const bytes = [];\n    while (true) {\n      if (bytesRemaining() === 0) {\n        return null;\n      }\n      const byte = getUint8();\n      bytes.push(byte);\n      if (byte === 10) {\n        break;\n      }\n    }\n    const str = new TextDecoder().decode(new Uint8Array(bytes)).trim();\n    return str;\n  };\n  const getUint8 = () => {\n    const val = getView().getUint8(counter.getDiscardedOffset());\n    counter.increment(1);\n    return val;\n  };\n  const getEightByteNumber = (littleEndian = false) => {\n    if (littleEndian) {\n      const one = getUint8();\n      const two = getUint8();\n      const three = getUint8();\n      const four = getUint8();\n      const five = getUint8();\n      const six = getUint8();\n      const seven = getUint8();\n      const eight = getUint8();\n      return (eight << 56 | seven << 48 | six << 40 | five << 32 | four << 24 | three << 16 | two << 8 | one) >>> 0;\n    }\n    function byteArrayToBigInt(byteArray) {\n      let result = BigInt(0);\n      for (let i = 0;i < byteArray.length; i++) {\n        result = (result << BigInt(8)) + BigInt(byteArray[i]);\n      }\n      return result;\n    }\n    const bigInt = byteArrayToBigInt([\n      getUint8(),\n      getUint8(),\n      getUint8(),\n      getUint8(),\n      getUint8(),\n      getUint8(),\n      getUint8(),\n      getUint8()\n    ]);\n    return Number(bigInt);\n  };\n  const getFourByteNumber = () => {\n    const unsigned = getUint8() << 24 | getUint8() << 16 | getUint8() << 8 | getUint8();\n    return unsigned >>> 0;\n  };\n  const getPaddedFourByteNumber = () => {\n    let lastInt = 128;\n    while (lastInt = getUint8(), lastInt === 128) {}\n    return lastInt;\n  };\n  const getUint32 = () => {\n    const val = getView().getUint32(counter.getDiscardedOffset());\n    counter.increment(4);\n    return val;\n  };\n  const getSyncSafeInt32 = () => {\n    const val = getView().getUint32(counter.getDiscardedOffset());\n    counter.increment(4);\n    return (val & 2130706432) >> 3 | (val & 8323072) >> 2 | (val & 32512) >> 1 | val & 127;\n  };\n  const getUint64 = (littleEndian = false) => {\n    const val = getView().getBigUint64(counter.getDiscardedOffset(), littleEndian);\n    counter.increment(8);\n    return val;\n  };\n  const getInt64 = (littleEndian = false) => {\n    const val = getView().getBigInt64(counter.getDiscardedOffset(), littleEndian);\n    counter.increment(8);\n    return val;\n  };\n  const startBox = (size) => {\n    const startOffset = counter.getOffset();\n    return {\n      discardRest: () => discard(size - (counter.getOffset() - startOffset)),\n      expectNoMoreBytes: () => {\n        const remaining = size - (counter.getOffset() - startOffset);\n        if (remaining !== 0) {\n          throw new Error(\"expected 0 bytes, got \" + remaining);\n        }\n      }\n    };\n  };\n  const getUint32Le = () => {\n    const val = getView().getUint32(counter.getDiscardedOffset(), true);\n    counter.increment(4);\n    return val;\n  };\n  const getInt32Le = () => {\n    const val = getView().getInt32(counter.getDiscardedOffset(), true);\n    counter.increment(4);\n    return val;\n  };\n  const getInt32 = () => {\n    const val = getView().getInt32(counter.getDiscardedOffset());\n    counter.increment(4);\n    return val;\n  };\n  const bytesRemaining = () => {\n    return getUint8Array().byteLength - counter.getDiscardedOffset();\n  };\n  const readExpGolomb = () => {\n    if (!bitReadingMode) {\n      throw new Error(\"Not in bit reading mode\");\n    }\n    let zerosCount = 0;\n    while (getBits(1) === 0) {\n      zerosCount++;\n    }\n    let suffix = 0;\n    for (let i = 0;i < zerosCount; i++) {\n      suffix = suffix << 1 | getBits(1);\n    }\n    return (1 << zerosCount) - 1 + suffix;\n  };\n  const peekB = (length) => {\n    Log.info(\"info\", [...getSlice(length)].map((b) => b.toString(16).padStart(2, \"0\")));\n    counter.decrement(length);\n  };\n  const peekD = (length) => {\n    Log.info(\"info\", [...getSlice(length)].map((b) => b.toString(16).padStart(2, \"0\")));\n    counter.decrement(length);\n  };\n  const leb128 = () => {\n    let result = 0;\n    let shift = 0;\n    let byte;\n    do {\n      byte = getBits(8);\n      result |= (byte & 127) << shift;\n      shift += 7;\n    } while (byte >= 128);\n    return result;\n  };\n  let bitIndex = 0;\n  const stopReadingBits = () => {\n    bitIndex = 0;\n    bitReadingMode = false;\n  };\n  let byteToShift = 0;\n  let bitReadingMode = false;\n  const startReadingBits = () => {\n    bitReadingMode = true;\n    byteToShift = getUint8();\n  };\n  const getFlacCodecNumber = () => {\n    let ones = 0;\n    let bits = 0;\n    while ((++bits || true) && getBits(1) === 1) {\n      ones++;\n    }\n    if (ones === 0) {\n      return getBits(7);\n    }\n    const bitArray = [];\n    const firstByteBits = 8 - ones - 1;\n    for (let i = 0;i < firstByteBits; i++) {\n      bitArray.unshift(getBits(1));\n    }\n    const extraBytes = ones - 1;\n    for (let i = 0;i < extraBytes; i++) {\n      for (let j = 0;j < 8; j++) {\n        const val = getBits(1);\n        if (j < 2) {\n          continue;\n        }\n        bitArray.unshift(val);\n      }\n    }\n    const encoded = bitArray.reduce((acc, bit, index) => {\n      return acc | bit << index;\n    }, 0);\n    return encoded;\n  };\n  const getBits = (bits) => {\n    let result = 0;\n    let bitsCollected = 0;\n    while (bitsCollected < bits) {\n      if (bitIndex >= 8) {\n        bitIndex = 0;\n        byteToShift = getUint8();\n      }\n      const remainingBitsInByte = 8 - bitIndex;\n      const bitsToReadNow = Math.min(bits - bitsCollected, remainingBitsInByte);\n      const mask = (1 << bitsToReadNow) - 1;\n      const shift = remainingBitsInByte - bitsToReadNow;\n      result <<= bitsToReadNow;\n      result |= byteToShift >> shift & mask;\n      bitsCollected += bitsToReadNow;\n      bitIndex += bitsToReadNow;\n    }\n    return result;\n  };\n  return {\n    startReadingBits,\n    stopReadingBits,\n    skipTo,\n    addData,\n    counter,\n    peekB,\n    peekD,\n    getBits,\n    bytesRemaining,\n    leb128,\n    removeBytesRead,\n    discard,\n    getEightByteNumber,\n    getFourByteNumber,\n    getSlice,\n    getAtom: () => {\n      const atom = getSlice(4);\n      return new TextDecoder().decode(atom);\n    },\n    detectFileType: () => {\n      return detectFileType(getUint8Array());\n    },\n    getPaddedFourByteNumber,\n    getMatroskaSegmentId: () => {\n      if (bytesRemaining() === 0) {\n        return null;\n      }\n      const first = getSlice(1);\n      const firstOneString = `0x${Array.from(new Uint8Array(first)).map((b) => {\n        return b.toString(16).padStart(2, \"0\");\n      }).join(\"\")}`;\n      if (knownIdsWithOneLength.includes(firstOneString)) {\n        return firstOneString;\n      }\n      if (bytesRemaining() === 0) {\n        return null;\n      }\n      const firstTwo = getSlice(1);\n      const firstTwoString = `${firstOneString}${Array.from(new Uint8Array(firstTwo)).map((b) => {\n        return b.toString(16).padStart(2, \"0\");\n      }).join(\"\")}`;\n      if (knownIdsWithTwoLength.includes(firstTwoString)) {\n        return firstTwoString;\n      }\n      if (bytesRemaining() === 0) {\n        return null;\n      }\n      const firstThree = getSlice(1);\n      const firstThreeString = `${firstTwoString}${Array.from(new Uint8Array(firstThree)).map((b) => {\n        return b.toString(16).padStart(2, \"0\");\n      }).join(\"\")}`;\n      if (knownIdsWithThreeLength.includes(firstThreeString)) {\n        return firstThreeString;\n      }\n      if (bytesRemaining() === 0) {\n        return null;\n      }\n      const segmentId = getSlice(1);\n      return `${firstThreeString}${Array.from(new Uint8Array(segmentId)).map((b) => {\n        return b.toString(16).padStart(2, \"0\");\n      }).join(\"\")}`;\n    },\n    getVint: () => {\n      if (bytesRemaining() === 0) {\n        return null;\n      }\n      const firstByte = getUint8();\n      const totalLength = firstByte;\n      if (totalLength === 0) {\n        return 0;\n      }\n      let actualLength = 0;\n      while ((totalLength >> 7 - actualLength & 1) === 0) {\n        actualLength++;\n      }\n      if (bytesRemaining() < actualLength) {\n        return null;\n      }\n      const slice = getSlice(actualLength);\n      const d = [firstByte, ...Array.from(new Uint8Array(slice))];\n      actualLength += 1;\n      let value = 0;\n      value = totalLength & 255 >> actualLength;\n      for (let i = 1;i < actualLength; i++) {\n        value = value << 8 | d[i];\n      }\n      if (value === -1) {\n        return Infinity;\n      }\n      return value;\n    },\n    getUint8,\n    getEBML: () => {\n      const val = getUint8();\n      const actualValue = val & 127;\n      return actualValue;\n    },\n    getInt8: () => {\n      const val = getView().getInt8(counter.getDiscardedOffset());\n      counter.increment(1);\n      return val;\n    },\n    getUint16: () => {\n      const val = getView().getUint16(counter.getDiscardedOffset());\n      counter.increment(2);\n      return val;\n    },\n    getUint16Le: () => {\n      const val = getView().getUint16(counter.getDiscardedOffset(), true);\n      counter.increment(2);\n      return val;\n    },\n    getUint24: () => {\n      const val1 = getView().getUint8(counter.getDiscardedOffset());\n      const val2 = getView().getUint8(counter.getDiscardedOffset() + 1);\n      const val3 = getView().getUint8(counter.getDiscardedOffset() + 2);\n      counter.increment(3);\n      return val1 << 16 | val2 << 8 | val3;\n    },\n    getInt24: () => {\n      const val1 = getView().getInt8(counter.getDiscardedOffset());\n      const val2 = getView().getUint8(counter.getDiscardedOffset() + 1);\n      const val3 = getView().getUint8(counter.getDiscardedOffset() + 2);\n      counter.increment(3);\n      return val1 << 16 | val2 << 8 | val3;\n    },\n    getInt16: () => {\n      const val = getView().getInt16(counter.getDiscardedOffset());\n      counter.increment(2);\n      return val;\n    },\n    getUint32,\n    getUint64,\n    getInt64,\n    getFixedPointUnsigned1616Number: () => {\n      const val = getUint32();\n      return val / 2 ** 16;\n    },\n    getFixedPointSigned1616Number: () => {\n      const val = getInt32();\n      return val / 2 ** 16;\n    },\n    getFixedPointSigned230Number: () => {\n      const val = getInt32();\n      return val / 2 ** 30;\n    },\n    getPascalString: () => {\n      const val = getSlice(32);\n      return [...Array.from(new Uint8Array(val))];\n    },\n    getUint(length) {\n      const bytes = getSlice(length);\n      const numbers = [...Array.from(new Uint8Array(bytes))];\n      return numbers.reduce((acc, byte, index) => acc + (byte << 8 * (numbers.length - index - 1)), 0);\n    },\n    getByteString(length, trimTrailingZeroes) {\n      let bytes = getSlice(length);\n      while (trimTrailingZeroes && bytes[bytes.length - 1] === 0) {\n        bytes = bytes.slice(0, -1);\n      }\n      return new TextDecoder().decode(bytes).trim();\n    },\n    planBytes: (size) => {\n      const currentOffset = counter.getOffset();\n      return {\n        discardRest: () => {\n          const toDiscard = size - (counter.getOffset() - currentOffset);\n          if (toDiscard < 0) {\n            throw new Error(\"read too many bytes\");\n          }\n          return getSlice(toDiscard);\n        }\n      };\n    },\n    getFloat64: () => {\n      const val = getView().getFloat64(counter.getDiscardedOffset());\n      counter.increment(8);\n      return val;\n    },\n    readUntilNullTerminator,\n    getFloat32: () => {\n      const val = getView().getFloat32(counter.getDiscardedOffset());\n      counter.increment(4);\n      return val;\n    },\n    getUint32Le,\n    getInt32Le,\n    getInt32,\n    destroy,\n    startBox,\n    readExpGolomb,\n    startCheckpoint,\n    getFlacCodecNumber,\n    readUntilLineEnd,\n    getSyncSafeInt32,\n    replaceData\n  };\n};\n\n// src/containers/webm/av1-codec-private.ts\nvar parseAv1PrivateData = (data, colrAtom) => {\n  const iterator = getArrayBufferIterator({\n    initialData: data,\n    maxBytes: data.byteLength,\n    logLevel: \"error\"\n  });\n  iterator.startReadingBits();\n  if (iterator.getBits(1) !== 1) {\n    iterator.destroy();\n    throw new Error(\"Expected av1 private data to be version 1\");\n  }\n  const version = iterator.getBits(7);\n  if (version !== 1) {\n    iterator.destroy();\n    throw new Error(`Expected av1 private data to be version 1, got ${version}`);\n  }\n  let str = \"av01.\";\n  const seqProfile = iterator.getBits(3);\n  str += seqProfile;\n  str += \".\";\n  const seq_level_idx = iterator.getBits(5);\n  const seq_tier_0 = iterator.getBits(1);\n  str += String(seq_level_idx).padStart(2, \"0\");\n  str += seq_tier_0 ? \"H\" : \"M\";\n  str += \".\";\n  const high_bitdepth = iterator.getBits(1);\n  const twelve_bit = iterator.getBits(1);\n  const bitDepth2 = high_bitdepth && seqProfile === 2 ? twelve_bit ? 12 : 10 : high_bitdepth ? 10 : 8;\n  str += bitDepth2.toString().padStart(2, \"0\");\n  str += \".\";\n  const mono_chrome = iterator.getBits(1);\n  str += mono_chrome ? \"1\" : \"0\";\n  str += \".\";\n  const subsampling_x = iterator.getBits(1);\n  str += subsampling_x ? \"1\" : \"0\";\n  const subsampling_y = iterator.getBits(1);\n  str += subsampling_y ? \"1\" : \"0\";\n  const chroma_sample_position = iterator.getBits(2);\n  str += subsampling_x && subsampling_y ? chroma_sample_position === 1 ? \"1\" : \"0\" : \"0\";\n  str += \".\";\n  if (colrAtom && colrAtom.colorType === \"transfer-characteristics\") {\n    str += colrAtom.primaries.toString().padStart(2, \"0\");\n    str += \".\";\n    str += colrAtom.transfer.toString().padStart(2, \"0\");\n    str += \".\";\n    str += colrAtom.matrixIndex.toString().padStart(2, \"0\");\n    str += \".\";\n    str += colrAtom.fullRangeFlag ? \"1\" : \"0\";\n  } else {\n    str += \"01\";\n    str += \".\";\n    str += \"01\";\n    str += \".\";\n    str += \"01\";\n    str += \".\";\n    str += \"0\";\n  }\n  const suffix = \".0.110.01.01.01.0\";\n  if (str.endsWith(suffix)) {\n    str = str.slice(0, -suffix.length);\n  }\n  iterator.destroy();\n  return str;\n};\n\n// src/get-video-codec.ts\nvar getVideoCodec = (state) => {\n  const track = getTracks(state, true);\n  return track.find((t) => t.type === \"video\")?.codecEnum ?? null;\n};\nvar hasVideoCodec = (state) => {\n  return getHasTracks(state, true);\n};\nvar getVideoPrivateData = (trakBox) => {\n  const videoSample = getStsdVideoConfig(trakBox);\n  const avccBox = getAvccBox(trakBox);\n  const hvccBox = getHvccBox(trakBox);\n  const av1cBox = getAv1CBox(trakBox);\n  if (!videoSample) {\n    return null;\n  }\n  if (avccBox) {\n    return { type: \"avc-sps-pps\", data: avccBox.privateData };\n  }\n  if (hvccBox) {\n    return { type: \"hvcc-data\", data: hvccBox.privateData };\n  }\n  if (av1cBox) {\n    return { type: \"av1c-data\", data: av1cBox.privateData };\n  }\n  return null;\n};\nvar getIsoBmColrConfig = (trakBox) => {\n  const videoSample = getStsdVideoConfig(trakBox);\n  if (!videoSample) {\n    return null;\n  }\n  const colrAtom = getColrBox(videoSample);\n  if (!colrAtom) {\n    return null;\n  }\n  if (colrAtom.colorType !== \"transfer-characteristics\") {\n    return null;\n  }\n  return {\n    fullRange: colrAtom.fullRangeFlag,\n    matrix: getMatrixCoefficientsFromIndex(colrAtom.matrixIndex),\n    primaries: getPrimariesFromIndex(colrAtom.primaries),\n    transfer: getTransferCharacteristicsFromIndex(colrAtom.transfer)\n  };\n};\nvar getVideoCodecString = (trakBox) => {\n  const videoSample = getStsdVideoConfig(trakBox);\n  const avccBox = getAvccBox(trakBox);\n  const hvccBox = getHvccBox(trakBox);\n  const av1cBox = getAv1CBox(trakBox);\n  if (!videoSample) {\n    return null;\n  }\n  if (avccBox) {\n    return `${videoSample.format}.${avccBox.configurationString}`;\n  }\n  if (hvccBox) {\n    return `${videoSample.format}.${hvccBox.configurationString}`;\n  }\n  if (av1cBox) {\n    const colrAtom = getColrBox(videoSample);\n    return parseAv1PrivateData(av1cBox.privateData, colrAtom);\n  }\n  return videoSample.format;\n};\n\n// src/webcodecs-timescale.ts\nvar WEBCODECS_TIMESCALE = 1e6;\n\n// src/containers/iso-base-media/color-to-webcodecs-colors.ts\nvar mediaParserAdvancedColorToWebCodecsColor = (color2) => {\n  return {\n    transfer: color2.transfer,\n    matrix: color2.matrix,\n    primaries: color2.primaries,\n    fullRange: color2.fullRange\n  };\n};\n\n// src/aac-codecprivate.ts\nvar getSampleRateFromSampleFrequencyIndex = (samplingFrequencyIndex) => {\n  switch (samplingFrequencyIndex) {\n    case 0:\n      return 96000;\n    case 1:\n      return 88200;\n    case 2:\n      return 64000;\n    case 3:\n      return 48000;\n    case 4:\n      return 44100;\n    case 5:\n      return 32000;\n    case 6:\n      return 24000;\n    case 7:\n      return 22050;\n    case 8:\n      return 16000;\n    case 9:\n      return 12000;\n    case 10:\n      return 11025;\n    case 11:\n      return 8000;\n    case 12:\n      return 7350;\n    default:\n      throw new Error(`Unexpected sampling frequency index ${samplingFrequencyIndex}`);\n  }\n};\nvar getConfigForSampleRate = (sampleRate) => {\n  if (sampleRate === 96000) {\n    return 0;\n  }\n  if (sampleRate === 88200) {\n    return 1;\n  }\n  if (sampleRate === 64000) {\n    return 2;\n  }\n  if (sampleRate === 48000) {\n    return 3;\n  }\n  if (sampleRate === 44100) {\n    return 4;\n  }\n  if (sampleRate === 32000) {\n    return 5;\n  }\n  if (sampleRate === 24000) {\n    return 6;\n  }\n  if (sampleRate === 22050) {\n    return 7;\n  }\n  if (sampleRate === 16000) {\n    return 8;\n  }\n  if (sampleRate === 12000) {\n    return 9;\n  }\n  if (sampleRate === 11025) {\n    return 10;\n  }\n  if (sampleRate === 8000) {\n    return 11;\n  }\n  if (sampleRate === 7350) {\n    return 12;\n  }\n  throw new Error(`Unexpected sample rate ${sampleRate}`);\n};\nvar createAacCodecPrivate = ({\n  audioObjectType,\n  sampleRate,\n  channelConfiguration,\n  codecPrivate: codecPrivate2\n}) => {\n  if (codecPrivate2 !== null && codecPrivate2.length > 2) {\n    return codecPrivate2;\n  }\n  const bits = `${audioObjectType.toString(2).padStart(5, \"0\")}${getConfigForSampleRate(sampleRate).toString(2).padStart(4, \"0\")}${channelConfiguration.toString(2).padStart(4, \"0\")}000`;\n  if (bits.length !== 16) {\n    throw new Error(\"Invalid AAC codec private \" + bits.length);\n  }\n  if (channelConfiguration === 0 || channelConfiguration > 7) {\n    throw new Error(\"Invalid channel configuration \" + channelConfiguration);\n  }\n  const firstByte = parseInt(bits.slice(0, 8), 2);\n  const secondByte = parseInt(bits.slice(8, 16), 2);\n  return new Uint8Array([firstByte, secondByte]);\n};\nvar parseAacCodecPrivate = (bytes) => {\n  if (bytes.length < 2) {\n    throw new Error(\"Invalid AAC codec private length\");\n  }\n  const bits = [...bytes].map((b) => b.toString(2).padStart(8, \"0\")).join(\"\");\n  let offset = 0;\n  const audioObjectType = parseInt(bits.slice(offset, offset + 5), 2);\n  offset += 5;\n  const samplingFrequencyIndex = parseInt(bits.slice(offset, offset + 4), 2);\n  offset += 4;\n  if (samplingFrequencyIndex === 15) {\n    offset += 24;\n  }\n  const channelConfiguration = parseInt(bits.slice(offset, offset + 4), 2);\n  offset += 4;\n  if (audioObjectType === 5) {\n    const extensionSamplingFrequencyIndex = parseInt(bits.slice(offset, offset + 4), 2);\n    offset += 4;\n    const newAudioObjectType = parseInt(bits.slice(offset, offset + 5), 2);\n    offset += 5;\n    return {\n      audioObjectType: newAudioObjectType,\n      sampleRate: getSampleRateFromSampleFrequencyIndex(extensionSamplingFrequencyIndex),\n      channelConfiguration\n    };\n  }\n  const sampleRate = getSampleRateFromSampleFrequencyIndex(samplingFrequencyIndex);\n  return {\n    audioObjectType,\n    sampleRate,\n    channelConfiguration\n  };\n};\nvar mapAudioObjectTypeToCodecString = (audioObjectType) => {\n  switch (audioObjectType) {\n    case 1:\n      return \"mp4a.40.2\";\n    case 2:\n      return \"mp4a.40.5\";\n    case 3:\n      return \"mp4a.40.29\";\n    case 4:\n      return \"mp4a.40.1\";\n    case 5:\n      return \"mp4a.40.3\";\n    case 6:\n      return \"mp4a.40.4\";\n    case 17:\n      return \"mp4a.40.17\";\n    case 23:\n      return \"mp4a.40.23\";\n    default:\n      throw new Error(`Unexpected audio object type ${audioObjectType}`);\n  }\n};\n\n// src/containers/iso-base-media/get-actual-number-of-channels.ts\nvar getActualDecoderParameters = ({\n  audioCodec,\n  codecPrivate: codecPrivate2,\n  numberOfChannels,\n  sampleRate\n}) => {\n  if (audioCodec !== \"aac\") {\n    return {\n      numberOfChannels,\n      sampleRate,\n      codecPrivate: codecPrivate2\n    };\n  }\n  if (codecPrivate2 === null) {\n    return { numberOfChannels, sampleRate, codecPrivate: codecPrivate2 };\n  }\n  if (codecPrivate2.type !== \"aac-config\") {\n    throw new Error(\"Expected AAC codec private data\");\n  }\n  const parsed = parseAacCodecPrivate(codecPrivate2.data);\n  const actual = createAacCodecPrivate({\n    ...parsed,\n    codecPrivate: codecPrivate2.data\n  });\n  return {\n    numberOfChannels: parsed.channelConfiguration,\n    sampleRate: parsed.sampleRate,\n    codecPrivate: { type: \"aac-config\", data: actual }\n  };\n};\n\n// src/containers/iso-base-media/get-video-codec-from-iso-track.ts\nvar getVideoCodecFromIsoTrak = (trakBox) => {\n  const stsdBox = getStsdBox(trakBox);\n  if (stsdBox && stsdBox.type === \"stsd-box\") {\n    const videoSample = stsdBox.samples.find((s) => s.type === \"video\");\n    if (videoSample && videoSample.type === \"video\") {\n      if (videoSample.format === \"hvc1\" || videoSample.format === \"hev1\") {\n        return \"h265\";\n      }\n      if (videoSample.format === \"avc1\") {\n        return \"h264\";\n      }\n      if (videoSample.format === \"av01\") {\n        return \"av1\";\n      }\n      if (videoSample.format === \"ap4h\") {\n        return \"prores\";\n      }\n      if (videoSample.format === \"ap4x\") {\n        return \"prores\";\n      }\n      if (videoSample.format === \"apch\") {\n        return \"prores\";\n      }\n      if (videoSample.format === \"apcn\") {\n        return \"prores\";\n      }\n      if (videoSample.format === \"apcs\") {\n        return \"prores\";\n      }\n      if (videoSample.format === \"apco\") {\n        return \"prores\";\n      }\n      if (videoSample.format === \"aprh\") {\n        return \"prores\";\n      }\n      if (videoSample.format === \"aprn\") {\n        return \"prores\";\n      }\n    }\n  }\n  throw new Error(\"Could not find video codec\");\n};\n\n// src/containers/iso-base-media/make-track.ts\nvar makeBaseMediaTrack = (trakBox, startTimeInSeconds) => {\n  const tkhdBox = getTkhdBox(trakBox);\n  const videoDescriptors = getVideoDescriptors(trakBox);\n  const timescaleAndDuration = getTimescaleAndDuration(trakBox);\n  if (!tkhdBox) {\n    throw new Error(\"Expected tkhd box in trak box\");\n  }\n  if (!timescaleAndDuration) {\n    throw new Error(\"Expected timescale and duration in trak box\");\n  }\n  if (trakBoxContainsAudio(trakBox)) {\n    const numberOfChannels = getNumberOfChannelsFromTrak(trakBox);\n    if (numberOfChannels === null) {\n      throw new Error(\"Could not find number of channels\");\n    }\n    const sampleRate = getSampleRate(trakBox);\n    if (sampleRate === null) {\n      throw new Error(\"Could not find sample rate\");\n    }\n    const { codecString, description } = getAudioCodecStringFromTrak(trakBox);\n    const codecPrivate2 = getCodecPrivateFromTrak(trakBox) ?? description ?? null;\n    const codecEnum = getAudioCodecFromTrack(trakBox);\n    const actual = getActualDecoderParameters({\n      audioCodec: codecEnum,\n      codecPrivate: codecPrivate2 ?? null,\n      numberOfChannels,\n      sampleRate\n    });\n    return {\n      type: \"audio\",\n      trackId: tkhdBox.trackId,\n      originalTimescale: timescaleAndDuration.timescale,\n      codec: codecString,\n      numberOfChannels: actual.numberOfChannels,\n      sampleRate: actual.sampleRate,\n      description: actual.codecPrivate?.data ?? undefined,\n      codecData: actual.codecPrivate,\n      codecEnum,\n      startInSeconds: startTimeInSeconds,\n      timescale: WEBCODECS_TIMESCALE\n    };\n  }\n  if (!trakBoxContainsVideo(trakBox)) {\n    return {\n      type: \"other\",\n      trackId: tkhdBox.trackId,\n      originalTimescale: timescaleAndDuration.timescale,\n      trakBox,\n      startInSeconds: startTimeInSeconds,\n      timescale: WEBCODECS_TIMESCALE\n    };\n  }\n  const videoSample = getStsdVideoConfig(trakBox);\n  if (!videoSample) {\n    throw new Error(\"No video sample\");\n  }\n  const sampleAspectRatio = getSampleAspectRatio(trakBox);\n  const aspectRatioApplied = applyAspectRatios({\n    dimensions: videoSample,\n    sampleAspectRatio,\n    displayAspectRatio: getDisplayAspectRatio({\n      sampleAspectRatio,\n      nativeDimensions: videoSample\n    })\n  });\n  const { displayAspectHeight, displayAspectWidth, height, rotation, width } = applyTkhdBox(aspectRatioApplied, tkhdBox);\n  const codec = getVideoCodecString(trakBox);\n  if (!codec) {\n    throw new Error(\"Could not find video codec\");\n  }\n  const privateData = getVideoPrivateData(trakBox);\n  const advancedColor = getIsoBmColrConfig(trakBox) ?? {\n    fullRange: null,\n    matrix: null,\n    primaries: null,\n    transfer: null\n  };\n  const track = {\n    m3uStreamFormat: null,\n    type: \"video\",\n    trackId: tkhdBox.trackId,\n    description: videoDescriptors ?? undefined,\n    originalTimescale: timescaleAndDuration.timescale,\n    codec,\n    sampleAspectRatio: getSampleAspectRatio(trakBox),\n    width,\n    height,\n    codedWidth: videoSample.width,\n    codedHeight: videoSample.height,\n    displayAspectWidth,\n    displayAspectHeight,\n    rotation,\n    codecData: privateData,\n    colorSpace: mediaParserAdvancedColorToWebCodecsColor(advancedColor),\n    advancedColor,\n    codecEnum: getVideoCodecFromIsoTrak(trakBox),\n    fps: getFpsFromMp4TrakBox(trakBox),\n    startInSeconds: startTimeInSeconds,\n    timescale: WEBCODECS_TIMESCALE\n  };\n  return track;\n};\n\n// src/containers/iso-base-media/mdat/get-editlist.ts\nvar findTrackStartTimeInSeconds = ({\n  movieTimeScale,\n  trakBox\n}) => {\n  const elstBox = getElstBox(trakBox);\n  if (!elstBox) {\n    return 0;\n  }\n  const { entries } = elstBox;\n  let dwellTime = 0;\n  for (const entry of entries) {\n    const { editDuration, mediaTime } = entry;\n    if (mediaTime !== -1) {\n      continue;\n    }\n    dwellTime += editDuration;\n  }\n  return dwellTime / movieTimeScale;\n};\n\n// src/containers/avc/codec-string.ts\nvar getCodecStringFromSpsAndPps = (sps) => {\n  return `avc1.${sps.spsData.profile.toString(16).padStart(2, \"0\")}${sps.spsData.compatibility.toString(16).padStart(2, \"0\")}${sps.spsData.level.toString(16).padStart(2, \"0\")}`;\n};\n\n// src/combine-uint8-arrays.ts\nvar combineUint8Arrays = (arrays) => {\n  if (arrays.length === 0) {\n    return new Uint8Array([]);\n  }\n  if (arrays.length === 1) {\n    return arrays[0];\n  }\n  let totalLength = 0;\n  for (const array of arrays) {\n    totalLength += array.length;\n  }\n  const result = new Uint8Array(totalLength);\n  let offset = 0;\n  for (const array of arrays) {\n    result.set(array, offset);\n    offset += array.length;\n  }\n  return result;\n};\n\n// src/truthy.ts\nfunction truthy(value) {\n  return Boolean(value);\n}\n\n// src/containers/avc/create-sps-pps-data.ts\nfunction serializeUint16(value) {\n  const buffer = new ArrayBuffer(2);\n  const view = new DataView(buffer);\n  view.setUint16(0, value);\n  return new Uint8Array(buffer);\n}\nvar createSpsPpsData = (avc1Profile) => {\n  return combineUint8Arrays([\n    new Uint8Array([\n      1,\n      avc1Profile.sps.spsData.profile,\n      avc1Profile.sps.spsData.compatibility,\n      avc1Profile.sps.spsData.level,\n      255,\n      225\n    ]),\n    serializeUint16(avc1Profile.sps.sps.length),\n    avc1Profile.sps.sps,\n    new Uint8Array([1]),\n    serializeUint16(avc1Profile.pps.pps.length),\n    avc1Profile.pps.pps,\n    [66, 77, 88].some((b) => avc1Profile.sps.spsData.profile === b) ? null : new Uint8Array([253, 248, 248, 0])\n  ].filter(truthy));\n};\n\n// src/add-avc-profile-to-track.ts\nvar addAvcProfileToTrack = (track, avc1Profile) => {\n  if (avc1Profile === null) {\n    return track;\n  }\n  return {\n    ...track,\n    codec: getCodecStringFromSpsAndPps(avc1Profile.sps),\n    codecData: { type: \"avc-sps-pps\", data: createSpsPpsData(avc1Profile) },\n    description: undefined\n  };\n};\n\n// src/containers/riff/timescale.ts\nvar MEDIA_PARSER_RIFF_TIMESCALE = 1e6;\n\n// src/containers/riff/get-tracks-from-avi.ts\nvar TO_BE_OVERRIDDEN_LATER = \"to-be-overriden-later\";\nvar getNumberOfTracks = (structure) => {\n  const avihBox = getAvihBox(structure);\n  if (avihBox) {\n    return avihBox.streams;\n  }\n  throw new Error(\"No avih box found\");\n};\nvar makeAviAudioTrack = ({\n  strf,\n  index\n}) => {\n  if (strf.formatTag !== 255) {\n    throw new Error(`Unsupported audio format ${strf.formatTag}`);\n  }\n  return {\n    type: \"audio\",\n    codec: \"mp4a.40.2\",\n    codecData: { type: \"aac-config\", data: new Uint8Array([18, 16]) },\n    codecEnum: \"aac\",\n    description: new Uint8Array([18, 16]),\n    numberOfChannels: strf.numberOfChannels,\n    sampleRate: strf.sampleRate,\n    originalTimescale: MEDIA_PARSER_RIFF_TIMESCALE,\n    trackId: index,\n    startInSeconds: 0,\n    timescale: WEBCODECS_TIMESCALE\n  };\n};\nvar makeAviVideoTrack = ({\n  strh,\n  strf,\n  index\n}) => {\n  if (strh.handler !== \"H264\") {\n    throw new Error(`Unsupported video codec ${strh.handler}`);\n  }\n  return {\n    codecData: null,\n    codec: TO_BE_OVERRIDDEN_LATER,\n    codecEnum: \"h264\",\n    codedHeight: strf.height,\n    codedWidth: strf.width,\n    width: strf.width,\n    height: strf.height,\n    type: \"video\",\n    displayAspectHeight: strf.height,\n    originalTimescale: MEDIA_PARSER_RIFF_TIMESCALE,\n    description: undefined,\n    m3uStreamFormat: null,\n    trackId: index,\n    colorSpace: {\n      fullRange: null,\n      matrix: null,\n      primaries: null,\n      transfer: null\n    },\n    advancedColor: {\n      fullRange: null,\n      matrix: null,\n      primaries: null,\n      transfer: null\n    },\n    displayAspectWidth: strf.width,\n    rotation: 0,\n    sampleAspectRatio: {\n      numerator: 1,\n      denominator: 1\n    },\n    fps: strh.rate / strh.scale,\n    startInSeconds: 0,\n    timescale: WEBCODECS_TIMESCALE\n  };\n};\nvar getTracksFromAvi = (structure, state) => {\n  const tracks2 = [];\n  const boxes = getStrlBoxes(structure);\n  let i = 0;\n  for (const box of boxes) {\n    const strh = getStrhBox(box.children);\n    if (!strh) {\n      continue;\n    }\n    const { strf } = strh;\n    if (strf.type === \"strf-box-video\") {\n      tracks2.push(addAvcProfileToTrack(makeAviVideoTrack({ strh, strf, index: i }), state.riff.getAvcProfile()));\n    } else if (strh.fccType === \"auds\") {\n      tracks2.push(makeAviAudioTrack({ strf, index: i }));\n    } else {\n      throw new Error(`Unsupported track type ${strh.fccType}`);\n    }\n    i++;\n  }\n  return tracks2;\n};\nvar hasAllTracksFromAvi = (state) => {\n  try {\n    const structure = state.structure.getRiffStructure();\n    const numberOfTracks = getNumberOfTracks(structure);\n    const tracks2 = getTracksFromAvi(structure, state);\n    return tracks2.length === numberOfTracks && !tracks2.find((t) => t.type === \"video\" && t.codec === TO_BE_OVERRIDDEN_LATER);\n  } catch {\n    return false;\n  }\n};\n\n// src/containers/transport-stream/traversal.ts\nvar findProgramAssociationTableOrThrow = (structure) => {\n  const box = structure.boxes.find((b) => b.type === \"transport-stream-pat-box\");\n  if (!box) {\n    throw new Error(\"No PAT box found\");\n  }\n  return box;\n};\nvar findProgramMapOrNull = (structure) => {\n  const box = structure.boxes.find((b) => b.type === \"transport-stream-pmt-box\");\n  if (!box) {\n    return null;\n  }\n  return box;\n};\nvar findProgramMapTableOrThrow = (structure) => {\n  const box = findProgramMapOrNull(structure);\n  if (!box) {\n    throw new Error(\"No PMT box found\");\n  }\n  return box;\n};\nvar getProgramForId = (structure, packetIdentifier) => {\n  const box = findProgramAssociationTableOrThrow(structure);\n  const entry = box.pat.find((e) => e.programMapIdentifier === packetIdentifier);\n  return entry ?? null;\n};\nvar getStreamForId = (structure, packetIdentifier) => {\n  const box = findProgramMapTableOrThrow(structure);\n  const entry = box.streams.find((e) => e.pid === packetIdentifier);\n  return entry ?? null;\n};\n\n// src/containers/transport-stream/get-tracks.ts\nvar filterStreamsBySupportedTypes = (streams) => {\n  return streams.filter((stream) => stream.streamType === 27 || stream.streamType === 15);\n};\nvar getTracksFromTransportStream = (parserState) => {\n  const structure = parserState.structure.getTsStructure();\n  const programMapTable = findProgramMapTableOrThrow(structure);\n  const parserTracks = parserState.callbacks.tracks.getTracks();\n  const mapped = filterStreamsBySupportedTypes(programMapTable.streams).map((stream) => {\n    return parserTracks.find((track) => track.trackId === stream.pid);\n  }).filter(truthy);\n  if (mapped.length !== filterStreamsBySupportedTypes(programMapTable.streams).length) {\n    throw new Error(\"Not all tracks found\");\n  }\n  return mapped;\n};\nvar hasAllTracksFromTransportStream = (parserState) => {\n  try {\n    getTracksFromTransportStream(parserState);\n    return true;\n  } catch {\n    return false;\n  }\n};\n\n// src/make-hvc1-codec-strings.ts\nvar getHvc1CodecString = (data) => {\n  const configurationVersion = data.getUint8();\n  if (configurationVersion !== 1) {\n    throw new Error(`Unsupported HVCC version ${configurationVersion}`);\n  }\n  const generalProfileSpaceTierFlagAndIdc = data.getUint8();\n  let generalProfileCompatibility = data.getUint32();\n  const generalProfileSpace = generalProfileSpaceTierFlagAndIdc >> 6;\n  const generalTierFlag = (generalProfileSpaceTierFlagAndIdc & 32) >> 5;\n  const generalProfileIdc = generalProfileSpaceTierFlagAndIdc & 31;\n  const generalConstraintIndicator = data.getSlice(6);\n  const generalLevelIdc = data.getUint8();\n  let profileId = 0;\n  for (let i = 0;i < 32; i++) {\n    profileId |= generalProfileCompatibility & 1;\n    if (i === 31)\n      break;\n    profileId <<= 1;\n    generalProfileCompatibility >>= 1;\n  }\n  const profileSpaceChar = generalProfileSpace === 0 ? \"\" : generalProfileSpace === 1 ? \"A\" : generalProfileSpace === 2 ? \"B\" : \"C\";\n  const generalTierChar = generalTierFlag === 0 ? \"L\" : \"H\";\n  let hasByte = false;\n  let generalConstraintString = \"\";\n  for (let i = 5;i >= 0; i--) {\n    if (generalConstraintIndicator[i] || hasByte) {\n      generalConstraintString = generalConstraintIndicator[i].toString(16) + generalConstraintString;\n      hasByte = true;\n    }\n  }\n  return `${profileSpaceChar}${generalProfileIdc.toString(16)}.${profileId.toString(16)}.${generalTierChar}${generalLevelIdc}${generalConstraintString ? \".\" : \"\"}${generalConstraintString}`;\n};\n\n// src/containers/webm/traversal.ts\nvar getMainSegment = (segments) => {\n  return segments.find((s) => s.type === \"Segment\") ?? null;\n};\nvar getTrackCodec = (track) => {\n  const child = track.value.find((b) => b.type === \"CodecID\");\n  return child ?? null;\n};\nvar getTrackTimestampScale = (track) => {\n  const child = track.value.find((b) => b.type === \"TrackTimestampScale\");\n  if (!child) {\n    return null;\n  }\n  if (child.type !== \"TrackTimestampScale\") {\n    throw new Error(\"Expected TrackTimestampScale\");\n  }\n  return child.value;\n};\nvar getTrackId = (track) => {\n  const trackId = track.value.find((b) => b.type === \"TrackNumber\");\n  if (!trackId || trackId.type !== \"TrackNumber\") {\n    throw new Error(\"Expected track number segment\");\n  }\n  return trackId.value.value;\n};\nvar getCodecSegment = (track) => {\n  const codec = track.value.find((b) => b.type === \"CodecID\");\n  if (!codec || codec.type !== \"CodecID\") {\n    return null;\n  }\n  return codec;\n};\nvar getColourSegment = (track) => {\n  const videoSegment2 = getVideoSegment(track);\n  if (!videoSegment2) {\n    return null;\n  }\n  const colour = videoSegment2.value.find((b) => b.type === \"Colour\");\n  if (!colour || colour.type !== \"Colour\") {\n    return null;\n  }\n  return colour;\n};\nvar getTransferCharacteristicsSegment = (color2) => {\n  if (!color2 || color2.type !== \"Colour\") {\n    return null;\n  }\n  const box = color2.value.find((b) => b.type === \"TransferCharacteristics\");\n  if (!box || box.type !== \"TransferCharacteristics\") {\n    return null;\n  }\n  return box;\n};\nvar getMatrixCoefficientsSegment = (color2) => {\n  if (!color2 || color2.type !== \"Colour\") {\n    return null;\n  }\n  const box = color2.value.find((b) => b.type === \"MatrixCoefficients\");\n  if (!box || box.type !== \"MatrixCoefficients\") {\n    return null;\n  }\n  return box;\n};\nvar getPrimariesSegment = (color2) => {\n  if (!color2 || color2.type !== \"Colour\") {\n    return null;\n  }\n  const box = color2.value.find((b) => b.type === \"Primaries\");\n  if (!box || box.type !== \"Primaries\") {\n    return null;\n  }\n  return box;\n};\nvar getRangeSegment = (color2) => {\n  if (!color2 || color2.type !== \"Colour\") {\n    return null;\n  }\n  const box = color2.value.find((b) => b.type === \"Range\");\n  if (!box || box.type !== \"Range\") {\n    return null;\n  }\n  return box;\n};\nvar getDisplayHeightSegment = (track) => {\n  const videoSegment2 = getVideoSegment(track);\n  if (!videoSegment2) {\n    return null;\n  }\n  const displayHeight2 = videoSegment2.value.find((b) => b.type === \"DisplayHeight\");\n  if (!displayHeight2 || displayHeight2.type !== \"DisplayHeight\") {\n    return null;\n  }\n  return displayHeight2;\n};\nvar getTrackTypeSegment = (track) => {\n  const trackType2 = track.value.find((b) => b.type === \"TrackType\");\n  if (!trackType2 || trackType2.type !== \"TrackType\") {\n    return null;\n  }\n  return trackType2;\n};\nvar getWidthSegment = (track) => {\n  const videoSegment2 = getVideoSegment(track);\n  if (!videoSegment2) {\n    return null;\n  }\n  const width = videoSegment2.value.find((b) => b.type === \"PixelWidth\");\n  if (!width || width.type !== \"PixelWidth\") {\n    return null;\n  }\n  return width;\n};\nvar getHeightSegment = (track) => {\n  const videoSegment2 = getVideoSegment(track);\n  if (!videoSegment2) {\n    return null;\n  }\n  const height = videoSegment2.value.find((b) => b.type === \"PixelHeight\");\n  if (!height || height.type !== \"PixelHeight\") {\n    return null;\n  }\n  return height;\n};\nvar getDisplayWidthSegment = (track) => {\n  const videoSegment2 = getVideoSegment(track);\n  if (!videoSegment2) {\n    return null;\n  }\n  const displayWidth2 = videoSegment2.value.find((b) => b.type === \"DisplayWidth\");\n  if (!displayWidth2 || displayWidth2.type !== \"DisplayWidth\") {\n    return null;\n  }\n  return displayWidth2;\n};\nvar getTracksSegment = (segment) => {\n  const tracksSegment = segment.value.find((b) => b.type === \"Tracks\");\n  if (!tracksSegment) {\n    return null;\n  }\n  return tracksSegment;\n};\nvar getTrackWithUid = (segment, trackUid) => {\n  const tracksSegment = getTracksSegment(segment);\n  if (!tracksSegment) {\n    return null;\n  }\n  const trackEntries = tracksSegment.value.filter((t) => t.type === \"TrackEntry\");\n  const trackEntry2 = trackEntries.find((entry) => {\n    return entry?.value.find((t) => t.type === \"TrackUID\" && t.value === trackUid);\n  });\n  if (!trackEntry2) {\n    return null;\n  }\n  return trackEntry2.value.find((t) => t.type === \"TrackNumber\")?.value.value ?? null;\n};\nvar getVideoSegment = (track) => {\n  const videoSegment2 = track.value.find((b) => b.type === \"Video\");\n  if (!videoSegment2 || videoSegment2.type !== \"Video\") {\n    return null;\n  }\n  return videoSegment2 ?? null;\n};\nvar getAudioSegment = (track) => {\n  const audioSegment2 = track.value.find((b) => b.type === \"Audio\");\n  if (!audioSegment2 || audioSegment2.type !== \"Audio\") {\n    return null;\n  }\n  return audioSegment2 ?? null;\n};\nvar getSampleRate2 = (track) => {\n  const audioSegment2 = getAudioSegment(track);\n  if (!audioSegment2) {\n    return null;\n  }\n  const samplingFrequency2 = audioSegment2.value.find((b) => b.type === \"SamplingFrequency\");\n  if (!samplingFrequency2 || samplingFrequency2.type !== \"SamplingFrequency\") {\n    return null;\n  }\n  return samplingFrequency2.value.value;\n};\nvar getNumberOfChannels = (track) => {\n  const audioSegment2 = getAudioSegment(track);\n  if (!audioSegment2) {\n    throw new Error(\"Could not find audio segment\");\n  }\n  const channels2 = audioSegment2.value.find((b) => b.type === \"Channels\");\n  if (!channels2 || channels2.type !== \"Channels\") {\n    return 1;\n  }\n  return channels2.value.value;\n};\nvar getBitDepth = (track) => {\n  const audioSegment2 = getAudioSegment(track);\n  if (!audioSegment2) {\n    return null;\n  }\n  const bitDepth2 = audioSegment2.value.find((b) => b.type === \"BitDepth\");\n  if (!bitDepth2 || bitDepth2.type !== \"BitDepth\") {\n    return null;\n  }\n  return bitDepth2.value.value;\n};\nvar getPrivateData = (track) => {\n  const privateData = track.value.find((b) => b.type === \"CodecPrivate\");\n  if (!privateData || privateData.type !== \"CodecPrivate\") {\n    return null;\n  }\n  return privateData.value;\n};\n\n// src/containers/webm/color.ts\nvar parseColorSegment = (colourSegment) => {\n  const transferCharacteristics2 = getTransferCharacteristicsSegment(colourSegment);\n  const matrixCoefficients2 = getMatrixCoefficientsSegment(colourSegment);\n  const primaries2 = getPrimariesSegment(colourSegment);\n  const range2 = getRangeSegment(colourSegment);\n  return {\n    transfer: transferCharacteristics2 ? getTransferCharacteristicsFromIndex(transferCharacteristics2.value.value) : null,\n    matrix: matrixCoefficients2 ? getMatrixCoefficientsFromIndex(matrixCoefficients2.value.value) : null,\n    primaries: primaries2 ? getPrimariesFromIndex(primaries2.value.value) : null,\n    fullRange: transferCharacteristics2?.value.value && matrixCoefficients2?.value.value ? null : range2 ? Boolean(range2?.value.value) : null\n  };\n};\n\n// src/containers/webm/description.ts\nvar getAudioDescription = (track) => {\n  const codec = getCodecSegment(track);\n  if (!codec || codec.value !== \"A_VORBIS\") {\n    return;\n  }\n  const privateData = getPrivateData(track);\n  if (!privateData) {\n    return;\n  }\n  if (privateData[0] !== 2) {\n    throw new Error(\"Expected vorbis private data version 2\");\n  }\n  let offset = 1;\n  let vorbisInfoLength = 0;\n  let vorbisSkipLength = 0;\n  while ((privateData[offset] & 255) === 255) {\n    vorbisInfoLength += 255;\n    offset++;\n  }\n  vorbisInfoLength += privateData[offset++] & 255;\n  while ((privateData[offset] & 255) === 255) {\n    vorbisSkipLength += 255;\n    offset++;\n  }\n  vorbisSkipLength += privateData[offset++] & 255;\n  if (privateData[offset] !== 1) {\n    throw new Error(\"Error parsing vorbis codec private\");\n  }\n  const vorbisInfo = privateData.slice(offset, offset + vorbisInfoLength);\n  offset += vorbisInfoLength;\n  if (privateData[offset] !== 3) {\n    throw new Error(\"Error parsing vorbis codec private\");\n  }\n  const vorbisComments = privateData.slice(offset, offset + vorbisSkipLength);\n  offset += vorbisSkipLength;\n  if (privateData[offset] !== 5) {\n    throw new Error(\"Error parsing vorbis codec private\");\n  }\n  const vorbisBooks = privateData.slice(offset);\n  const bufferIterator = getArrayBufferIterator({\n    initialData: vorbisInfo.slice(0),\n    maxBytes: vorbisInfo.length,\n    logLevel: \"error\"\n  });\n  bufferIterator.getUint8();\n  const vorbis = bufferIterator.getByteString(6, false);\n  if (vorbis !== \"vorbis\") {\n    throw new Error(\"Error parsing vorbis codec private\");\n  }\n  const vorbisVersion = bufferIterator.getUint32Le();\n  if (vorbisVersion !== 0) {\n    throw new Error(\"Error parsing vorbis codec private\");\n  }\n  const vorbisDescription = new Uint8Array([\n    2,\n    vorbisInfo.length,\n    vorbisComments.length,\n    ...vorbisInfo,\n    ...vorbisComments,\n    ...vorbisBooks\n  ]);\n  return vorbisDescription;\n};\n\n// src/containers/webm/segments/track-entry.ts\nvar trackTypeToString = (trackType2) => {\n  switch (trackType2) {\n    case 1:\n      return \"video\";\n    case 2:\n      return \"audio\";\n    case 3:\n      return \"complex\";\n    case 4:\n      return \"subtitle\";\n    case 5:\n      return \"button\";\n    case 6:\n      return \"control\";\n    case 7:\n      return \"metadata\";\n    default:\n      throw new Error(`Unknown track type: ${trackType2}`);\n  }\n};\n\n// src/containers/webm/make-track.ts\nvar NO_CODEC_PRIVATE_SHOULD_BE_DERIVED_FROM_SPS = \"no-codec-private-should-be-derived-from-sps\";\nvar getDescription = (track) => {\n  const codec = getCodecSegment(track);\n  if (!codec) {\n    return;\n  }\n  if (codec.value === \"V_MPEG4/ISO/AVC\" || codec.value === \"V_MPEGH/ISO/HEVC\") {\n    const priv = getPrivateData(track);\n    if (priv) {\n      return priv;\n    }\n  }\n  return;\n};\nvar getMatroskaVideoCodecEnum = ({\n  codecSegment: codec\n}) => {\n  if (codec.value === \"V_VP8\") {\n    return \"vp8\";\n  }\n  if (codec.value === \"V_VP9\") {\n    return \"vp9\";\n  }\n  if (codec.value === \"V_MPEG4/ISO/AVC\") {\n    return \"h264\";\n  }\n  if (codec.value === \"V_AV1\") {\n    return \"av1\";\n  }\n  if (codec.value === \"V_MPEGH/ISO/HEVC\") {\n    return \"h265\";\n  }\n  throw new Error(`Unknown codec: ${codec.value}`);\n};\nvar getMatroskaVideoCodecString = ({\n  track,\n  codecSegment: codec\n}) => {\n  if (codec.value === \"V_VP8\") {\n    return \"vp8\";\n  }\n  if (codec.value === \"V_VP9\") {\n    const priv = getPrivateData(track);\n    if (priv) {\n      throw new Error(\"@remotion/media-parser cannot handle the private data for VP9. Do you have an example file you could send so we can implement it? https://remotion.dev/report\");\n    }\n    return \"vp09.00.10.08\";\n  }\n  if (codec.value === \"V_MPEG4/ISO/AVC\") {\n    const priv = getPrivateData(track);\n    if (priv) {\n      return `avc1.${priv[1].toString(16).padStart(2, \"0\")}${priv[2].toString(16).padStart(2, \"0\")}${priv[3].toString(16).padStart(2, \"0\")}`;\n    }\n    return NO_CODEC_PRIVATE_SHOULD_BE_DERIVED_FROM_SPS;\n  }\n  if (codec.value === \"V_MPEGH/ISO/HEVC\") {\n    const priv = getPrivateData(track);\n    const iterator = getArrayBufferIterator({\n      initialData: priv,\n      maxBytes: priv.length,\n      logLevel: \"error\"\n    });\n    return \"hvc1.\" + getHvc1CodecString(iterator);\n  }\n  if (codec.value === \"V_AV1\") {\n    const priv = getPrivateData(track);\n    if (!priv) {\n      throw new Error(\"Expected private data in AV1 track\");\n    }\n    return parseAv1PrivateData(priv, null);\n  }\n  throw new Error(`Unknown codec: ${codec.value}`);\n};\nvar getMatroskaAudioCodecEnum = ({\n  track\n}) => {\n  const codec = getCodecSegment(track);\n  if (!codec) {\n    throw new Error(\"Expected codec segment\");\n  }\n  if (codec.value === \"A_OPUS\") {\n    return \"opus\";\n  }\n  if (codec.value === \"A_VORBIS\") {\n    return \"vorbis\";\n  }\n  if (codec.value === \"A_PCM/INT/LIT\") {\n    const bitDepth2 = getBitDepth(track);\n    if (bitDepth2 === null) {\n      throw new Error(\"Expected bit depth\");\n    }\n    if (bitDepth2 === 8) {\n      return \"pcm-u8\";\n    }\n    if (bitDepth2 === 16) {\n      return \"pcm-s16\";\n    }\n    if (bitDepth2 === 24) {\n      return \"pcm-s24\";\n    }\n    throw new Error(\"Unknown audio format\");\n  }\n  if (codec.value === \"A_AAC\") {\n    return `aac`;\n  }\n  if (codec.value === \"A_MPEG/L3\") {\n    return \"mp3\";\n  }\n  throw new Error(`Unknown codec: ${codec.value}`);\n};\nvar getMatroskaAudioCodecString = (track) => {\n  const codec = getCodecSegment(track);\n  if (!codec) {\n    throw new Error(\"Expected codec segment\");\n  }\n  if (codec.value === \"A_OPUS\") {\n    return \"opus\";\n  }\n  if (codec.value === \"A_VORBIS\") {\n    return \"vorbis\";\n  }\n  if (codec.value === \"A_PCM/INT/LIT\") {\n    const bitDepth2 = getBitDepth(track);\n    if (bitDepth2 === null) {\n      throw new Error(\"Expected bit depth\");\n    }\n    if (bitDepth2 === 8) {\n      return \"pcm-u8\";\n    }\n    return \"pcm-s\" + bitDepth2;\n  }\n  if (codec.value === \"A_AAC\") {\n    const priv = getPrivateData(track);\n    const iterator = getArrayBufferIterator({\n      initialData: priv,\n      maxBytes: priv.length,\n      logLevel: \"error\"\n    });\n    iterator.startReadingBits();\n    const profile = iterator.getBits(5);\n    iterator.stopReadingBits();\n    iterator.destroy();\n    return `mp4a.40.${profile.toString().padStart(2, \"0\")}`;\n  }\n  if (codec.value === \"A_MPEG/L3\") {\n    return \"mp3\";\n  }\n  throw new Error(`Unknown codec: ${codec.value}`);\n};\nvar getTrack = ({\n  timescale,\n  track\n}) => {\n  const trackType2 = getTrackTypeSegment(track);\n  if (!trackType2) {\n    throw new Error(\"Expected track type segment\");\n  }\n  const trackId = getTrackId(track);\n  if (trackTypeToString(trackType2.value.value) === \"video\") {\n    const width = getWidthSegment(track);\n    if (width === null) {\n      throw new Error(\"Expected width segment\");\n    }\n    const height = getHeightSegment(track);\n    if (height === null) {\n      throw new Error(\"Expected height segment\");\n    }\n    const displayHeight2 = getDisplayHeightSegment(track);\n    const displayWidth2 = getDisplayWidthSegment(track);\n    const codec = getCodecSegment(track);\n    if (!codec) {\n      return null;\n    }\n    const codecPrivate2 = getPrivateData(track);\n    const codecString = getMatroskaVideoCodecString({\n      track,\n      codecSegment: codec\n    });\n    const colour = getColourSegment(track);\n    if (!codecString) {\n      return null;\n    }\n    const codecEnum = getMatroskaVideoCodecEnum({\n      codecSegment: codec\n    });\n    const codecData = codecPrivate2 === null ? null : codecEnum === \"h264\" ? { type: \"avc-sps-pps\", data: codecPrivate2 } : codecEnum === \"av1\" ? {\n      type: \"av1c-data\",\n      data: codecPrivate2\n    } : codecEnum === \"h265\" ? {\n      type: \"hvcc-data\",\n      data: codecPrivate2\n    } : codecEnum === \"vp8\" ? {\n      type: \"unknown-data\",\n      data: codecPrivate2\n    } : codecEnum === \"vp9\" ? {\n      type: \"unknown-data\",\n      data: codecPrivate2\n    } : null;\n    const advancedColor = colour ? parseColorSegment(colour) : {\n      fullRange: null,\n      matrix: null,\n      primaries: null,\n      transfer: null\n    };\n    return {\n      m3uStreamFormat: null,\n      type: \"video\",\n      trackId,\n      codec: codecString,\n      description: getDescription(track),\n      height: displayHeight2 ? displayHeight2.value.value : height.value.value,\n      width: displayWidth2 ? displayWidth2.value.value : width.value.value,\n      sampleAspectRatio: {\n        numerator: 1,\n        denominator: 1\n      },\n      originalTimescale: timescale,\n      codedHeight: height.value.value,\n      codedWidth: width.value.value,\n      displayAspectHeight: displayHeight2 ? displayHeight2.value.value : height.value.value,\n      displayAspectWidth: displayWidth2 ? displayWidth2.value.value : width.value.value,\n      rotation: 0,\n      codecData,\n      colorSpace: mediaParserAdvancedColorToWebCodecsColor(advancedColor),\n      advancedColor,\n      codecEnum,\n      fps: null,\n      startInSeconds: 0,\n      timescale: WEBCODECS_TIMESCALE\n    };\n  }\n  if (trackTypeToString(trackType2.value.value) === \"audio\") {\n    const sampleRate = getSampleRate2(track);\n    const numberOfChannels = getNumberOfChannels(track);\n    const codecPrivate2 = getPrivateData(track);\n    if (sampleRate === null) {\n      throw new Error(\"Could not find sample rate or number of channels\");\n    }\n    const codecString = getMatroskaAudioCodecString(track);\n    return {\n      type: \"audio\",\n      trackId,\n      codec: codecString,\n      originalTimescale: timescale,\n      numberOfChannels,\n      sampleRate,\n      description: getAudioDescription(track),\n      codecData: codecPrivate2 ? codecString === \"opus\" ? { type: \"ogg-identification\", data: codecPrivate2 } : { type: \"unknown-data\", data: codecPrivate2 } : null,\n      codecEnum: getMatroskaAudioCodecEnum({\n        track\n      }),\n      startInSeconds: 0,\n      timescale: WEBCODECS_TIMESCALE\n    };\n  }\n  return null;\n};\n\n// src/containers/webm/get-ready-tracks.ts\nvar getTracksFromMatroska = ({\n  structureState,\n  webmState\n}) => {\n  const structure = structureState.getMatroskaStructure();\n  const mainSegment = getMainSegment(structure.boxes);\n  if (!mainSegment) {\n    throw new Error(\"No main segment\");\n  }\n  const tracksSegment = getTracksSegment(mainSegment);\n  if (!tracksSegment) {\n    throw new Error(\"No tracks segment\");\n  }\n  const resolvedTracks = [];\n  const missingInfo = [];\n  for (const trackEntrySegment of tracksSegment.value) {\n    if (trackEntrySegment.type === \"Crc32\") {\n      continue;\n    }\n    if (trackEntrySegment.type !== \"TrackEntry\") {\n      throw new Error(\"Expected track entry segment\");\n    }\n    const track = getTrack({\n      track: trackEntrySegment,\n      timescale: webmState.getTimescale()\n    });\n    if (!track) {\n      continue;\n    }\n    if (track.codec === NO_CODEC_PRIVATE_SHOULD_BE_DERIVED_FROM_SPS) {\n      const avc = webmState.getAvcProfileForTrackNumber(track.trackId);\n      if (avc) {\n        resolvedTracks.push({\n          ...track,\n          codec: getCodecStringFromSpsAndPps(avc)\n        });\n      } else {\n        missingInfo.push(track);\n      }\n    } else {\n      resolvedTracks.push(track);\n    }\n  }\n  return { missingInfo, resolved: resolvedTracks };\n};\nvar matroskaHasTracks = ({\n  structureState,\n  webmState\n}) => {\n  const structure = structureState.getMatroskaStructure();\n  const mainSegment = getMainSegment(structure.boxes);\n  if (!mainSegment) {\n    return false;\n  }\n  return getTracksSegment(mainSegment) !== null && getTracksFromMatroska({\n    structureState,\n    webmState\n  }).missingInfo.length === 0;\n};\n\n// src/get-tracks.ts\nvar isoBaseMediaHasTracks = (state, mayUsePrecomputed) => {\n  return Boolean(getMoovBoxFromState({\n    structureState: state.structure,\n    isoState: state.iso,\n    mp4HeaderSegment: state.m3uPlaylistContext?.mp4HeaderSegment ?? null,\n    mayUsePrecomputed\n  }));\n};\nvar getHasTracks = (state, mayUsePrecomputed) => {\n  const structure = state.structure.getStructure();\n  if (structure.type === \"matroska\") {\n    return matroskaHasTracks({\n      structureState: state.structure,\n      webmState: state.webm\n    });\n  }\n  if (structure.type === \"iso-base-media\") {\n    return isoBaseMediaHasTracks(state, mayUsePrecomputed);\n  }\n  if (structure.type === \"riff\") {\n    return hasAllTracksFromAvi(state);\n  }\n  if (structure.type === \"transport-stream\") {\n    return hasAllTracksFromTransportStream(state);\n  }\n  if (structure.type === \"mp3\") {\n    return state.callbacks.tracks.getTracks().length > 0;\n  }\n  if (structure.type === \"wav\") {\n    return state.callbacks.tracks.hasAllTracks();\n  }\n  if (structure.type === \"aac\") {\n    return state.callbacks.tracks.hasAllTracks();\n  }\n  if (structure.type === \"flac\") {\n    return state.callbacks.tracks.hasAllTracks();\n  }\n  if (structure.type === \"m3u\") {\n    return state.callbacks.tracks.hasAllTracks();\n  }\n  throw new Error(\"Unknown container \" + structure);\n};\nvar getCategorizedTracksFromMatroska = (state) => {\n  const { resolved } = getTracksFromMatroska({\n    structureState: state.structure,\n    webmState: state.webm\n  });\n  return resolved;\n};\nvar getTracksFromMoovBox = (moovBox) => {\n  const mediaParserTracks = [];\n  const tracks2 = getTraks(moovBox);\n  for (const trakBox of tracks2) {\n    const mvhdBox = getMvhdBox(moovBox);\n    if (!mvhdBox) {\n      throw new Error(\"Mvhd box is not found\");\n    }\n    const startTime = findTrackStartTimeInSeconds({\n      movieTimeScale: mvhdBox.timeScale,\n      trakBox\n    });\n    const track = makeBaseMediaTrack(trakBox, startTime);\n    if (!track) {\n      continue;\n    }\n    mediaParserTracks.push(track);\n  }\n  return mediaParserTracks;\n};\nvar getTracksFromIsoBaseMedia = ({\n  mayUsePrecomputed,\n  structure,\n  isoState,\n  m3uPlaylistContext\n}) => {\n  const moovBox = getMoovBoxFromState({\n    structureState: structure,\n    isoState,\n    mp4HeaderSegment: m3uPlaylistContext?.mp4HeaderSegment ?? null,\n    mayUsePrecomputed\n  });\n  if (!moovBox) {\n    return [];\n  }\n  return getTracksFromMoovBox(moovBox);\n};\nvar defaultGetTracks = (parserState) => {\n  const tracks2 = parserState.callbacks.tracks.getTracks();\n  if (tracks2.length === 0) {\n    throw new Error(\"No tracks found\");\n  }\n  return tracks2;\n};\nvar getTracks = (state, mayUsePrecomputed) => {\n  const structure = state.structure.getStructure();\n  if (structure.type === \"matroska\") {\n    return getCategorizedTracksFromMatroska(state);\n  }\n  if (structure.type === \"iso-base-media\") {\n    return getTracksFromIsoBaseMedia({\n      isoState: state.iso,\n      m3uPlaylistContext: state.m3uPlaylistContext,\n      structure: state.structure,\n      mayUsePrecomputed\n    });\n  }\n  if (structure.type === \"riff\") {\n    return getTracksFromAvi(structure, state);\n  }\n  if (structure.type === \"transport-stream\") {\n    return getTracksFromTransportStream(state);\n  }\n  if (structure.type === \"mp3\" || structure.type === \"wav\" || structure.type === \"flac\" || structure.type === \"aac\" || structure.type === \"m3u\") {\n    return defaultGetTracks(state);\n  }\n  throw new Error(`Unknown container${structure}`);\n};\n\n// src/get-audio-codec.ts\nvar getAudioCodec = (parserState) => {\n  const tracks2 = getTracks(parserState, true);\n  if (tracks2.length === 0) {\n    throw new Error(\"No tracks yet\");\n  }\n  const audioTrack = tracks2.find((t) => t.type === \"audio\");\n  if (!audioTrack) {\n    return null;\n  }\n  if (audioTrack.type === \"audio\") {\n    return audioTrack.codecEnum;\n  }\n  return null;\n};\nvar hasAudioCodec = (state) => {\n  return getHasTracks(state, true);\n};\nvar getCodecSpecificatorFromEsdsBox = ({\n  child\n}) => {\n  const descriptor = child.descriptors.find((d) => d.type === \"decoder-config-descriptor\");\n  if (!descriptor) {\n    throw new Error(\"No decoder-config-descriptor\");\n  }\n  if (descriptor.type !== \"decoder-config-descriptor\") {\n    throw new Error(\"Expected decoder-config-descriptor\");\n  }\n  if (descriptor.asNumber !== 64) {\n    return {\n      primary: descriptor.asNumber,\n      secondary: null,\n      description: undefined\n    };\n  }\n  const audioSpecificConfig = descriptor.decoderSpecificConfigs.find((d) => {\n    return d.type === \"mp4a-specific-config\" ? d : null;\n  });\n  if (!audioSpecificConfig || audioSpecificConfig.type !== \"mp4a-specific-config\") {\n    throw new Error(\"No audio-specific-config\");\n  }\n  return {\n    primary: descriptor.asNumber,\n    secondary: audioSpecificConfig.audioObjectType,\n    description: audioSpecificConfig.asBytes\n  };\n};\nvar getCodecPrivateFromTrak = (trakBox) => {\n  const stsdBox = getStsdBox(trakBox);\n  if (!stsdBox) {\n    return null;\n  }\n  const audioSample = stsdBox.samples.find((s) => s.type === \"audio\");\n  if (!audioSample || audioSample.type !== \"audio\") {\n    return null;\n  }\n  const esds = audioSample.children.find((b) => b.type === \"esds-box\");\n  if (!esds || esds.type !== \"esds-box\") {\n    return null;\n  }\n  const decoderConfigDescriptor = esds.descriptors.find((d) => d.type === \"decoder-config-descriptor\");\n  if (!decoderConfigDescriptor) {\n    return null;\n  }\n  const mp4a = decoderConfigDescriptor.decoderSpecificConfigs.find((d) => d.type === \"mp4a-specific-config\");\n  if (!mp4a) {\n    return null;\n  }\n  return { type: \"aac-config\", data: mp4a.asBytes };\n};\nvar onSample = (sample, children) => {\n  const child = children.find((c) => c.type === \"esds-box\");\n  if (child && child.type === \"esds-box\") {\n    const ret = getCodecSpecificatorFromEsdsBox({ child });\n    return {\n      format: sample.format,\n      primarySpecificator: ret.primary,\n      secondarySpecificator: ret.secondary,\n      description: ret.description\n    };\n  }\n  return {\n    format: sample.format,\n    primarySpecificator: null,\n    secondarySpecificator: null,\n    description: undefined\n  };\n};\nvar getNumberOfChannelsFromTrak = (trak) => {\n  const stsdBox = getStsdBox(trak);\n  if (!stsdBox) {\n    return null;\n  }\n  const sample = stsdBox.samples.find((s) => s.type === \"audio\");\n  if (!sample || sample.type !== \"audio\") {\n    return null;\n  }\n  return sample.numberOfChannels;\n};\nvar getSampleRate = (trak) => {\n  const stsdBox = getStsdBox(trak);\n  if (!stsdBox) {\n    return null;\n  }\n  const sample = stsdBox.samples.find((s) => s.type === \"audio\");\n  if (!sample || sample.type !== \"audio\") {\n    return null;\n  }\n  return sample.sampleRate;\n};\nvar getAudioCodecFromTrak = (trak) => {\n  const stsdBox = getStsdBox(trak);\n  if (!stsdBox) {\n    return null;\n  }\n  const sample = stsdBox.samples.find((s) => s.type === \"audio\");\n  if (!sample || sample.type !== \"audio\") {\n    return null;\n  }\n  const waveBox = sample.children.find((b) => b.type === \"regular-box\" && b.boxType === \"wave\");\n  if (waveBox && waveBox.type === \"regular-box\" && waveBox.boxType === \"wave\") {\n    const esdsSample = onSample(sample, waveBox.children);\n    if (esdsSample) {\n      return esdsSample;\n    }\n  }\n  const ret = onSample(sample, sample.children);\n  if (ret) {\n    return ret;\n  }\n  return null;\n};\nvar isLpcmAudioCodec = (trak) => {\n  return getAudioCodecFromTrak(trak)?.format === \"lpcm\";\n};\nvar isIn24AudioCodec = (trak) => {\n  return getAudioCodecFromTrak(trak)?.format === \"in24\";\n};\nvar isTwosAudioCodec = (trak) => {\n  return getAudioCodecFromTrak(trak)?.format === \"twos\";\n};\nvar getAudioCodecStringFromTrak = (trak) => {\n  const codec = getAudioCodecFromTrak(trak);\n  if (!codec) {\n    throw new Error(\"Expected codec\");\n  }\n  if (codec.format === \"lpcm\") {\n    return {\n      codecString: \"pcm-s16\",\n      description: codec.description ? { type: \"unknown-data\", data: codec.description } : undefined\n    };\n  }\n  if (codec.format === \"twos\") {\n    return {\n      codecString: \"pcm-s16\",\n      description: codec.description ? { type: \"unknown-data\", data: codec.description } : undefined\n    };\n  }\n  if (codec.format === \"in24\") {\n    return {\n      codecString: \"pcm-s24\",\n      description: codec.description ? { type: \"unknown-data\", data: codec.description } : undefined\n    };\n  }\n  const codecStringWithoutMp3Exception = [\n    codec.format,\n    codec.primarySpecificator ? codec.primarySpecificator.toString(16) : null,\n    codec.secondarySpecificator ? codec.secondarySpecificator.toString().padStart(2, \"0\") : null\n  ].filter(Boolean).join(\".\");\n  const codecString = codecStringWithoutMp3Exception.toLowerCase() === \"mp4a.6b\" || codecStringWithoutMp3Exception.toLowerCase() === \"mp4a.69\" ? \"mp3\" : codecStringWithoutMp3Exception;\n  if (codecString === \"mp3\") {\n    return {\n      codecString,\n      description: codec.description ? {\n        type: \"unknown-data\",\n        data: codec.description\n      } : undefined\n    };\n  }\n  if (codecString.startsWith(\"mp4a.\")) {\n    return {\n      codecString,\n      description: codec.description ? {\n        type: \"aac-config\",\n        data: codec.description\n      } : undefined\n    };\n  }\n  return {\n    codecString,\n    description: codec.description ? {\n      type: \"unknown-data\",\n      data: codec.description\n    } : undefined\n  };\n};\nvar getAudioCodecFromAudioCodecInfo = (codec) => {\n  if (codec.format === \"twos\") {\n    return \"pcm-s16\";\n  }\n  if (codec.format === \"in24\") {\n    return \"pcm-s24\";\n  }\n  if (codec.format === \"lpcm\") {\n    return \"pcm-s16\";\n  }\n  if (codec.format === \"sowt\") {\n    return \"aiff\";\n  }\n  if (codec.format === \"ac-3\") {\n    return \"ac3\";\n  }\n  if (codec.format === \"Opus\") {\n    return \"opus\";\n  }\n  if (codec.format === \"mp4a\") {\n    if (codec.primarySpecificator === 64) {\n      return \"aac\";\n    }\n    if (codec.primarySpecificator === 107) {\n      return \"mp3\";\n    }\n    if (codec.primarySpecificator === null) {\n      return \"aac\";\n    }\n    throw new Error(\"Unknown mp4a codec: \" + codec.primarySpecificator);\n  }\n  throw new Error(`Unknown audio format: ${codec.format}`);\n};\nvar getAudioCodecFromTrack = (track) => {\n  const audioSample = getAudioCodecFromTrak(track);\n  if (!audioSample) {\n    throw new Error(\"Could not find audio sample\");\n  }\n  return getAudioCodecFromAudioCodecInfo(audioSample);\n};\n\n// src/get-container.ts\nvar getContainer = (segments) => {\n  if (segments.type === \"iso-base-media\") {\n    return \"mp4\";\n  }\n  if (segments.type === \"matroska\") {\n    return \"webm\";\n  }\n  if (segments.type === \"transport-stream\") {\n    return \"transport-stream\";\n  }\n  if (segments.type === \"mp3\") {\n    return \"mp3\";\n  }\n  if (segments.type === \"wav\") {\n    return \"wav\";\n  }\n  if (segments.type === \"flac\") {\n    return \"flac\";\n  }\n  if (segments.type === \"riff\") {\n    if (isRiffAvi(segments)) {\n      return \"avi\";\n    }\n    throw new Error(\"Unknown RIFF container \" + segments.type);\n  }\n  if (segments.type === \"aac\") {\n    return \"aac\";\n  }\n  if (segments.type === \"m3u\") {\n    return \"m3u8\";\n  }\n  throw new Error(\"Unknown container \" + segments);\n};\nvar hasContainer = (boxes) => {\n  try {\n    return getContainer(boxes) !== null;\n  } catch {\n    return false;\n  }\n};\n\n// src/get-dimensions.ts\nvar getDimensions = (state) => {\n  const structure = state.structure.getStructureOrNull();\n  if (structure && isAudioStructure(structure)) {\n    return null;\n  }\n  const tracks2 = getTracks(state, true);\n  if (!tracks2.length) {\n    return null;\n  }\n  const firstVideoTrack = tracks2.find((t) => t.type === \"video\");\n  if (!firstVideoTrack) {\n    return null;\n  }\n  return {\n    width: firstVideoTrack.width,\n    height: firstVideoTrack.height,\n    rotation: firstVideoTrack.rotation,\n    unrotatedHeight: firstVideoTrack.displayAspectHeight,\n    unrotatedWidth: firstVideoTrack.displayAspectWidth\n  };\n};\nvar hasDimensions = (state) => {\n  const structure = state.structure.getStructureOrNull();\n  if (structure && isAudioStructure(structure)) {\n    return true;\n  }\n  try {\n    return getDimensions(state) !== null;\n  } catch {\n    return false;\n  }\n};\n\n// src/containers/flac/get-duration-from-flac.ts\nvar getDurationFromFlac = (parserState) => {\n  const structure = parserState.structure.getFlacStructure();\n  const streaminfo = structure.boxes.find((b) => b.type === \"flac-streaminfo\");\n  if (!streaminfo) {\n    throw new Error(\"Streaminfo not found\");\n  }\n  return streaminfo.totalSamples / streaminfo.sampleRate;\n};\n\n// src/containers/iso-base-media/are-samples-complete.ts\nvar areSamplesComplete = ({\n  moofBoxes,\n  tfraBoxes\n}) => {\n  if (moofBoxes.length === 0) {\n    return true;\n  }\n  return tfraBoxes.length > 0 && tfraBoxes.every((t) => t.entries.length === moofBoxes.length);\n};\n\n// src/samples-from-moof.ts\nvar getSamplesFromTraf = (trafSegment, moofOffset, trexBoxes) => {\n  if (trafSegment.type !== \"regular-box\" || trafSegment.boxType !== \"traf\") {\n    throw new Error(\"Expected traf-box\");\n  }\n  const tfhdBox = getTfhdBox(trafSegment);\n  const trexBox = trexBoxes.find((t) => t.trackId === tfhdBox?.trackId) ?? null;\n  const defaultTrackSampleDuration = tfhdBox?.defaultSampleDuration || trexBox?.defaultSampleDuration || null;\n  const defaultTrackSampleSize = tfhdBox?.defaultSampleSize || trexBox?.defaultSampleSize || null;\n  const defaultTrackSampleFlags = tfhdBox?.defaultSampleFlags ?? trexBox?.defaultSampleFlags ?? null;\n  const tfdtBox = getTfdtBox(trafSegment);\n  const trunBoxes = getTrunBoxes(trafSegment);\n  let time = 0;\n  let offset = 0;\n  let dataOffset = 0;\n  const samples = [];\n  for (const trunBox of trunBoxes) {\n    let i = -1;\n    if (trunBox.dataOffset) {\n      dataOffset = trunBox.dataOffset;\n      offset = 0;\n    }\n    for (const sample of trunBox.samples) {\n      i++;\n      const duration2 = sample.sampleDuration || defaultTrackSampleDuration;\n      if (duration2 === null) {\n        throw new Error(\"Expected duration\");\n      }\n      const size = sample.sampleSize ?? defaultTrackSampleSize;\n      if (size === null) {\n        throw new Error(\"Expected size\");\n      }\n      const isFirstSample = i === 0;\n      const sampleFlags = sample.sampleFlags ? sample.sampleFlags : isFirstSample && trunBox.firstSampleFlags !== null ? trunBox.firstSampleFlags : defaultTrackSampleFlags;\n      if (sampleFlags === null) {\n        throw new Error(\"Expected sample flags\");\n      }\n      const keyframe = !(sampleFlags >> 16 & 1);\n      const dts = time + (tfdtBox?.baseMediaDecodeTime ?? 0);\n      const samplePosition = {\n        offset: offset + (moofOffset ?? 0) + (dataOffset ?? 0),\n        decodingTimestamp: dts,\n        timestamp: dts + (sample.sampleCompositionTimeOffset ?? 0),\n        duration: duration2,\n        isKeyframe: keyframe,\n        size,\n        chunk: 0,\n        bigEndian: false,\n        chunkSize: null\n      };\n      samples.push(samplePosition);\n      offset += size;\n      time += duration2;\n    }\n  }\n  return samples;\n};\nvar getSamplesFromMoof = ({\n  moofBox,\n  trackId,\n  trexBoxes\n}) => {\n  const mapped = moofBox.trafBoxes.map((traf) => {\n    const tfhdBox = getTfhdBox(traf);\n    if (!tfhdBox || tfhdBox.trackId !== trackId) {\n      return [];\n    }\n    return getSamplesFromTraf(traf, moofBox.offset, trexBoxes);\n  });\n  return mapped.flat(1);\n};\n\n// src/containers/iso-base-media/collect-sample-positions-from-moof-boxes.ts\nvar collectSamplePositionsFromMoofBoxes = ({\n  moofBoxes,\n  tkhdBox,\n  isComplete,\n  trexBoxes\n}) => {\n  const samplePositions = moofBoxes.map((m, index) => {\n    const isLastFragment = index === moofBoxes.length - 1 && isComplete;\n    return {\n      isLastFragment,\n      samples: getSamplesFromMoof({\n        moofBox: m,\n        trackId: tkhdBox.trackId,\n        trexBoxes\n      })\n    };\n  });\n  return { samplePositions, isComplete };\n};\n\n// src/get-sample-positions.ts\nvar getSamplePositions = ({\n  stcoBox,\n  stszBox,\n  stscBox,\n  stssBox,\n  sttsBox,\n  cttsBox\n}) => {\n  const sttsDeltas = [];\n  for (const distribution of sttsBox.sampleDistribution) {\n    for (let i = 0;i < distribution.sampleCount; i++) {\n      sttsDeltas.push(distribution.sampleDelta);\n    }\n  }\n  const cttsEntries = [];\n  for (const entry of cttsBox?.entries ?? [\n    { sampleCount: sttsDeltas.length, sampleOffset: 0 }\n  ]) {\n    for (let i = 0;i < entry.sampleCount; i++) {\n      cttsEntries.push(entry.sampleOffset);\n    }\n  }\n  let dts = 0;\n  const chunks = stcoBox.entries;\n  const samples = [];\n  let samplesPerChunk = 1;\n  for (let i = 0;i < chunks.length; i++) {\n    const hasEntry = stscBox.entries.get(i + 1);\n    if (hasEntry !== undefined) {\n      samplesPerChunk = hasEntry;\n    }\n    let offsetInThisChunk = 0;\n    for (let j = 0;j < samplesPerChunk; j++) {\n      const size = stszBox.countType === \"fixed\" ? stszBox.sampleSize : stszBox.entries[samples.length];\n      const isKeyframe = stssBox ? stssBox.sampleNumber.has(samples.length + 1) : true;\n      const delta = sttsDeltas[samples.length];\n      const ctsOffset = cttsEntries[samples.length];\n      const cts = dts + ctsOffset;\n      samples.push({\n        offset: Number(chunks[i]) + offsetInThisChunk,\n        size,\n        isKeyframe,\n        decodingTimestamp: dts,\n        timestamp: cts,\n        duration: delta,\n        chunk: i,\n        bigEndian: false,\n        chunkSize: null\n      });\n      dts += delta;\n      offsetInThisChunk += size;\n    }\n  }\n  return samples;\n};\n\n// src/get-sample-positions-from-mp4.ts\nvar getGroupedSamplesPositionsFromMp4 = ({\n  trakBox,\n  bigEndian\n}) => {\n  const stscBox = getStscBox(trakBox);\n  const stszBox = getStszBox(trakBox);\n  const stcoBox = getStcoBox(trakBox);\n  if (!stscBox) {\n    throw new Error(\"Expected stsc box in trak box\");\n  }\n  if (!stcoBox) {\n    throw new Error(\"Expected stco box in trak box\");\n  }\n  if (!stszBox) {\n    throw new Error(\"Expected stsz box in trak box\");\n  }\n  if (stszBox.countType !== \"fixed\") {\n    throw new Error(\"Only supporting fixed count type in stsz box\");\n  }\n  const samples = [];\n  let timestamp = 0;\n  const stscKeys = Array.from(stscBox.entries.keys());\n  for (let i = 0;i < stcoBox.entries.length; i++) {\n    const entry = stcoBox.entries[i];\n    const chunk = i + 1;\n    const stscEntry = stscKeys.findLast((e) => e <= chunk);\n    if (stscEntry === undefined) {\n      throw new Error(\"should not be\");\n    }\n    const samplesPerChunk = stscBox.entries.get(stscEntry);\n    if (samplesPerChunk === undefined) {\n      throw new Error(\"should not be\");\n    }\n    samples.push({\n      chunk,\n      timestamp,\n      decodingTimestamp: timestamp,\n      offset: Number(entry),\n      size: stszBox.sampleSize * samplesPerChunk,\n      duration: samplesPerChunk,\n      isKeyframe: true,\n      bigEndian,\n      chunkSize: stszBox.sampleSize\n    });\n    timestamp += samplesPerChunk;\n  }\n  return samples;\n};\n\n// src/containers/iso-base-media/should-group-audio-samples.ts\nvar shouldGroupAudioSamples = (trakBox) => {\n  const isLpcm = isLpcmAudioCodec(trakBox);\n  const isIn24 = isIn24AudioCodec(trakBox);\n  const isTwos = isTwosAudioCodec(trakBox);\n  if (isLpcm || isIn24 || isTwos) {\n    return {\n      bigEndian: isTwos || isIn24\n    };\n  }\n  return null;\n};\n\n// src/containers/iso-base-media/collect-sample-positions-from-trak.ts\nvar collectSamplePositionsFromTrak = (trakBox) => {\n  const shouldGroupSamples = shouldGroupAudioSamples(trakBox);\n  const timescaleAndDuration = getTimescaleAndDuration(trakBox);\n  if (shouldGroupSamples) {\n    return getGroupedSamplesPositionsFromMp4({\n      trakBox,\n      bigEndian: shouldGroupSamples.bigEndian\n    });\n  }\n  const stszBox = getStszBox(trakBox);\n  const stcoBox = getStcoBox(trakBox);\n  const stscBox = getStscBox(trakBox);\n  const stssBox = getStssBox(trakBox);\n  const sttsBox = getSttsBox(trakBox);\n  const cttsBox = getCttsBox(trakBox);\n  if (!stszBox) {\n    throw new Error(\"Expected stsz box in trak box\");\n  }\n  if (!stcoBox) {\n    throw new Error(\"Expected stco box in trak box\");\n  }\n  if (!stscBox) {\n    throw new Error(\"Expected stsc box in trak box\");\n  }\n  if (!sttsBox) {\n    throw new Error(\"Expected stts box in trak box\");\n  }\n  if (!timescaleAndDuration) {\n    throw new Error(\"Expected timescale and duration in trak box\");\n  }\n  const samplePositions = getSamplePositions({\n    stcoBox,\n    stscBox,\n    stszBox,\n    stssBox,\n    sttsBox,\n    cttsBox\n  });\n  return samplePositions;\n};\n\n// src/containers/iso-base-media/get-sample-positions-from-track.ts\nvar getSamplePositionsFromTrack = ({\n  trakBox,\n  moofBoxes,\n  moofComplete,\n  trexBoxes\n}) => {\n  const tkhdBox = getTkhdBox(trakBox);\n  if (!tkhdBox) {\n    throw new Error(\"Expected tkhd box in trak box\");\n  }\n  if (moofBoxes.length > 0) {\n    const { samplePositions } = collectSamplePositionsFromMoofBoxes({\n      moofBoxes,\n      tkhdBox,\n      isComplete: moofComplete,\n      trexBoxes\n    });\n    return {\n      samplePositions: samplePositions.map((s) => s.samples).flat(1),\n      isComplete: moofComplete\n    };\n  }\n  return {\n    samplePositions: collectSamplePositionsFromTrak(trakBox),\n    isComplete: true\n  };\n};\n\n// src/containers/m3u/get-playlist.ts\nvar getAllPlaylists = ({\n  structure,\n  src\n}) => {\n  const isIndependent = isIndependentSegments(structure);\n  if (!isIndependent) {\n    return [\n      {\n        type: \"m3u-playlist\",\n        boxes: structure.boxes,\n        src\n      }\n    ];\n  }\n  const playlists = structure.boxes.filter((box) => box.type === \"m3u-playlist\");\n  return playlists;\n};\nvar getPlaylist = (structure, src) => {\n  const allPlaylists = getAllPlaylists({ structure, src });\n  const playlists = allPlaylists.find((box) => box.src === src);\n  if (!playlists) {\n    throw new Error(`Expected m3u-playlist with src ${src}`);\n  }\n  return playlists;\n};\nvar getDurationFromPlaylist = (playlist) => {\n  const duration2 = playlist.boxes.filter((box) => box.type === \"m3u-extinf\");\n  if (duration2.length === 0) {\n    throw new Error(\"Expected duration in m3u playlist\");\n  }\n  return duration2.reduce((acc, d) => acc + d.value, 0);\n};\n\n// src/containers/m3u/get-duration-from-m3u.ts\nvar getDurationFromM3u = (state) => {\n  const playlists = getAllPlaylists({\n    structure: state.structure.getM3uStructure(),\n    src: state.src\n  });\n  return Math.max(...playlists.map((p) => {\n    return getDurationFromPlaylist(p);\n  }));\n};\n\n// src/containers/mp3/get-frame-length.ts\nvar getUnroundedMpegFrameLength = ({\n  samplesPerFrame,\n  bitrateKbit,\n  samplingFrequency: samplingFrequency2,\n  padding,\n  layer\n}) => {\n  if (layer === 1) {\n    throw new Error(\"MPEG Layer I is not supported\");\n  }\n  return samplesPerFrame / 8 * bitrateKbit / samplingFrequency2 * 1000 + (padding ? layer === 1 ? 4 : 1 : 0);\n};\nvar getAverageMpegFrameLength = ({\n  samplesPerFrame,\n  bitrateKbit,\n  samplingFrequency: samplingFrequency2,\n  layer\n}) => {\n  const withoutPadding = getUnroundedMpegFrameLength({\n    bitrateKbit,\n    layer,\n    padding: false,\n    samplesPerFrame,\n    samplingFrequency: samplingFrequency2\n  });\n  const rounded = Math.floor(withoutPadding);\n  const rest = withoutPadding % 1;\n  return rest * (rounded + 1) + (1 - rest) * rounded;\n};\nvar getMpegFrameLength = ({\n  samplesPerFrame,\n  bitrateKbit,\n  samplingFrequency: samplingFrequency2,\n  padding,\n  layer\n}) => {\n  return Math.floor(getUnroundedMpegFrameLength({\n    bitrateKbit,\n    layer,\n    padding,\n    samplesPerFrame,\n    samplingFrequency: samplingFrequency2\n  }));\n};\n\n// src/containers/mp3/samples-per-mpeg-file.ts\nvar getSamplesPerMpegFrame = ({\n  mpegVersion,\n  layer\n}) => {\n  if (mpegVersion === 1) {\n    if (layer === 1) {\n      return 384;\n    }\n    if (layer === 2 || layer === 3) {\n      return 1152;\n    }\n  }\n  if (mpegVersion === 2) {\n    if (layer === 1) {\n      return 384;\n    }\n    if (layer === 2) {\n      return 1152;\n    }\n    if (layer === 3) {\n      return 576;\n    }\n  }\n  throw new Error(\"Invalid MPEG layer\");\n};\n\n// src/containers/mp3/get-duration.ts\nvar getDurationFromMp3Xing = ({\n  xingData,\n  samplesPerFrame\n}) => {\n  const xingFrames = xingData.numberOfFrames;\n  if (!xingFrames) {\n    throw new Error(\"Cannot get duration of VBR MP3 file - no frames\");\n  }\n  const { sampleRate } = xingData;\n  if (!sampleRate) {\n    throw new Error(\"Cannot get duration of VBR MP3 file - no sample rate\");\n  }\n  const xingSamples = xingFrames * samplesPerFrame;\n  return xingSamples / sampleRate;\n};\nvar getDurationFromMp3 = (state) => {\n  const mp3Info = state.mp3.getMp3Info();\n  const mp3BitrateInfo = state.mp3.getMp3BitrateInfo();\n  if (!mp3Info || !mp3BitrateInfo) {\n    return null;\n  }\n  const samplesPerFrame = getSamplesPerMpegFrame({\n    layer: mp3Info.layer,\n    mpegVersion: mp3Info.mpegVersion\n  });\n  if (mp3BitrateInfo.type === \"variable\") {\n    return getDurationFromMp3Xing({\n      xingData: mp3BitrateInfo.xingData,\n      samplesPerFrame\n    });\n  }\n  const frameLengthInBytes = getMpegFrameLength({\n    bitrateKbit: mp3BitrateInfo.bitrateInKbit,\n    padding: false,\n    samplesPerFrame,\n    samplingFrequency: mp3Info.sampleRate,\n    layer: mp3Info.layer\n  });\n  const frames = Math.floor((state.contentLength - state.mediaSection.getMediaSectionAssertOnlyOne().start) / frameLengthInBytes);\n  const samples = frames * samplesPerFrame;\n  const durationInSeconds = samples / mp3Info.sampleRate;\n  return durationInSeconds;\n};\n\n// src/containers/riff/get-duration.ts\nvar getDurationFromAvi = (structure) => {\n  const strl = getStrlBoxes(structure);\n  const lengths = [];\n  for (const s of strl) {\n    const strh = getStrhBox(s.children);\n    if (!strh) {\n      throw new Error(\"No strh box\");\n    }\n    const samplesPerSecond = strh.rate / strh.scale;\n    const streamLength = strh.length / samplesPerSecond;\n    lengths.push(streamLength);\n  }\n  return Math.max(...lengths);\n};\n\n// src/containers/wav/get-duration-from-wav.ts\nvar getDurationFromWav = (state) => {\n  const structure = state.structure.getWavStructure();\n  const fmt = structure.boxes.find((b) => b.type === \"wav-fmt\");\n  if (!fmt) {\n    throw new Error(\"Expected fmt box\");\n  }\n  const dataBox = structure.boxes.find((b) => b.type === \"wav-data\");\n  if (!dataBox) {\n    throw new Error(\"Expected data box\");\n  }\n  const durationInSeconds = dataBox.dataSize / (fmt.sampleRate * fmt.blockAlign);\n  return durationInSeconds;\n};\n\n// src/state/iso-base-media/precomputed-tfra.ts\nvar precomputedTfraState = () => {\n  let tfraBoxes = [];\n  return {\n    getTfraBoxes: () => tfraBoxes,\n    setTfraBoxes: (boxes) => {\n      tfraBoxes = boxes;\n    }\n  };\n};\nvar deduplicateTfraBoxesByOffset = (tfraBoxes) => {\n  return tfraBoxes.filter((m, i, arr) => i === arr.findIndex((t) => t.offset === m.offset));\n};\n\n// src/get-duration.ts\nvar getDurationFromMatroska = (segments) => {\n  const mainSegment = segments.find((s) => s.type === \"Segment\");\n  if (!mainSegment || mainSegment.type !== \"Segment\") {\n    return null;\n  }\n  const { value: children } = mainSegment;\n  if (!children) {\n    return null;\n  }\n  const infoSegment = children.find((s) => s.type === \"Info\");\n  const relevantBoxes = [\n    ...mainSegment.value,\n    ...infoSegment && infoSegment.type === \"Info\" ? infoSegment.value : []\n  ];\n  const timestampScale2 = relevantBoxes.find((s) => s.type === \"TimestampScale\");\n  if (!timestampScale2 || timestampScale2.type !== \"TimestampScale\") {\n    return null;\n  }\n  const duration2 = relevantBoxes.find((s) => s.type === \"Duration\");\n  if (!duration2 || duration2.type !== \"Duration\") {\n    return null;\n  }\n  return duration2.value.value / timestampScale2.value.value * 1000;\n};\nvar getDurationFromIsoBaseMedia = (parserState) => {\n  const structure = parserState.structure.getIsoStructure();\n  const moovBox = getMoovBoxFromState({\n    structureState: parserState.structure,\n    isoState: parserState.iso,\n    mp4HeaderSegment: parserState.m3uPlaylistContext?.mp4HeaderSegment ?? null,\n    mayUsePrecomputed: true\n  });\n  if (!moovBox) {\n    return null;\n  }\n  const moofBoxes = getMoofBoxes(structure.boxes);\n  const mfra = parserState.iso.mfra.getIfAlreadyLoaded();\n  const tfraBoxes = deduplicateTfraBoxesByOffset([\n    ...mfra ? getTfraBoxesFromMfraBoxChildren(mfra) : [],\n    ...getTfraBoxes(structure.boxes)\n  ]);\n  if (!areSamplesComplete({ moofBoxes, tfraBoxes })) {\n    return null;\n  }\n  const mvhdBox = getMvhdBox(moovBox);\n  if (!mvhdBox) {\n    return null;\n  }\n  if (mvhdBox.type !== \"mvhd-box\") {\n    throw new Error(\"Expected mvhd-box\");\n  }\n  if (mvhdBox.durationInSeconds > 0) {\n    return mvhdBox.durationInSeconds;\n  }\n  const tracks2 = getTracks(parserState, true);\n  const allSamples = tracks2.map((t) => {\n    const { originalTimescale: ts } = t;\n    const trakBox = getTrakBoxByTrackId(moovBox, t.trackId);\n    if (!trakBox) {\n      return null;\n    }\n    const { samplePositions, isComplete } = getSamplePositionsFromTrack({\n      trakBox,\n      moofBoxes,\n      moofComplete: areSamplesComplete({ moofBoxes, tfraBoxes }),\n      trexBoxes: getTrexBoxes(moovBox)\n    });\n    if (!isComplete) {\n      return null;\n    }\n    if (samplePositions.length === 0) {\n      return null;\n    }\n    const highest = samplePositions?.map((sp) => (sp.timestamp + sp.duration) / ts).reduce((a, b) => Math.max(a, b), 0);\n    return highest ?? 0;\n  });\n  if (allSamples.every((s) => s === null)) {\n    return null;\n  }\n  const highestTimestamp = Math.max(...allSamples.filter((s) => s !== null));\n  return highestTimestamp;\n};\nvar getDuration = (parserState) => {\n  const structure = parserState.structure.getStructure();\n  if (structure.type === \"matroska\") {\n    return getDurationFromMatroska(structure.boxes);\n  }\n  if (structure.type === \"iso-base-media\") {\n    return getDurationFromIsoBaseMedia(parserState);\n  }\n  if (structure.type === \"riff\") {\n    return getDurationFromAvi(structure);\n  }\n  if (structure.type === \"transport-stream\") {\n    return null;\n  }\n  if (structure.type === \"mp3\") {\n    return getDurationFromMp3(parserState);\n  }\n  if (structure.type === \"wav\") {\n    return getDurationFromWav(parserState);\n  }\n  if (structure.type === \"aac\") {\n    return null;\n  }\n  if (structure.type === \"flac\") {\n    return getDurationFromFlac(parserState);\n  }\n  if (structure.type === \"m3u\") {\n    return getDurationFromM3u(parserState);\n  }\n  throw new Error(\"Has no duration \" + structure);\n};\nvar hasDuration = (parserState) => {\n  const structure = parserState.structure.getStructureOrNull();\n  if (structure === null) {\n    return false;\n  }\n  return getHasTracks(parserState, true);\n};\nvar hasSlowDuration = (parserState) => {\n  try {\n    if (!hasDuration(parserState)) {\n      return false;\n    }\n    return getDuration(parserState) !== null;\n  } catch {\n    return false;\n  }\n};\n\n// src/get-is-hdr.ts\nvar isVideoTrackHdr = (track) => {\n  return track.advancedColor.matrix === \"bt2020-ncl\" && (track.advancedColor.transfer === \"hlg\" || track.advancedColor.transfer === \"pq\") && track.advancedColor.primaries === \"bt2020\";\n};\nvar getIsHdr = (state) => {\n  const tracks2 = getTracks(state, true);\n  return tracks2.some((track) => track.type === \"video\" && isVideoTrackHdr(track));\n};\nvar hasHdr = (state) => {\n  return getHasTracks(state, true);\n};\n\n// src/containers/iso-base-media/get-keyframes.ts\nvar getKeyframesFromIsoBaseMedia = (state) => {\n  const tracks2 = getTracksFromIsoBaseMedia({\n    isoState: state.iso,\n    m3uPlaylistContext: state.m3uPlaylistContext,\n    structure: state.structure,\n    mayUsePrecomputed: true\n  });\n  const videoTracks = tracks2.filter((t) => t.type === \"video\");\n  const structure = state.structure.getIsoStructure();\n  const moofBoxes = getMoofBoxes(structure.boxes);\n  const tfraBoxes = getTfraBoxes(structure.boxes);\n  const moov = getMoovFromFromIsoStructure(structure);\n  if (!moov) {\n    return [];\n  }\n  const allSamples = videoTracks.map((t) => {\n    const { originalTimescale: ts } = t;\n    const trakBox = getTrakBoxByTrackId(moov, t.trackId);\n    if (!trakBox) {\n      return [];\n    }\n    const { samplePositions, isComplete } = getSamplePositionsFromTrack({\n      trakBox,\n      moofBoxes,\n      moofComplete: areSamplesComplete({\n        moofBoxes,\n        tfraBoxes\n      }),\n      trexBoxes: getTrexBoxes(moov)\n    });\n    if (!isComplete) {\n      return [];\n    }\n    const keyframes = samplePositions.filter((k) => {\n      return k.isKeyframe;\n    }).map((k) => {\n      return {\n        trackId: t.trackId,\n        presentationTimeInSeconds: k.timestamp / ts,\n        decodingTimeInSeconds: k.decodingTimestamp / ts,\n        positionInBytes: k.offset,\n        sizeInBytes: k.size\n      };\n    });\n    return keyframes;\n  });\n  return allSamples.flat();\n};\n\n// src/get-keyframes.ts\nvar getKeyframes = (state) => {\n  const structure = state.structure.getStructure();\n  if (structure.type === \"iso-base-media\") {\n    return getKeyframesFromIsoBaseMedia(state);\n  }\n  return null;\n};\nvar hasKeyframes = (parserState) => {\n  const structure = parserState.structure.getStructure();\n  if (structure.type === \"iso-base-media\") {\n    return getHasTracks(parserState, true);\n  }\n  return true;\n};\n\n// src/containers/flac/get-metadata-from-flac.ts\nvar getMetadataFromFlac = (structure) => {\n  const box = structure.boxes.find((b) => b.type === \"flac-vorbis-comment\");\n  if (!box) {\n    return null;\n  }\n  return box.fields;\n};\n\n// src/containers/mp3/get-metadata-from-mp3.ts\nvar getMetadataFromMp3 = (mp3Structure) => {\n  const findHeader = mp3Structure.boxes.find((b) => b.type === \"id3-header\");\n  return findHeader ? findHeader.metatags : null;\n};\n\n// src/containers/wav/get-metadata-from-wav.ts\nvar getMetadataFromWav = (structure) => {\n  const list = structure.boxes.find((b) => b.type === \"wav-list\");\n  if (!list) {\n    return null;\n  }\n  return list.metadata;\n};\n\n// src/metadata/metadata-from-iso.ts\nvar mapToKey = (index) => {\n  if (index === \"ART\") {\n    return \"artist\";\n  }\n  if (index === \"alb\") {\n    return \"album\";\n  }\n  if (index === \"cmt\") {\n    return \"comment\";\n  }\n  if (index === \"day\") {\n    return \"releaseDate\";\n  }\n  if (index === \"gen\") {\n    return \"genre\";\n  }\n  if (index === \"nam\") {\n    return \"title\";\n  }\n  if (index === \"too\") {\n    return \"encoder\";\n  }\n  if (index === \"wrt\") {\n    return \"writer\";\n  }\n  if (index === \"cpy\") {\n    return \"copyright\";\n  }\n  if (index === \"dir\") {\n    return \"director\";\n  }\n  if (index === \"prd\") {\n    return \"producer\";\n  }\n  if (index === \"des\") {\n    return \"description\";\n  }\n  return null;\n};\nvar parseIlstBoxWithoutKeys = (ilstBox) => {\n  return ilstBox.entries.map((entry) => {\n    const key = mapToKey(entry.index);\n    if (!key) {\n      return null;\n    }\n    if (entry.value.type === \"unknown\") {\n      return null;\n    }\n    return {\n      trackId: null,\n      key,\n      value: entry.value.value\n    };\n  }).filter(truthy);\n};\nvar parseIsoMetaBox = (meta, trackId) => {\n  const ilstBox = meta.children.find((b) => b.type === \"ilst-box\");\n  const keysBox = meta.children.find((b) => b.type === \"keys-box\");\n  if (!ilstBox || !keysBox) {\n    if (ilstBox) {\n      return parseIlstBoxWithoutKeys(ilstBox);\n    }\n    return [];\n  }\n  const entries = [];\n  for (let i = 0;i < ilstBox.entries.length; i++) {\n    const ilstEntry = ilstBox.entries[i];\n    const keysEntry = keysBox.entries[i];\n    if (ilstEntry.value.type !== \"unknown\") {\n      const value = typeof ilstEntry.value.value === \"string\" && ilstEntry.value.value.endsWith(\"\\x00\") ? ilstEntry.value.value.slice(0, -1) : ilstEntry.value.value;\n      entries.push({\n        key: keysEntry.value,\n        value,\n        trackId\n      });\n    }\n  }\n  return entries;\n};\nvar getMetadataFromIsoBase = (state) => {\n  const moov = getMoovBoxFromState({\n    structureState: state.structure,\n    isoState: state.iso,\n    mp4HeaderSegment: state.m3uPlaylistContext?.mp4HeaderSegment ?? null,\n    mayUsePrecomputed: true\n  });\n  if (!moov) {\n    return [];\n  }\n  const traks = getTraks(moov);\n  const meta = moov.children.find((b) => b.type === \"regular-box\" && b.boxType === \"meta\");\n  const udta = moov.children.find((b) => b.type === \"regular-box\" && b.boxType === \"udta\");\n  const metaInUdta = udta?.children.find((b) => {\n    return b.type === \"regular-box\" && b.boxType === \"meta\";\n  });\n  const metaInTracks = traks.map((t) => {\n    const metaBox = t.children.find((child) => child.type === \"regular-box\" && child.boxType === \"meta\");\n    if (metaBox) {\n      const tkhd = getTkhdBox(t);\n      if (!tkhd) {\n        throw new Error(\"No tkhd box found\");\n      }\n      return parseIsoMetaBox(metaBox, tkhd.trackId);\n    }\n    return null;\n  }).filter(truthy);\n  return [\n    ...meta ? parseIsoMetaBox(meta, null) : [],\n    ...metaInUdta ? parseIsoMetaBox(metaInUdta, null) : [],\n    ...metaInTracks.flat(1)\n  ];\n};\n\n// src/metadata/metadata-from-matroska.ts\nvar removeEndZeroes = (value) => {\n  return value.endsWith(\"\\x00\") ? removeEndZeroes(value.slice(0, -1)) : value;\n};\nvar parseSimpleTagIntoEbml = (children, trackId) => {\n  const tagName = children.find((c) => c.type === \"TagName\");\n  const tagString = children.find((c) => c.type === \"TagString\");\n  if (!tagName || !tagString) {\n    return null;\n  }\n  return {\n    trackId,\n    key: tagName.value.toLowerCase(),\n    value: removeEndZeroes(tagString.value)\n  };\n};\nvar getMetadataFromMatroska = (structure) => {\n  const entries = [];\n  for (const segment of structure.boxes) {\n    if (segment.type !== \"Segment\") {\n      continue;\n    }\n    const tags2 = segment.value.filter((s) => s.type === \"Tags\");\n    for (const tag of tags2) {\n      for (const child of tag.value) {\n        if (child.type !== \"Tag\") {\n          continue;\n        }\n        let trackId = null;\n        const target = child.value.find((c) => c.type === \"Targets\");\n        if (target) {\n          const tagTrackId = target.value.find((c) => c.type === \"TagTrackUID\")?.value;\n          if (tagTrackId) {\n            trackId = getTrackWithUid(segment, tagTrackId);\n          }\n        }\n        const simpleTags = child.value.filter((s) => s.type === \"SimpleTag\");\n        for (const simpleTag of simpleTags) {\n          const parsed = parseSimpleTagIntoEbml(simpleTag.value, trackId);\n          if (parsed) {\n            entries.push(parsed);\n          }\n        }\n      }\n    }\n  }\n  return entries;\n};\n\n// src/metadata/metadata-from-riff.ts\nvar getMetadataFromRiff = (structure) => {\n  const boxes = structure.boxes.find((b) => b.type === \"list-box\" && b.listType === \"INFO\");\n  if (!boxes) {\n    return [];\n  }\n  const { children } = boxes;\n  return children.map((child) => {\n    if (child.type !== \"isft-box\") {\n      return null;\n    }\n    return {\n      trackId: null,\n      key: \"encoder\",\n      value: child.software\n    };\n  }).filter(truthy);\n};\n\n// src/metadata/get-metadata.ts\nvar getMetadata = (state) => {\n  const structure = state.structure.getStructure();\n  if (structure.type === \"matroska\") {\n    return getMetadataFromMatroska(structure);\n  }\n  if (structure.type === \"riff\") {\n    return getMetadataFromRiff(structure);\n  }\n  if (structure.type === \"transport-stream\" || structure.type === \"m3u\") {\n    return [];\n  }\n  if (structure.type === \"mp3\") {\n    const tags2 = getMetadataFromMp3(structure);\n    if (tags2 === null) {\n      throw new Error(\"Failed to get metadata from mp3\");\n    }\n    return tags2;\n  }\n  if (structure.type === \"wav\") {\n    return getMetadataFromWav(structure) ?? [];\n  }\n  if (structure.type === \"aac\") {\n    return [];\n  }\n  if (structure.type === \"flac\") {\n    return getMetadataFromFlac(structure) ?? [];\n  }\n  if (structure.type === \"iso-base-media\") {\n    return getMetadataFromIsoBase(state);\n  }\n  throw new Error(\"Unknown container \" + structure);\n};\nvar hasMetadata = (structure) => {\n  if (structure.type === \"mp3\") {\n    return getMetadataFromMp3(structure) !== null;\n  }\n  if (structure.type === \"wav\") {\n    return getMetadataFromWav(structure) !== null;\n  }\n  if (structure.type === \"m3u\" || structure.type === \"transport-stream\" || structure.type === \"aac\") {\n    return true;\n  }\n  if (structure.type === \"flac\") {\n    return getMetadataFromFlac(structure) !== null;\n  }\n  if (structure.type === \"iso-base-media\") {\n    return false;\n  }\n  if (structure.type === \"matroska\") {\n    return false;\n  }\n  if (structure.type === \"riff\") {\n    return false;\n  }\n  throw new Error(\"Unknown container \" + structure);\n};\n\n// src/get-location.ts\nfunction parseLocation(locationString) {\n  const locationPattern = /^([+-]\\d{2}\\.?\\d{0,10})([+-]\\d{3}\\.?\\d{0,10})([+-]\\d+(\\.\\d+)?)?\\/$/;\n  const match = locationString.match(locationPattern);\n  if (!match) {\n    return null;\n  }\n  const latitude = parseFloat(match[1]);\n  const longitude = parseFloat(match[2]);\n  const altitude = match[3] ? parseFloat(match[3]) : null;\n  return {\n    latitude,\n    longitude,\n    altitude\n  };\n}\nvar getLocation = (state) => {\n  const metadata = getMetadata(state);\n  const locationEntry = metadata.find((entry) => entry.key === \"com.apple.quicktime.location.ISO6709\");\n  const horizontalAccuracy = metadata.find((entry) => entry.key === \"com.apple.quicktime.location.accuracy.horizontal\");\n  if (locationEntry) {\n    const parsed = parseLocation(locationEntry.value);\n    if (parsed === null) {\n      return null;\n    }\n    return {\n      ...parsed,\n      horizontalAccuracy: horizontalAccuracy?.value ? parseFloat(String(horizontalAccuracy.value)) : null\n    };\n  }\n  return null;\n};\n\n// src/get-number-of-audio-channels.ts\nvar getNumberOfAudioChannels = (state) => {\n  return state.callbacks.tracks.getTracks().find((track) => {\n    return track.type === \"audio\";\n  })?.numberOfChannels ?? null;\n};\nvar hasNumberOfAudioChannels = (state) => {\n  return state.callbacks.tracks.hasAllTracks();\n};\n\n// src/get-sample-rate.ts\nvar getSampleRate3 = (state) => {\n  return state.callbacks.tracks.getTracks().find((track) => {\n    return track.type === \"audio\";\n  })?.sampleRate ?? null;\n};\nvar hasSampleRate = (state) => {\n  return state.callbacks.tracks.hasAllTracks();\n};\n\n// src/containers/aac/get-seeking-byte.ts\nvar getSeekingByteForAac = ({\n  time,\n  seekingHints\n}) => {\n  let bestAudioSample;\n  for (const hint of seekingHints.audioSampleMap) {\n    if (hint.timeInSeconds > time) {\n      continue;\n    }\n    if (hint.timeInSeconds + hint.durationInSeconds < time && !seekingHints.lastSampleObserved) {\n      continue;\n    }\n    if (!bestAudioSample) {\n      bestAudioSample = hint;\n      continue;\n    }\n    if (bestAudioSample.timeInSeconds < hint.timeInSeconds) {\n      bestAudioSample = hint;\n    }\n  }\n  if (bestAudioSample) {\n    return {\n      type: \"do-seek\",\n      byte: bestAudioSample.offset,\n      timeInSeconds: bestAudioSample.timeInSeconds\n    };\n  }\n  return { type: \"valid-but-must-wait\" };\n};\n\n// src/containers/flac/get-seeking-byte.ts\nvar getSeekingByteForFlac = ({\n  time,\n  seekingHints\n}) => {\n  let bestAudioSample;\n  for (const hint of seekingHints.audioSampleMap) {\n    if (hint.timeInSeconds > time) {\n      continue;\n    }\n    if (hint.timeInSeconds + hint.durationInSeconds < time && !seekingHints.lastSampleObserved) {\n      continue;\n    }\n    if (!bestAudioSample) {\n      bestAudioSample = hint;\n      continue;\n    }\n    if (bestAudioSample.timeInSeconds < hint.timeInSeconds) {\n      bestAudioSample = hint;\n    }\n  }\n  if (bestAudioSample) {\n    return bestAudioSample;\n  }\n  return null;\n};\n\n// src/containers/iso-base-media/find-keyframe-before-time.ts\nvar findKeyframeBeforeTime = ({\n  samplePositions,\n  time,\n  timescale,\n  mediaSections,\n  logLevel,\n  startInSeconds\n}) => {\n  let videoByte = 0;\n  let videoSample = null;\n  for (const sample of samplePositions) {\n    const ctsInSeconds = sample.timestamp / timescale + startInSeconds;\n    const dtsInSeconds = sample.decodingTimestamp / timescale + startInSeconds;\n    if (!sample.isKeyframe) {\n      continue;\n    }\n    if (!(ctsInSeconds <= time || dtsInSeconds <= time)) {\n      continue;\n    }\n    if (videoByte <= sample.offset) {\n      videoByte = sample.offset;\n      videoSample = sample;\n    }\n  }\n  if (!videoSample) {\n    throw new Error(\"No sample found\");\n  }\n  const mediaSection = mediaSections.find((section) => videoSample.offset >= section.start && videoSample.offset < section.start + section.size);\n  if (!mediaSection) {\n    Log.trace(logLevel, \"Found a sample, but the offset has not yet been marked as a video section yet. Not yet able to seek, but probably once we have started reading the next box.\", videoSample);\n    return null;\n  }\n  return videoSample;\n};\n\n// src/containers/iso-base-media/find-track-to-seek.ts\nvar findAnyTrackWithSamplePositions = (allTracks, struc) => {\n  const moov = getMoovFromFromIsoStructure(struc);\n  if (!moov) {\n    return null;\n  }\n  for (const track of allTracks) {\n    if (track.type === \"video\" || track.type === \"audio\") {\n      const trakBox = getTrakBoxByTrackId(moov, track.trackId);\n      if (!trakBox) {\n        continue;\n      }\n      const { samplePositions } = getSamplePositionsFromTrack({\n        trakBox,\n        moofBoxes: getMoofBoxes(struc.boxes),\n        moofComplete: areSamplesComplete({\n          moofBoxes: getMoofBoxes(struc.boxes),\n          tfraBoxes: getTfraBoxes(struc.boxes)\n        }),\n        trexBoxes: getTrexBoxes(moov)\n      });\n      if (samplePositions.length === 0) {\n        continue;\n      }\n      return { track, samplePositions };\n    }\n  }\n  return null;\n};\nvar findTrackToSeek = (allTracks, structure) => {\n  const firstVideoTrack = allTracks.find((t) => t.type === \"video\");\n  const struc = structure.getIsoStructure();\n  if (!firstVideoTrack) {\n    return findAnyTrackWithSamplePositions(allTracks, struc);\n  }\n  const moov = getMoovFromFromIsoStructure(struc);\n  if (!moov) {\n    return null;\n  }\n  const trakBox = getTrakBoxByTrackId(moov, firstVideoTrack.trackId);\n  if (!trakBox) {\n    return null;\n  }\n  const { samplePositions } = getSamplePositionsFromTrack({\n    trakBox,\n    moofBoxes: getMoofBoxes(struc.boxes),\n    moofComplete: areSamplesComplete({\n      moofBoxes: getMoofBoxes(struc.boxes),\n      tfraBoxes: getTfraBoxes(struc.boxes)\n    }),\n    trexBoxes: getTrexBoxes(moov)\n  });\n  if (samplePositions.length === 0) {\n    return findAnyTrackWithSamplePositions(allTracks, struc);\n  }\n  return { track: firstVideoTrack, samplePositions };\n};\n\n// src/state/video-section.ts\nvar isByteInMediaSection = ({\n  position,\n  mediaSections\n}) => {\n  if (mediaSections.length === 0) {\n    return \"no-section-defined\";\n  }\n  for (const section of mediaSections) {\n    if (position >= section.start && position < section.start + section.size) {\n      return \"in-section\";\n    }\n  }\n  return \"outside-section\";\n};\nvar getCurrentMediaSection = ({\n  offset,\n  mediaSections\n}) => {\n  for (const section of mediaSections) {\n    if (offset >= section.start && offset < section.start + section.size) {\n      return section;\n    }\n  }\n  return null;\n};\nvar mediaSectionState = () => {\n  const mediaSections = [];\n  const addMediaSection = (section) => {\n    const overlaps = mediaSections.some((existingSection) => section.start < existingSection.start + existingSection.size && section.start + section.size > existingSection.start);\n    if (overlaps) {\n      return;\n    }\n    for (let i = mediaSections.length - 1;i >= 0; i--) {\n      const existingSection = mediaSections[i];\n      if (section.start <= existingSection.start && section.start + section.size >= existingSection.start + existingSection.size) {\n        mediaSections.splice(i, 1);\n      }\n    }\n    mediaSections.push(section);\n  };\n  const getMediaSections = () => {\n    return mediaSections;\n  };\n  const isCurrentByteInMediaSection = (iterator) => {\n    const offset = iterator.counter.getOffset();\n    return isByteInMediaSection({\n      position: offset,\n      mediaSections\n    });\n  };\n  const getMediaSectionAssertOnlyOne = () => {\n    if (mediaSections.length !== 1) {\n      throw new Error(\"Expected only one video section\");\n    }\n    return mediaSections[0];\n  };\n  return {\n    addMediaSection,\n    getMediaSections,\n    isCurrentByteInMediaSection,\n    isByteInMediaSection,\n    getCurrentMediaSection,\n    getMediaSectionAssertOnlyOne,\n    mediaSections\n  };\n};\n\n// src/containers/iso-base-media/get-sample-position-bounds.ts\nvar getSamplePositionBounds = (samplePositions, timescale) => {\n  let min = Infinity;\n  let max = -Infinity;\n  for (const samplePosition of samplePositions) {\n    const timestampMin = Math.min(samplePosition.timestamp, samplePosition.decodingTimestamp);\n    const timestampMax = Math.max(samplePosition.timestamp, samplePosition.decodingTimestamp) + (samplePosition.duration ?? 0);\n    if (timestampMin < min) {\n      min = timestampMin;\n    }\n    if (timestampMax > max) {\n      max = timestampMax;\n    }\n  }\n  return { min: min / timescale, max: max / timescale };\n};\n\n// src/containers/iso-base-media/mfra/find-best-segment-from-tfra.ts\nvar findBestSegmentFromTfra = ({\n  mfra,\n  time,\n  firstTrack,\n  timescale\n}) => {\n  const tfra = mfra.find((b) => b.type === \"tfra-box\" && b.trackId === firstTrack.trackId);\n  if (!tfra) {\n    return null;\n  }\n  let bestSegment = null;\n  for (const segment of tfra.entries) {\n    if (segment.time / timescale <= time) {\n      bestSegment = segment;\n    }\n  }\n  if (!bestSegment) {\n    return null;\n  }\n  const currentSegmentIndex = tfra.entries.indexOf(bestSegment);\n  const offsetOfNext = currentSegmentIndex === tfra.entries.length - 1 ? Infinity : tfra.entries[currentSegmentIndex + 1].moofOffset;\n  return {\n    start: bestSegment.moofOffset,\n    end: offsetOfNext\n  };\n};\n\n// src/containers/iso-base-media/get-seeking-byte-from-fragmented-mp4.ts\nvar getSeekingByteFromFragmentedMp4 = async ({\n  info,\n  time,\n  logLevel,\n  currentPosition,\n  isoState,\n  tracks: tracks2,\n  isLastChunkInPlaylist,\n  structure,\n  mp4HeaderSegment\n}) => {\n  const firstVideoTrack = tracks2.find((t) => t.type === \"video\");\n  const firstTrack = firstVideoTrack ?? tracks2.find((t) => t.type === \"audio\");\n  if (!firstTrack) {\n    throw new Error(\"no video and no audio tracks\");\n  }\n  const moov = getMoovBoxFromState({\n    structureState: structure,\n    isoState,\n    mp4HeaderSegment,\n    mayUsePrecomputed: true\n  });\n  if (!moov) {\n    throw new Error(\"No moov atom found\");\n  }\n  const trakBox = getTrakBoxByTrackId(moov, firstTrack.trackId);\n  if (!trakBox) {\n    throw new Error(\"No trak box found\");\n  }\n  const tkhdBox = getTkhdBox(trakBox);\n  if (!tkhdBox) {\n    throw new Error(\"Expected tkhd box in trak box\");\n  }\n  const isComplete = areSamplesComplete({\n    moofBoxes: info.moofBoxes,\n    tfraBoxes: info.tfraBoxes\n  });\n  const { samplePositions: samplePositionsArray } = collectSamplePositionsFromMoofBoxes({\n    moofBoxes: info.moofBoxes,\n    tkhdBox,\n    isComplete,\n    trexBoxes: getTrexBoxes(moov)\n  });\n  Log.trace(logLevel, \"Fragmented MP4 - Checking if we have seeking info for this time range\");\n  for (const positions of samplePositionsArray) {\n    const { min, max } = getSamplePositionBounds(positions.samples, firstTrack.originalTimescale);\n    if (min <= time && (positions.isLastFragment || isLastChunkInPlaylist || time <= max)) {\n      Log.trace(logLevel, `Fragmented MP4 - Found that we have seeking info for this time range: ${min} <= ${time} <= ${max}`);\n      const kf = findKeyframeBeforeTime({\n        samplePositions: positions.samples,\n        time,\n        timescale: firstTrack.originalTimescale,\n        logLevel,\n        mediaSections: info.mediaSections,\n        startInSeconds: firstTrack.startInSeconds\n      });\n      if (kf) {\n        return {\n          type: \"do-seek\",\n          byte: kf.offset,\n          timeInSeconds: Math.min(kf.decodingTimestamp, kf.timestamp) / firstTrack.originalTimescale\n        };\n      }\n    }\n  }\n  const atom = await (info.mfraAlreadyLoaded ? Promise.resolve(info.mfraAlreadyLoaded) : isoState.mfra.triggerLoad());\n  if (atom) {\n    const moofOffset = findBestSegmentFromTfra({\n      mfra: atom,\n      time,\n      firstTrack,\n      timescale: firstTrack.originalTimescale\n    });\n    if (moofOffset !== null && !(moofOffset.start <= currentPosition && currentPosition < moofOffset.end)) {\n      Log.verbose(logLevel, `Fragmented MP4 - Found based on mfra information that we should seek to: ${moofOffset.start} ${moofOffset.end}`);\n      return {\n        type: \"intermediary-seek\",\n        byte: moofOffset.start\n      };\n    }\n  }\n  Log.trace(logLevel, \"Fragmented MP4 - No seeking info found for this time range.\");\n  if (isByteInMediaSection({\n    position: currentPosition,\n    mediaSections: info.mediaSections\n  }) !== \"in-section\") {\n    return {\n      type: \"valid-but-must-wait\"\n    };\n  }\n  Log.trace(logLevel, \"Fragmented MP4 - Inside the wrong video section, skipping to the end of the section\");\n  const mediaSection = getCurrentMediaSection({\n    offset: currentPosition,\n    mediaSections: info.mediaSections\n  });\n  if (!mediaSection) {\n    throw new Error(\"No video section defined\");\n  }\n  return {\n    type: \"intermediary-seek\",\n    byte: mediaSection.start + mediaSection.size\n  };\n};\n\n// src/containers/iso-base-media/get-seeking-byte.ts\nvar getSeekingByteFromIsoBaseMedia = ({\n  info,\n  time,\n  logLevel,\n  currentPosition,\n  isoState,\n  m3uPlaylistContext,\n  structure\n}) => {\n  const tracks2 = getTracksFromIsoBaseMedia({\n    isoState,\n    m3uPlaylistContext,\n    structure,\n    mayUsePrecomputed: false\n  });\n  const hasMoov = Boolean(getMoovBoxFromState({\n    structureState: structure,\n    isoState,\n    mayUsePrecomputed: false,\n    mp4HeaderSegment: m3uPlaylistContext?.mp4HeaderSegment ?? null\n  }));\n  if (!hasMoov) {\n    Log.trace(logLevel, \"No moov box found, must wait\");\n    return Promise.resolve({\n      type: \"valid-but-must-wait\"\n    });\n  }\n  if (info.moofBoxes.length > 0) {\n    return getSeekingByteFromFragmentedMp4({\n      info,\n      time,\n      logLevel,\n      currentPosition,\n      isoState,\n      tracks: tracks2,\n      isLastChunkInPlaylist: m3uPlaylistContext?.isLastChunkInPlaylist ?? false,\n      structure,\n      mp4HeaderSegment: m3uPlaylistContext?.mp4HeaderSegment ?? null\n    });\n  }\n  const trackWithSamplePositions = findTrackToSeek(tracks2, structure);\n  if (!trackWithSamplePositions) {\n    return Promise.resolve({\n      type: \"valid-but-must-wait\"\n    });\n  }\n  const { track, samplePositions } = trackWithSamplePositions;\n  const keyframe = findKeyframeBeforeTime({\n    samplePositions,\n    time,\n    timescale: track.originalTimescale,\n    logLevel,\n    mediaSections: info.mediaSections,\n    startInSeconds: track.startInSeconds\n  });\n  if (keyframe) {\n    return Promise.resolve({\n      type: \"do-seek\",\n      byte: keyframe.offset,\n      timeInSeconds: Math.min(keyframe.decodingTimestamp, keyframe.timestamp) / track.originalTimescale\n    });\n  }\n  return Promise.resolve({\n    type: \"invalid\"\n  });\n};\n\n// src/containers/m3u/get-seeking-byte.ts\nvar clearM3uStateInPrepareForSeek = ({\n  m3uState,\n  logLevel\n}) => {\n  const selectedPlaylists = m3uState.getSelectedPlaylists();\n  for (const playlistUrl of selectedPlaylists) {\n    const streamRun = m3uState.getM3uStreamRun(playlistUrl);\n    if (streamRun) {\n      streamRun.abort();\n    }\n    Log.trace(logLevel, \"Clearing M3U stream run for\", playlistUrl);\n    m3uState.setM3uStreamRun(playlistUrl, null);\n  }\n  m3uState.clearAllChunksProcessed();\n  m3uState.sampleSorter.clearSamples();\n};\nvar getSeekingByteForM3u8 = ({\n  time,\n  currentPosition,\n  m3uState,\n  logLevel\n}) => {\n  clearM3uStateInPrepareForSeek({ m3uState, logLevel });\n  const selectedPlaylists = m3uState.getSelectedPlaylists();\n  for (const playlistUrl of selectedPlaylists) {\n    m3uState.setSeekToSecondsToProcess(playlistUrl, {\n      targetTime: time\n    });\n  }\n  return {\n    type: \"do-seek\",\n    byte: currentPosition,\n    timeInSeconds: time\n  };\n};\n\n// src/containers/mp3/seek/get-approximate-byte-from-bitrate.ts\nvar getApproximateByteFromBitrate = ({\n  mp3BitrateInfo,\n  timeInSeconds,\n  mp3Info,\n  mediaSection,\n  contentLength\n}) => {\n  if (mp3BitrateInfo.type === \"variable\") {\n    return null;\n  }\n  const samplesPerFrame = getSamplesPerMpegFrame({\n    layer: mp3Info.layer,\n    mpegVersion: mp3Info.mpegVersion\n  });\n  const frameLengthInBytes = getMpegFrameLength({\n    bitrateKbit: mp3BitrateInfo.bitrateInKbit,\n    padding: false,\n    samplesPerFrame,\n    samplingFrequency: mp3Info.sampleRate,\n    layer: mp3Info.layer\n  });\n  const frameIndexUnclamped = Math.floor(timeInSeconds * mp3Info.sampleRate / samplesPerFrame);\n  const frames = Math.floor((contentLength - mediaSection.start) / frameLengthInBytes);\n  const frameIndex = Math.min(frames - 1, frameIndexUnclamped);\n  const byteRelativeToMediaSection = frameIndex * frameLengthInBytes;\n  const byteBeforeFrame = byteRelativeToMediaSection + mediaSection.start;\n  return byteBeforeFrame;\n};\n\n// src/containers/mp3/seek/get-byte-from-observed-samples.ts\nvar getByteFromObservedSamples = ({\n  info,\n  timeInSeconds\n}) => {\n  let bestAudioSample;\n  for (const hint of info.audioSampleMap) {\n    if (hint.timeInSeconds > timeInSeconds) {\n      continue;\n    }\n    if (hint.timeInSeconds + hint.durationInSeconds < timeInSeconds && !info.lastSampleObserved) {\n      continue;\n    }\n    if (!bestAudioSample) {\n      bestAudioSample = hint;\n      continue;\n    }\n    if (bestAudioSample.timeInSeconds < hint.timeInSeconds) {\n      bestAudioSample = hint;\n    }\n  }\n  return bestAudioSample;\n};\n\n// src/containers/mp3/parse-xing.ts\nvar SAMPLE_RATES = [44100, 48000, 32000, 99999];\nvar FRAMES_FLAG = 1;\nvar BYTES_FLAG = 2;\nvar TOC_FLAG = 4;\nvar VBR_SCALE_FLAG = 8;\nvar extractI4 = (data, offset) => {\n  let x = 0;\n  x = data[offset];\n  x <<= 8;\n  x |= data[offset + 1];\n  x <<= 8;\n  x |= data[offset + 2];\n  x <<= 8;\n  x |= data[offset + 3];\n  return x;\n};\nvar parseXing = (data) => {\n  const h_id = data[1] >> 3 & 1;\n  const h_sr_index = data[2] >> 2 & 3;\n  const h_mode = data[3] >> 6 & 3;\n  let xingOffset = 0;\n  if (h_id) {\n    if (h_mode !== 3) {\n      xingOffset += 32 + 4;\n    } else {\n      xingOffset += 17 + 4;\n    }\n  } else if (h_mode !== 3) {\n    xingOffset += 17 + 4;\n  } else {\n    xingOffset += 9 + 4;\n  }\n  const expectXing = new TextDecoder(\"utf8\").decode(data.slice(xingOffset, xingOffset + 4));\n  if (expectXing !== \"Xing\") {\n    throw new Error(\"Invalid Xing header\");\n  }\n  let sampleRate = SAMPLE_RATES[h_sr_index];\n  if (h_id === 0) {\n    sampleRate >>= 1;\n  }\n  let offset = xingOffset + 4;\n  const flags = extractI4(data, offset);\n  offset += 4;\n  let numberOfFrames;\n  let fileSize;\n  let tableOfContents;\n  let vbrScale;\n  if (flags & FRAMES_FLAG) {\n    numberOfFrames = extractI4(data, offset);\n    offset += 4;\n  }\n  if (flags & BYTES_FLAG) {\n    fileSize = extractI4(data, offset);\n    offset += 4;\n  }\n  if (flags & TOC_FLAG) {\n    tableOfContents = data.slice(offset, offset + 100);\n    offset += 100;\n  }\n  if (flags & VBR_SCALE_FLAG) {\n    vbrScale = extractI4(data, offset);\n    offset += 4;\n  }\n  if (offset > data.length) {\n    throw new Error(\"xing header was parsed wrong: read beyond available data\");\n  }\n  return {\n    sampleRate,\n    numberOfFrames: numberOfFrames ?? null,\n    fileSize: fileSize ?? null,\n    tableOfContents: tableOfContents ? Array.from(tableOfContents.slice(0, 100)) : null,\n    vbrScale: vbrScale ?? null\n  };\n};\nvar getSeekPointInBytes = ({\n  fileSize,\n  percentBetween0And100,\n  tableOfContents\n}) => {\n  let index = Math.floor(percentBetween0And100);\n  if (index > 99) {\n    index = 99;\n  }\n  const fa = tableOfContents[index];\n  let fb;\n  if (index < 99) {\n    fb = tableOfContents[index + 1];\n  } else {\n    fb = 256;\n  }\n  const fx = fa + (fb - fa) * (percentBetween0And100 - index);\n  const seekPoint = 1 / 256 * fx * fileSize;\n  return Math.floor(seekPoint);\n};\nvar getTimeFromPosition = ({\n  position,\n  fileSize,\n  tableOfContents,\n  durationInSeconds\n}) => {\n  const positionNormalized = position / fileSize * 256;\n  let index = 0;\n  while (index < 99 && tableOfContents[index + 1] <= positionNormalized) {\n    index++;\n  }\n  const fa = tableOfContents[index];\n  const fb = index < 99 ? tableOfContents[index + 1] : 256;\n  const percentWithinSegment = (positionNormalized - fa) / (fb - fa);\n  const percentBetween0And100 = index + percentWithinSegment;\n  return percentBetween0And100 / 100 * durationInSeconds;\n};\n\n// src/containers/mp3/seek/get-seek-point-from-xing.ts\nvar getSeekPointFromXing = ({\n  timeInSeconds,\n  xingData,\n  mp3Info\n}) => {\n  const samplesPerFrame = getSamplesPerMpegFrame({\n    layer: mp3Info.layer,\n    mpegVersion: mp3Info.mpegVersion\n  });\n  const duration2 = getDurationFromMp3Xing({\n    xingData,\n    samplesPerFrame\n  });\n  const totalSamples = timeInSeconds * xingData.sampleRate;\n  const oneFrameSubtracted = totalSamples - samplesPerFrame;\n  const timeToTarget = Math.max(0, oneFrameSubtracted / xingData.sampleRate);\n  if (!xingData.fileSize || !xingData.tableOfContents) {\n    throw new Error(\"Cannot seek of VBR MP3 file\");\n  }\n  return getSeekPointInBytes({\n    fileSize: xingData.fileSize,\n    percentBetween0And100: timeToTarget / duration2 * 100,\n    tableOfContents: xingData.tableOfContents\n  });\n};\n\n// src/containers/mp3/get-seeking-byte.ts\nvar getSeekingByteForMp3 = ({\n  time,\n  info\n}) => {\n  if (info.mp3BitrateInfo === null || info.mp3Info === null || info.mediaSection === null) {\n    return {\n      type: \"valid-but-must-wait\"\n    };\n  }\n  const approximateByte = getApproximateByteFromBitrate({\n    mp3BitrateInfo: info.mp3BitrateInfo,\n    timeInSeconds: time,\n    mp3Info: info.mp3Info,\n    mediaSection: info.mediaSection,\n    contentLength: info.contentLength\n  });\n  const bestAudioSample = getByteFromObservedSamples({\n    info,\n    timeInSeconds: time\n  });\n  const xingSeekPoint = info.mp3BitrateInfo.type === \"variable\" ? getSeekPointFromXing({\n    mp3Info: info.mp3Info,\n    timeInSeconds: time,\n    xingData: info.mp3BitrateInfo.xingData\n  }) : null;\n  const candidates = [\n    approximateByte,\n    bestAudioSample?.offset ?? null,\n    xingSeekPoint\n  ].filter((b) => b !== null);\n  if (candidates.length === 0) {\n    return {\n      type: \"valid-but-must-wait\"\n    };\n  }\n  const byte = Math.max(...candidates);\n  const timeInSeconds = byte === bestAudioSample?.offset ? bestAudioSample.timeInSeconds : time;\n  return {\n    type: \"do-seek\",\n    byte,\n    timeInSeconds\n  };\n};\n\n// src/find-last-keyframe.ts\nfunction findLastKeyframe({\n  keyframes,\n  timeInSeconds\n}) {\n  let bestKeyframe = null;\n  for (const keyframe of keyframes) {\n    if (keyframe.presentationTimeInSeconds > timeInSeconds && keyframe.decodingTimeInSeconds > timeInSeconds) {\n      break;\n    }\n    if (bestKeyframe === null || keyframe.presentationTimeInSeconds > bestKeyframe.presentationTimeInSeconds) {\n      bestKeyframe = keyframe;\n    }\n  }\n  return bestKeyframe;\n}\n\n// src/containers/riff/get-seeking-byte.ts\nvar getSeekingByteForRiff = async ({\n  info,\n  time,\n  riffState,\n  avcState\n}) => {\n  const idx1Entries = await (info.hasIndex ? riffState.lazyIdx1.waitForLoaded() : Promise.resolve(null));\n  if (idx1Entries === null) {\n    const lastKeyframe = findLastKeyframe({\n      keyframes: info.observedKeyframes,\n      timeInSeconds: time\n    });\n    if (lastKeyframe === null) {\n      return {\n        type: \"valid-but-must-wait\"\n      };\n    }\n    riffState.sampleCounter.setSamplesFromSeek(lastKeyframe.sampleCounts);\n    riffState.queuedBFrames.clear();\n    avcState.clear();\n    return {\n      type: \"do-seek\",\n      byte: lastKeyframe.positionInBytes,\n      timeInSeconds: Math.min(lastKeyframe.decodingTimeInSeconds, lastKeyframe.presentationTimeInSeconds)\n    };\n  }\n  if (idx1Entries.videoTrackIndex === null) {\n    throw new Error(\"videoTrackIndex is null\");\n  }\n  if (info.samplesPerSecond === null) {\n    throw new Error(\"samplesPerSecond is null\");\n  }\n  const index = Math.floor(time * info.samplesPerSecond);\n  let bestEntry = null;\n  for (const entry of idx1Entries.entries) {\n    if (entry.sampleCounts[idx1Entries.videoTrackIndex] > index) {\n      continue;\n    }\n    if (bestEntry && entry.sampleCounts[idx1Entries.videoTrackIndex] < bestEntry.sampleCounts[idx1Entries.videoTrackIndex]) {\n      continue;\n    }\n    bestEntry = entry;\n  }\n  if (!bestEntry) {\n    throw new Error(\"No best entry\");\n  }\n  if (info.moviOffset === null) {\n    throw new Error(\"moviOffset is null\");\n  }\n  riffState.sampleCounter.setSamplesFromSeek(bestEntry.sampleCounts);\n  riffState.queuedBFrames.clear();\n  avcState.clear();\n  return {\n    type: \"do-seek\",\n    byte: bestEntry.offset + info.moviOffset - 4,\n    timeInSeconds: bestEntry.sampleCounts[idx1Entries.videoTrackIndex] / info.samplesPerSecond\n  };\n};\n\n// src/convert-audio-or-video-sample.ts\nvar fixFloat = (value) => {\n  if (value % 1 < 0.0000001) {\n    return Math.floor(value);\n  }\n  if (value % 1 > 0.9999999) {\n    return Math.ceil(value);\n  }\n  return value;\n};\nvar convertAudioOrVideoSampleToWebCodecsTimestamps = ({\n  sample,\n  timescale\n}) => {\n  if (timescale === WEBCODECS_TIMESCALE) {\n    return sample;\n  }\n  const { decodingTimestamp: dts, timestamp } = sample;\n  return {\n    decodingTimestamp: fixFloat(dts * (WEBCODECS_TIMESCALE / timescale)),\n    timestamp: fixFloat(timestamp * (WEBCODECS_TIMESCALE / timescale)),\n    duration: sample.duration === undefined ? undefined : fixFloat(sample.duration * (WEBCODECS_TIMESCALE / timescale)),\n    data: sample.data,\n    type: sample.type,\n    offset: sample.offset,\n    ...\"avc\" in sample ? { avc: sample.avc } : {}\n  };\n};\n\n// src/register-track.ts\nvar registerVideoTrack = async ({\n  track,\n  container,\n  logLevel,\n  onVideoTrack,\n  registerVideoSampleCallback,\n  tracks: tracks2\n}) => {\n  if (tracks2.getTracks().find((t) => t.trackId === track.trackId)) {\n    Log.trace(logLevel, `Track ${track.trackId} already registered, skipping`);\n    return null;\n  }\n  if (track.type !== \"video\") {\n    throw new Error(\"Expected video track\");\n  }\n  tracks2.addTrack(track);\n  if (!onVideoTrack) {\n    return null;\n  }\n  const callback = await onVideoTrack({\n    track,\n    container\n  });\n  await registerVideoSampleCallback(track.trackId, callback ?? null);\n  return callback;\n};\nvar registerAudioTrack = async ({\n  track,\n  container,\n  tracks: tracks2,\n  logLevel,\n  onAudioTrack,\n  registerAudioSampleCallback\n}) => {\n  if (tracks2.getTracks().find((t) => t.trackId === track.trackId)) {\n    Log.trace(logLevel, `Track ${track.trackId} already registered, skipping`);\n    return null;\n  }\n  if (track.type !== \"audio\") {\n    throw new Error(\"Expected audio track\");\n  }\n  tracks2.addTrack(track);\n  if (!onAudioTrack) {\n    return null;\n  }\n  const callback = await onAudioTrack({\n    track,\n    container\n  });\n  await registerAudioSampleCallback(track.trackId, callback ?? null);\n  return callback;\n};\nvar registerVideoTrackWhenProfileIsAvailable = ({\n  state,\n  track,\n  container\n}) => {\n  state.riff.registerOnAvcProfileCallback(async (profile) => {\n    await registerVideoTrack({\n      track: addAvcProfileToTrack(track, profile),\n      container,\n      logLevel: state.logLevel,\n      onVideoTrack: state.onVideoTrack,\n      registerVideoSampleCallback: state.callbacks.registerVideoSampleCallback,\n      tracks: state.callbacks.tracks\n    });\n  });\n};\n\n// src/containers/avc/interpret-sps.ts\nvar getDimensionsFromSps = (sps) => {\n  const height = sps.pic_height_in_map_units_minus1;\n  const width = sps.pic_width_in_mbs_minus1;\n  return {\n    height: (height + 1) * 16 - (sps.frame_crop_bottom_offset ?? 0) * 2 - (sps.frame_crop_top_offset ?? 0) * 2,\n    width: (width + 1) * 16 - (sps.frame_crop_right_offset ?? 0) * 2 - (sps.frame_crop_left_offset ?? 0) * 2\n  };\n};\nvar getSampleAspectRatioFromSps = (sps) => {\n  if (sps.vui_parameters?.sar_height && sps.vui_parameters.sar_width) {\n    return {\n      width: sps.vui_parameters.sar_width,\n      height: sps.vui_parameters.sar_height\n    };\n  }\n  return {\n    width: 1,\n    height: 1\n  };\n};\nvar getVideoColorFromSps = (sps) => {\n  const matrixCoefficients2 = sps.vui_parameters?.matrix_coefficients;\n  const transferCharacteristics2 = sps.vui_parameters?.transfer_characteristics;\n  const colorPrimaries = sps.vui_parameters?.colour_primaries;\n  return {\n    matrix: matrixCoefficients2 ? getMatrixCoefficientsFromIndex(matrixCoefficients2) : null,\n    transfer: transferCharacteristics2 ? getTransferCharacteristicsFromIndex(transferCharacteristics2) : null,\n    primaries: colorPrimaries ? getPrimariesFromIndex(colorPrimaries) : null,\n    fullRange: sps.vui_parameters?.video_full_range_flag ?? null\n  };\n};\n\n// src/containers/avc/key.ts\nvar getKeyFrameOrDeltaFromAvcInfo = (infos) => {\n  const keyOrDelta = infos.find((i) => i.type === \"keyframe\" || i.type === \"delta-frame\");\n  if (!keyOrDelta) {\n    throw new Error(\"expected avc to contain info about key or delta\");\n  }\n  return keyOrDelta.type === \"keyframe\" ? \"key\" : keyOrDelta.isBidirectionalFrame ? \"bidirectional\" : \"delta\";\n};\n\n// src/containers/avc/parse-avc.ts\nvar Extended_SAR = 255;\nvar getPoc = (iterator, sps, avcState, isReferencePicture) => {\n  const { pic_order_cnt_type, log2_max_pic_order_cnt_lsb_minus4 } = sps;\n  if (pic_order_cnt_type !== 0) {\n    return null;\n  }\n  const prevPicOrderCntLsb = avcState.getPrevPicOrderCntLsb();\n  const prevPicOrderCntMsb = avcState.getPrevPicOrderCntMsb();\n  if (log2_max_pic_order_cnt_lsb_minus4 === null) {\n    throw new Error(\"log2_max_pic_order_cnt_lsb_minus4 is null\");\n  }\n  const max_pic_order_cnt_lsb = 2 ** (log2_max_pic_order_cnt_lsb_minus4 + 4);\n  const pic_order_cnt_lsb = iterator.getBits(log2_max_pic_order_cnt_lsb_minus4 + 4);\n  let picOrderCntMsb;\n  if (pic_order_cnt_lsb < prevPicOrderCntLsb && prevPicOrderCntLsb - pic_order_cnt_lsb >= max_pic_order_cnt_lsb / 2) {\n    picOrderCntMsb = prevPicOrderCntMsb + max_pic_order_cnt_lsb;\n  } else if (pic_order_cnt_lsb > prevPicOrderCntLsb && pic_order_cnt_lsb - prevPicOrderCntLsb > max_pic_order_cnt_lsb / 2) {\n    picOrderCntMsb = prevPicOrderCntMsb - max_pic_order_cnt_lsb;\n  } else {\n    picOrderCntMsb = prevPicOrderCntMsb;\n  }\n  const poc = picOrderCntMsb + pic_order_cnt_lsb;\n  if (isReferencePicture) {\n    avcState.setPrevPicOrderCntLsb(pic_order_cnt_lsb);\n    avcState.setPrevPicOrderCntMsb(picOrderCntMsb);\n  }\n  return poc;\n};\nvar readVuiParameters = (iterator) => {\n  let sar_width = null;\n  let sar_height = null;\n  let overscan_appropriate_flag = null;\n  let video_format = null;\n  let video_full_range_flag = null;\n  let colour_primaries = null;\n  let transfer_characteristics = null;\n  let matrix_coefficients = null;\n  let chroma_sample_loc_type_top_field = null;\n  let chroma_sample_loc_type_bottom_field = null;\n  const aspect_ratio_info_present_flag = iterator.getBits(1);\n  if (aspect_ratio_info_present_flag) {\n    const aspect_ratio_idc = iterator.getBits(8);\n    if (aspect_ratio_idc === Extended_SAR) {\n      sar_width = iterator.getBits(16);\n      sar_height = iterator.getBits(16);\n    }\n  }\n  const overscan_info_present_flag = iterator.getBits(1);\n  if (overscan_info_present_flag) {\n    overscan_appropriate_flag = iterator.getBits(1);\n  }\n  const video_signal_type_present_flag = iterator.getBits(1);\n  if (video_signal_type_present_flag) {\n    video_format = iterator.getBits(3);\n    video_full_range_flag = Boolean(iterator.getBits(1));\n    const colour_description_present_flag = iterator.getBits(1);\n    if (colour_description_present_flag) {\n      colour_primaries = iterator.getBits(8);\n      transfer_characteristics = iterator.getBits(8);\n      matrix_coefficients = iterator.getBits(8);\n    }\n  }\n  const chroma_loc_info_present_flag = iterator.getBits(1);\n  if (chroma_loc_info_present_flag) {\n    chroma_sample_loc_type_top_field = iterator.readExpGolomb();\n    chroma_sample_loc_type_bottom_field = iterator.readExpGolomb();\n  }\n  return {\n    sar_width,\n    sar_height,\n    overscan_appropriate_flag,\n    chroma_sample_loc_type_bottom_field,\n    chroma_sample_loc_type_top_field,\n    colour_primaries,\n    matrix_coefficients,\n    transfer_characteristics,\n    video_format,\n    video_full_range_flag\n  };\n};\nvar readSps = (iterator) => {\n  const profile = iterator.getUint8();\n  const compatibility = iterator.getUint8();\n  const level = iterator.getUint8();\n  iterator.startReadingBits();\n  const seq_parameter_set_id = iterator.readExpGolomb();\n  let separate_colour_plane_flag = null;\n  let bit_depth_luma_minus8 = null;\n  let bit_depth_chroma_minus8 = null;\n  let qpprime_y_zero_transform_bypass_flag = null;\n  let log2_max_frame_num_minus4 = null;\n  let log2_max_pic_order_cnt_lsb_minus4 = null;\n  let max_num_ref_frames = null;\n  let gaps_in_frame_num_value_allowed_flag = null;\n  let mb_adaptive_frame_field_flag = null;\n  let direct_8x8_inference_flag = null;\n  let frame_crop_left_offset = null;\n  let frame_crop_right_offset = null;\n  let frame_crop_top_offset = null;\n  let frame_crop_bottom_offset = null;\n  let vui_parameters = null;\n  if (profile === 100 || profile === 110 || profile === 122 || profile === 244 || profile === 44 || profile === 83 || profile === 86 || profile === 118 || profile === 128 || profile === 138 || profile === 139 || profile === 134 || profile === 135) {\n    const chromaFormat = iterator.readExpGolomb();\n    if (chromaFormat === 3) {\n      separate_colour_plane_flag = iterator.getBits(1);\n    }\n    bit_depth_luma_minus8 = iterator.readExpGolomb();\n    bit_depth_chroma_minus8 = iterator.readExpGolomb();\n    qpprime_y_zero_transform_bypass_flag = iterator.getBits(1);\n    const seq_scaling_matrix_present_flag = iterator.getBits(1);\n    const seq_scaling_list_present_flag = [];\n    if (seq_scaling_matrix_present_flag) {\n      for (let i = 0;i < (chromaFormat !== 3 ? 8 : 12); i++) {\n        seq_scaling_list_present_flag[i] = iterator.getBits(1);\n        if (seq_scaling_list_present_flag[i]) {\n          if (i < 6) {\n            throw new Error(\"Not implemented\");\n          } else {\n            throw new Error(\"Not implemented\");\n          }\n        }\n      }\n    }\n  }\n  log2_max_frame_num_minus4 = iterator.readExpGolomb();\n  const pic_order_cnt_type = iterator.readExpGolomb();\n  if (pic_order_cnt_type === 0) {\n    log2_max_pic_order_cnt_lsb_minus4 = iterator.readExpGolomb();\n  } else if (pic_order_cnt_type === 1) {\n    throw new Error(\"pic_order_cnt_type = 1 not implemented\");\n  }\n  max_num_ref_frames = iterator.readExpGolomb();\n  gaps_in_frame_num_value_allowed_flag = iterator.getBits(1);\n  const pic_width_in_mbs_minus1 = iterator.readExpGolomb();\n  const pic_height_in_map_units_minus1 = iterator.readExpGolomb();\n  const frame_mbs_only_flag = iterator.getBits(1);\n  if (!frame_mbs_only_flag) {\n    mb_adaptive_frame_field_flag = iterator.getBits(1);\n  }\n  direct_8x8_inference_flag = iterator.getBits(1);\n  const frame_cropping_flag = iterator.getBits(1);\n  if (frame_cropping_flag) {\n    frame_crop_left_offset = iterator.readExpGolomb();\n    frame_crop_right_offset = iterator.readExpGolomb();\n    frame_crop_top_offset = iterator.readExpGolomb();\n    frame_crop_bottom_offset = iterator.readExpGolomb();\n  }\n  const vui_parameters_present_flag = iterator.getBits(1);\n  if (vui_parameters_present_flag) {\n    vui_parameters = readVuiParameters(iterator);\n  }\n  iterator.stopReadingBits();\n  return {\n    profile,\n    compatibility,\n    level,\n    bit_depth_chroma_minus8,\n    bit_depth_luma_minus8,\n    gaps_in_frame_num_value_allowed_flag,\n    log2_max_frame_num_minus4,\n    log2_max_pic_order_cnt_lsb_minus4,\n    max_num_ref_frames,\n    pic_height_in_map_units_minus1,\n    pic_width_in_mbs_minus1,\n    qpprime_y_zero_transform_bypass_flag,\n    separate_colour_plane_flag,\n    seq_parameter_set_id,\n    direct_8x8_inference_flag,\n    frame_crop_bottom_offset,\n    frame_crop_left_offset,\n    frame_crop_right_offset,\n    frame_crop_top_offset,\n    mb_adaptive_frame_field_flag,\n    vui_parameters,\n    pic_order_cnt_type\n  };\n};\nvar findEnd = (buffer) => {\n  let zeroesInARow = 0;\n  for (let i = 0;i < buffer.length; i++) {\n    const val = buffer[i];\n    if (val === 0) {\n      zeroesInARow++;\n      continue;\n    }\n    if (zeroesInARow >= 2 && val === 1) {\n      return i - zeroesInARow;\n    }\n    zeroesInARow = 0;\n  }\n  return null;\n};\nvar inspect = (buffer, avcState) => {\n  const iterator = getArrayBufferIterator({\n    initialData: buffer,\n    maxBytes: buffer.byteLength,\n    logLevel: \"error\"\n  });\n  iterator.startReadingBits();\n  iterator.getBits(1);\n  const nal_ref_idc = iterator.getBits(2);\n  const isReferencePicture = nal_ref_idc !== 0;\n  const type = iterator.getBits(5);\n  if (type === 7) {\n    iterator.stopReadingBits();\n    const end = findEnd(buffer);\n    const data = readSps(iterator);\n    const sps = buffer.slice(0, end === null ? Infinity : end);\n    avcState.setSps(data);\n    if (isReferencePicture) {\n      avcState.setPrevPicOrderCntLsb(0);\n      avcState.setPrevPicOrderCntMsb(0);\n    }\n    return {\n      spsData: data,\n      sps,\n      type: \"avc-profile\"\n    };\n  }\n  if (type === 5) {\n    avcState.setPrevPicOrderCntLsb(0);\n    avcState.setPrevPicOrderCntMsb(0);\n    iterator.readExpGolomb();\n    iterator.readExpGolomb();\n    iterator.readExpGolomb();\n    const sps = avcState.getSps();\n    if (!sps) {\n      throw new Error(\"SPS not found\");\n    }\n    const numberOfBitsForFrameNum = sps.log2_max_frame_num_minus4 + 4;\n    iterator.getBits(numberOfBitsForFrameNum);\n    iterator.readExpGolomb();\n    const { pic_order_cnt_type } = sps;\n    let poc = null;\n    if (pic_order_cnt_type === 0) {\n      poc = getPoc(iterator, sps, avcState, isReferencePicture);\n    }\n    iterator.stopReadingBits();\n    return {\n      type: \"keyframe\",\n      poc\n    };\n  }\n  if (type === 8) {\n    iterator.stopReadingBits();\n    const end = findEnd(buffer);\n    const pps = buffer.slice(0, end === null ? Infinity : end);\n    return {\n      type: \"avc-pps\",\n      pps\n    };\n  }\n  if (type === 1) {\n    iterator.readExpGolomb();\n    const slice_type = iterator.readExpGolomb();\n    const isBidirectionalFrame = slice_type === 6;\n    iterator.readExpGolomb();\n    const sps = avcState.getSps();\n    if (!sps) {\n      throw new Error(\"SPS not found\");\n    }\n    const numberOfBitsForFrameNum = sps.log2_max_frame_num_minus4 + 4;\n    iterator.getBits(numberOfBitsForFrameNum);\n    const { pic_order_cnt_type } = sps;\n    let poc = null;\n    if (pic_order_cnt_type === 0) {\n      poc = getPoc(iterator, sps, avcState, isReferencePicture);\n    }\n    iterator.stopReadingBits();\n    return {\n      type: \"delta-frame\",\n      isBidirectionalFrame,\n      poc\n    };\n  }\n  iterator.destroy();\n  return null;\n};\nvar parseAvc = (buffer, avcState) => {\n  let zeroesInARow = 0;\n  const infos = [];\n  for (let i = 0;i < buffer.length; i++) {\n    const val = buffer[i];\n    if (val === 0) {\n      zeroesInARow++;\n      continue;\n    }\n    if (zeroesInARow >= 2 && val === 1) {\n      zeroesInARow = 0;\n      const info = inspect(buffer.slice(i + 1, i + 100), avcState);\n      if (info) {\n        infos.push(info);\n        if (info.type === \"keyframe\" || info.type === \"delta-frame\") {\n          break;\n        }\n      }\n    }\n    if (val !== 1) {\n      zeroesInARow = 0;\n    }\n  }\n  return infos;\n};\n\n// src/containers/avc/sps-and-pps.ts\nvar getSpsAndPps = (infos) => {\n  const avcProfile = infos.find((i) => i.type === \"avc-profile\");\n  const ppsProfile = infos.find((i) => i.type === \"avc-pps\");\n  if (!avcProfile || !ppsProfile) {\n    throw new Error(\"Expected avcProfile and ppsProfile\");\n  }\n  return { pps: ppsProfile, sps: avcProfile };\n};\n\n// src/containers/transport-stream/handle-avc-packet.ts\nvar MPEG_TIMESCALE = 90000;\nvar handleAvcPacket = async ({\n  streamBuffer,\n  programId,\n  offset,\n  sampleCallbacks,\n  logLevel,\n  onVideoTrack,\n  transportStream,\n  makeSamplesStartAtZero,\n  avcState\n}) => {\n  const avc = parseAvc(streamBuffer.getBuffer(), avcState);\n  const isTrackRegistered = sampleCallbacks.tracks.getTracks().find((t) => {\n    return t.trackId === programId;\n  });\n  if (!isTrackRegistered) {\n    const spsAndPps = getSpsAndPps(avc);\n    const dimensions = getDimensionsFromSps(spsAndPps.sps.spsData);\n    const sampleAspectRatio = getSampleAspectRatioFromSps(spsAndPps.sps.spsData);\n    const startOffset = makeSamplesStartAtZero ? Math.min(streamBuffer.pesHeader.pts, streamBuffer.pesHeader.dts ?? Infinity) : 0;\n    transportStream.startOffset.setOffset({\n      trackId: programId,\n      newOffset: startOffset\n    });\n    const codecPrivate2 = createSpsPpsData(spsAndPps);\n    const advancedColor = getVideoColorFromSps(spsAndPps.sps.spsData);\n    const track = {\n      m3uStreamFormat: null,\n      rotation: 0,\n      trackId: programId,\n      type: \"video\",\n      originalTimescale: MPEG_TIMESCALE,\n      codec: getCodecStringFromSpsAndPps(spsAndPps.sps),\n      codecData: { type: \"avc-sps-pps\", data: codecPrivate2 },\n      fps: null,\n      codedWidth: dimensions.width,\n      codedHeight: dimensions.height,\n      height: dimensions.height,\n      width: dimensions.width,\n      displayAspectWidth: dimensions.width,\n      displayAspectHeight: dimensions.height,\n      codecEnum: \"h264\",\n      description: undefined,\n      sampleAspectRatio: {\n        denominator: sampleAspectRatio.height,\n        numerator: sampleAspectRatio.width\n      },\n      colorSpace: mediaParserAdvancedColorToWebCodecsColor(advancedColor),\n      advancedColor,\n      startInSeconds: 0,\n      timescale: WEBCODECS_TIMESCALE\n    };\n    await registerVideoTrack({\n      track,\n      container: \"transport-stream\",\n      logLevel,\n      onVideoTrack,\n      registerVideoSampleCallback: sampleCallbacks.registerVideoSampleCallback,\n      tracks: sampleCallbacks.tracks\n    });\n  }\n  const type = getKeyFrameOrDeltaFromAvcInfo(avc);\n  const sample = {\n    decodingTimestamp: (streamBuffer.pesHeader.dts ?? streamBuffer.pesHeader.pts) - transportStream.startOffset.getOffset(programId),\n    timestamp: streamBuffer.pesHeader.pts - transportStream.startOffset.getOffset(programId),\n    duration: undefined,\n    data: streamBuffer.getBuffer(),\n    type: type === \"bidirectional\" ? \"delta\" : type,\n    offset\n  };\n  if (type === \"key\") {\n    transportStream.observedPesHeaders.markPtsAsKeyframe(streamBuffer.pesHeader.pts);\n  }\n  const videoSample = convertAudioOrVideoSampleToWebCodecsTimestamps({\n    sample,\n    timescale: MPEG_TIMESCALE\n  });\n  await sampleCallbacks.onVideoSample({\n    videoSample,\n    trackId: programId\n  });\n  transportStream.lastEmittedSample.setLastEmittedSample(sample);\n};\n\n// src/containers/wav/get-seeking-byte.ts\nvar WAVE_SAMPLES_PER_SECOND = 25;\nvar getSeekingByteFromWav = ({\n  info,\n  time\n}) => {\n  const bytesPerSecond = info.sampleRate * info.blockAlign;\n  const durationInSeconds = info.mediaSection.size / bytesPerSecond;\n  const timeRoundedDown = Math.floor(Math.min(time, durationInSeconds - 0.0000001) * WAVE_SAMPLES_PER_SECOND) / WAVE_SAMPLES_PER_SECOND;\n  const byteOffset = bytesPerSecond * timeRoundedDown;\n  return Promise.resolve({\n    type: \"do-seek\",\n    byte: byteOffset + info.mediaSection.start,\n    timeInSeconds: timeRoundedDown\n  });\n};\n\n// src/containers/webm/seek/get-seeking-byte.ts\nvar toSeconds = (timeInTimescale, track) => {\n  return timeInTimescale / track.timescale * 1000;\n};\nvar findBiggestCueBeforeTime = ({\n  cues,\n  time,\n  track\n}) => {\n  let biggestCueBeforeTime;\n  for (const cue of cues) {\n    const cueTimeInSeconds = toSeconds(cue.timeInTimescale, track);\n    if (cueTimeInSeconds < time && (!biggestCueBeforeTime || cueTimeInSeconds > toSeconds(biggestCueBeforeTime.timeInTimescale, track))) {\n      biggestCueBeforeTime = cue;\n    }\n  }\n  return biggestCueBeforeTime;\n};\nvar findKeyframeBeforeTime2 = ({\n  keyframes,\n  time\n}) => {\n  let keyframeBeforeTime;\n  for (const keyframe of keyframes) {\n    if (keyframe.decodingTimeInSeconds < time && (!keyframeBeforeTime || keyframe.decodingTimeInSeconds > keyframeBeforeTime.decodingTimeInSeconds)) {\n      keyframeBeforeTime = keyframe;\n    }\n  }\n  return keyframeBeforeTime ?? null;\n};\nvar getByteFromCues = ({\n  cuesResponse,\n  time,\n  info,\n  logLevel\n}) => {\n  if (!cuesResponse) {\n    Log.trace(logLevel, \"Has no Matroska cues at the moment, cannot use them\");\n    return null;\n  }\n  const { cues, segmentOffset } = cuesResponse;\n  Log.trace(logLevel, \"Has Matroska cues. Will use them to perform a seek.\");\n  const biggestCueBeforeTime = findBiggestCueBeforeTime({\n    cues,\n    time,\n    track: info.track\n  });\n  if (!biggestCueBeforeTime) {\n    return null;\n  }\n  return {\n    byte: biggestCueBeforeTime.clusterPositionInSegment + segmentOffset,\n    timeInSeconds: toSeconds(biggestCueBeforeTime.timeInTimescale, info.track)\n  };\n};\nvar getSeekingByteFromMatroska = async ({\n  time,\n  webmState,\n  info,\n  logLevel,\n  mediaSection\n}) => {\n  if (!info.track) {\n    Log.trace(logLevel, \"No video track found, cannot seek yet\");\n    return {\n      type: \"valid-but-must-wait\"\n    };\n  }\n  const cuesResponse = info.loadedCues ?? await webmState.cues.getLoadedCues();\n  const byteFromObservedKeyframe = findKeyframeBeforeTime2({\n    keyframes: info.keyframes,\n    time\n  });\n  const byteFromCues = getByteFromCues({\n    cuesResponse,\n    time,\n    info,\n    logLevel\n  });\n  const byteFromFirstMediaSection = webmState.getFirstCluster()?.start ?? null;\n  const seekPossibilities = [\n    byteFromCues?.byte ?? null,\n    byteFromObservedKeyframe?.positionInBytes ?? null,\n    byteFromFirstMediaSection\n  ].filter((n) => n !== null);\n  const byteToSeekTo = seekPossibilities.length === 0 ? null : Math.max(...seekPossibilities);\n  if (byteToSeekTo === null) {\n    return {\n      type: \"invalid\"\n    };\n  }\n  mediaSection.addMediaSection({\n    start: byteToSeekTo,\n    size: 1\n  });\n  const timeInSeconds = (() => {\n    if (byteToSeekTo === byteFromObservedKeyframe?.positionInBytes) {\n      return Math.min(byteFromObservedKeyframe.decodingTimeInSeconds, byteFromObservedKeyframe.presentationTimeInSeconds);\n    }\n    if (byteToSeekTo === byteFromCues?.byte) {\n      return byteFromCues.timeInSeconds;\n    }\n    if (byteToSeekTo === byteFromFirstMediaSection) {\n      return 0;\n    }\n    throw new Error(\"Should not happen\");\n  })();\n  return {\n    type: \"do-seek\",\n    byte: byteToSeekTo,\n    timeInSeconds\n  };\n};\n\n// src/state/transport-stream/observed-pes-header.ts\nvar makeObservedPesHeader = () => {\n  const pesHeaders = [];\n  const confirmedAsKeyframe = [];\n  const addPesHeader = (pesHeader) => {\n    if (pesHeaders.find((p) => p.offset === pesHeader.offset)) {\n      return;\n    }\n    pesHeaders.push(pesHeader);\n  };\n  const markPtsAsKeyframe = (pts) => {\n    confirmedAsKeyframe.push(pts);\n  };\n  const getPesKeyframeHeaders = () => {\n    return pesHeaders.filter((p) => confirmedAsKeyframe.includes(p.pts));\n  };\n  const setPesKeyframesFromSeekingHints = (hints) => {\n    for (const pesHeader of hints.observedPesHeaders) {\n      addPesHeader(pesHeader);\n      markPtsAsKeyframe(pesHeader.pts);\n    }\n  };\n  const state = {\n    pesHeaders,\n    addPesHeader,\n    markPtsAsKeyframe,\n    getPesKeyframeHeaders,\n    setPesKeyframesFromSeekingHints\n  };\n  return state;\n};\nvar getLastKeyFrameBeforeTimeInSeconds = ({\n  observedPesHeaders,\n  timeInSeconds,\n  ptsStartOffset\n}) => {\n  return observedPesHeaders.findLast((k) => (k.pts - ptsStartOffset) / MPEG_TIMESCALE <= timeInSeconds);\n};\n\n// src/get-seeking-byte.ts\nvar getSeekingByte = ({\n  info,\n  time,\n  logLevel,\n  currentPosition,\n  isoState,\n  transportStream,\n  webmState,\n  mediaSection,\n  m3uPlaylistContext,\n  structure,\n  riffState,\n  m3uState,\n  avcState\n}) => {\n  if (info.type === \"iso-base-media-seeking-hints\") {\n    return getSeekingByteFromIsoBaseMedia({\n      info,\n      time,\n      logLevel,\n      currentPosition,\n      isoState,\n      structure,\n      m3uPlaylistContext\n    });\n  }\n  if (info.type === \"wav-seeking-hints\") {\n    return getSeekingByteFromWav({\n      info,\n      time\n    });\n  }\n  if (info.type === \"webm-seeking-hints\") {\n    return getSeekingByteFromMatroska({\n      info,\n      time,\n      webmState,\n      logLevel,\n      mediaSection\n    });\n  }\n  if (info.type === \"flac-seeking-hints\") {\n    const byte = getSeekingByteForFlac({\n      seekingHints: info,\n      time\n    });\n    if (byte) {\n      return Promise.resolve({\n        type: \"do-seek\",\n        byte: byte.offset,\n        timeInSeconds: byte.timeInSeconds\n      });\n    }\n    return Promise.resolve({\n      type: \"valid-but-must-wait\"\n    });\n  }\n  if (info.type === \"transport-stream-seeking-hints\") {\n    const lastKeyframeBeforeTimeInSeconds = getLastKeyFrameBeforeTimeInSeconds({\n      observedPesHeaders: info.observedPesHeaders,\n      timeInSeconds: time,\n      ptsStartOffset: info.ptsStartOffset\n    });\n    if (!lastKeyframeBeforeTimeInSeconds) {\n      transportStream.resetBeforeSeek();\n      return Promise.resolve({\n        type: \"do-seek\",\n        byte: 0,\n        timeInSeconds: 0\n      });\n    }\n    const byte = lastKeyframeBeforeTimeInSeconds.offset;\n    transportStream.resetBeforeSeek();\n    return Promise.resolve({\n      type: \"do-seek\",\n      byte,\n      timeInSeconds: Math.min(lastKeyframeBeforeTimeInSeconds.pts, lastKeyframeBeforeTimeInSeconds.dts ?? Infinity) / MPEG_TIMESCALE\n    });\n  }\n  if (info.type === \"riff-seeking-hints\") {\n    return getSeekingByteForRiff({\n      info,\n      time,\n      riffState,\n      avcState\n    });\n  }\n  if (info.type === \"mp3-seeking-hints\") {\n    return Promise.resolve(getSeekingByteForMp3({\n      info,\n      time\n    }));\n  }\n  if (info.type === \"aac-seeking-hints\") {\n    return Promise.resolve(getSeekingByteForAac({\n      time,\n      seekingHints: info\n    }));\n  }\n  if (info.type === \"m3u8-seeking-hints\") {\n    return Promise.resolve(getSeekingByteForM3u8({\n      time,\n      currentPosition,\n      m3uState,\n      logLevel\n    }));\n  }\n  throw new Error(`Unknown seeking info type: ${info}`);\n};\n\n// src/containers/aac/seeking-hints.ts\nvar getSeekingHintsForAac = ({\n  aacState,\n  samplesObserved\n}) => {\n  return {\n    type: \"aac-seeking-hints\",\n    audioSampleMap: aacState.audioSamples.getSamples(),\n    lastSampleObserved: samplesObserved.getLastSampleObserved()\n  };\n};\nvar setSeekingHintsForAac = () => {};\n\n// src/containers/flac/seeking-hints.ts\nvar getSeekingHintsForFlac = ({\n  flacState,\n  samplesObserved\n}) => {\n  return {\n    type: \"flac-seeking-hints\",\n    audioSampleMap: flacState.audioSamples.getSamples(),\n    blockingBitStrategy: flacState.getBlockingBitStrategy() ?? null,\n    lastSampleObserved: samplesObserved.getLastSampleObserved()\n  };\n};\nvar setSeekingHintsForFlac = ({\n  hints,\n  state\n}) => {\n  if (hints.blockingBitStrategy !== null) {\n    state.flac.setBlockingBitStrategy(hints.blockingBitStrategy);\n  }\n  state.flac.audioSamples.setFromSeekingHints(hints.audioSampleMap);\n};\n\n// src/containers/iso-base-media/seeking-hints.ts\nvar getSeekingHintsFromMp4 = ({\n  structureState,\n  isoState,\n  mp4HeaderSegment,\n  mediaSectionState: mediaSectionState2\n}) => {\n  const structure = structureState.getIsoStructure();\n  const moovAtom = getMoovBoxFromState({\n    isoState,\n    mp4HeaderSegment,\n    structureState,\n    mayUsePrecomputed: true\n  });\n  const moofBoxes = deduplicateMoofBoxesByOffset([\n    ...isoState.moof.getMoofBoxes(),\n    ...getMoofBoxes(structure.boxes)\n  ]);\n  const tfraBoxes = deduplicateTfraBoxesByOffset([\n    ...isoState.tfra.getTfraBoxes(),\n    ...getTfraBoxes(structure.boxes)\n  ]);\n  if (!moovAtom) {\n    return null;\n  }\n  return {\n    type: \"iso-base-media-seeking-hints\",\n    moovBox: moovAtom,\n    moofBoxes,\n    tfraBoxes,\n    mediaSections: mediaSectionState2.getMediaSections(),\n    mfraAlreadyLoaded: isoState.mfra.getIfAlreadyLoaded()\n  };\n};\nvar setSeekingHintsForMp4 = ({}) => {};\n\n// src/containers/m3u/seeking-hints.ts\nvar getSeekingHintsForM3u = () => {\n  return {\n    type: \"m3u8-seeking-hints\"\n  };\n};\n\n// src/containers/mp3/seeking-hints.ts\nvar getSeekingHintsForMp3 = ({\n  mp3State,\n  samplesObserved,\n  mediaSectionState: mediaSectionState2,\n  contentLength\n}) => {\n  return {\n    type: \"mp3-seeking-hints\",\n    audioSampleMap: mp3State.audioSamples.getSamples(),\n    lastSampleObserved: samplesObserved.getLastSampleObserved(),\n    mp3BitrateInfo: mp3State.getMp3BitrateInfo(),\n    mp3Info: mp3State.getMp3Info(),\n    mediaSection: mediaSectionState2.getMediaSections()[0] ?? null,\n    contentLength\n  };\n};\nvar setSeekingHintsForMp3 = ({\n  hints,\n  state\n}) => {\n  state.mp3.audioSamples.setFromSeekingHints(hints.audioSampleMap);\n};\n\n// src/containers/riff/has-index.ts\nvar riffHasIndex = (structure) => {\n  return structure.boxes.find((b) => b.type === \"list-box\" && b.listType === \"hdrl\")?.children.find((box) => box.type === \"avih-box\")?.hasIndex ?? false;\n};\n\n// src/containers/riff/seeking-hints.ts\nvar getSeekingHintsForRiff = ({\n  structureState,\n  riffState,\n  mediaSectionState: mediaSectionState2\n}) => {\n  const structure = structureState.getRiffStructure();\n  const strl = getStrlBoxes(structure);\n  let samplesPerSecond = null;\n  for (const s of strl) {\n    const strh = getStrhBox(s.children);\n    if (!strh) {\n      throw new Error(\"No strh box\");\n    }\n    if (strh.strf.type !== \"strf-box-video\") {\n      continue;\n    }\n    samplesPerSecond = strh.rate / strh.scale;\n    break;\n  }\n  return {\n    type: \"riff-seeking-hints\",\n    hasIndex: riffHasIndex(structure),\n    idx1Entries: riffState.lazyIdx1.getIfAlreadyLoaded(),\n    samplesPerSecond,\n    moviOffset: mediaSectionState2.getMediaSections()[0]?.start ?? null,\n    observedKeyframes: riffState.sampleCounter.riffKeys.getKeyframes()\n  };\n};\nvar setSeekingHintsForRiff = ({\n  hints,\n  state\n}) => {\n  state.riff.lazyIdx1.setFromSeekingHints(hints);\n  state.riff.sampleCounter.riffKeys.setFromSeekingHints(hints.observedKeyframes);\n};\n\n// src/containers/transport-stream/seeking-hints.ts\nvar getSeekingHintsFromTransportStream = (transportStream, tracksState) => {\n  const firstVideoTrack = tracksState.getTracks().find((t) => t.type === \"video\");\n  if (!firstVideoTrack) {\n    return null;\n  }\n  return {\n    type: \"transport-stream-seeking-hints\",\n    observedPesHeaders: transportStream.observedPesHeaders.getPesKeyframeHeaders(),\n    ptsStartOffset: transportStream.startOffset.getOffset(firstVideoTrack.trackId),\n    firstVideoTrackId: firstVideoTrack.trackId\n  };\n};\nvar setSeekingHintsForTransportStream = ({\n  hints,\n  state\n}) => {\n  state.transportStream.observedPesHeaders.setPesKeyframesFromSeekingHints(hints);\n  state.transportStream.startOffset.setOffset({\n    trackId: hints.firstVideoTrackId,\n    newOffset: hints.ptsStartOffset\n  });\n};\n\n// src/containers/wav/seeking-hints.ts\nvar getSeekingHintsFromWav = ({\n  structure,\n  mediaSectionState: mediaSectionState2\n}) => {\n  const fmtBox = structure.boxes.find((box) => box.type === \"wav-fmt\");\n  if (!fmtBox) {\n    return null;\n  }\n  const mediaSection = mediaSectionState2.getMediaSections();\n  if (mediaSection.length !== 1) {\n    return null;\n  }\n  return {\n    type: \"wav-seeking-hints\",\n    sampleRate: fmtBox.sampleRate,\n    blockAlign: fmtBox.blockAlign,\n    mediaSection: mediaSection[0]\n  };\n};\nvar setSeekingHintsForWav = ({\n  hints,\n  state\n}) => {\n  state.mediaSection.addMediaSection(hints.mediaSection);\n};\n\n// src/containers/webm/seek/seeking-hints.ts\nvar getSeekingHintsFromMatroska = (tracksState, keyframesState, webmState) => {\n  const tracks2 = tracksState.getTracks();\n  const firstVideoTrack = tracks2.find((track) => track.type === \"video\");\n  const keyframes = keyframesState.getKeyframes();\n  const loadedCues = webmState.cues.getIfAlreadyLoaded();\n  return {\n    type: \"webm-seeking-hints\",\n    track: firstVideoTrack ? {\n      timescale: firstVideoTrack.originalTimescale,\n      trackId: firstVideoTrack.trackId\n    } : null,\n    keyframes,\n    loadedCues,\n    timestampMap: webmState.getTimeStampMapForSeekingHints()\n  };\n};\nvar setSeekingHintsForWebm = ({\n  hints,\n  state\n}) => {\n  state.webm.cues.setFromSeekingHints(hints);\n  state.keyframes.setFromSeekingHints(hints.keyframes);\n  state.webm.setTimeStampMapForSeekingHints(hints.timestampMap);\n};\n\n// src/get-seeking-hints.ts\nvar getSeekingHints = ({\n  structureState,\n  m3uPlaylistContext,\n  mediaSectionState: mediaSectionState2,\n  isoState,\n  transportStream,\n  tracksState,\n  keyframesState,\n  webmState,\n  flacState,\n  samplesObserved,\n  riffState,\n  mp3State,\n  contentLength,\n  aacState\n}) => {\n  const structure = structureState.getStructureOrNull();\n  if (!structure) {\n    return null;\n  }\n  if (structure.type === \"iso-base-media\") {\n    return getSeekingHintsFromMp4({\n      structureState,\n      isoState,\n      mp4HeaderSegment: m3uPlaylistContext?.mp4HeaderSegment ?? null,\n      mediaSectionState: mediaSectionState2\n    });\n  }\n  if (structure.type === \"wav\") {\n    return getSeekingHintsFromWav({\n      structure,\n      mediaSectionState: mediaSectionState2\n    });\n  }\n  if (structure.type === \"matroska\") {\n    return getSeekingHintsFromMatroska(tracksState, keyframesState, webmState);\n  }\n  if (structure.type === \"transport-stream\") {\n    return getSeekingHintsFromTransportStream(transportStream, tracksState);\n  }\n  if (structure.type === \"flac\") {\n    return getSeekingHintsForFlac({\n      flacState,\n      samplesObserved\n    });\n  }\n  if (structure.type === \"riff\") {\n    return getSeekingHintsForRiff({\n      structureState,\n      riffState,\n      mediaSectionState: mediaSectionState2\n    });\n  }\n  if (structure.type === \"mp3\") {\n    return getSeekingHintsForMp3({\n      mp3State,\n      samplesObserved,\n      mediaSectionState: mediaSectionState2,\n      contentLength\n    });\n  }\n  if (structure.type === \"aac\") {\n    return getSeekingHintsForAac({\n      aacState,\n      samplesObserved\n    });\n  }\n  if (structure.type === \"m3u\") {\n    return getSeekingHintsForM3u();\n  }\n  throw new Error(`Seeking is not supported for this format: ${structure}`);\n};\n\n// src/seek-backwards.ts\nvar seekBackwards = async ({\n  iterator,\n  seekTo,\n  readerInterface,\n  src,\n  controller,\n  logLevel,\n  currentReader,\n  prefetchCache\n}) => {\n  const howManyBytesWeCanGoBack = iterator.counter.getDiscardedOffset();\n  if (iterator.counter.getOffset() - howManyBytesWeCanGoBack <= seekTo) {\n    Log.verbose(logLevel, `Seeking back to ${seekTo}`);\n    iterator.skipTo(seekTo);\n    return;\n  }\n  const time = Date.now();\n  Log.verbose(logLevel, `Seeking in video from position ${iterator.counter.getOffset()} -> ${seekTo}. Re-reading because this portion is not available.`);\n  await currentReader.getCurrent().abort();\n  const { reader: newReader } = await readerInterface.read({\n    src,\n    range: seekTo,\n    controller,\n    logLevel,\n    prefetchCache\n  });\n  iterator.replaceData(new Uint8Array([]), seekTo);\n  Log.verbose(logLevel, `Re-reading took ${Date.now() - time}ms. New position: ${iterator.counter.getOffset()}`);\n  currentReader.setCurrent(newReader);\n};\n\n// src/state/need-samples-for-fields.ts\nvar fieldsNeedSamplesMap = {\n  slowDurationInSeconds: true,\n  slowFps: true,\n  slowKeyframes: true,\n  slowNumberOfFrames: true,\n  audioCodec: false,\n  container: false,\n  dimensions: false,\n  durationInSeconds: false,\n  fps: false,\n  internalStats: false,\n  isHdr: false,\n  name: false,\n  rotation: false,\n  size: false,\n  slowStructure: false,\n  tracks: false,\n  unrotatedDimensions: false,\n  videoCodec: false,\n  metadata: false,\n  location: false,\n  mimeType: false,\n  keyframes: false,\n  images: false,\n  numberOfAudioChannels: false,\n  sampleRate: false,\n  slowAudioBitrate: true,\n  slowVideoBitrate: true,\n  m3uStreams: false\n};\nvar needsToIterateOverSamples = ({\n  fields,\n  emittedFields\n}) => {\n  const keys = Object.keys(fields ?? {});\n  const selectedKeys = keys.filter((k) => fields[k]);\n  return selectedKeys.some((k) => fieldsNeedSamplesMap[k] && !emittedFields[k]);\n};\nvar fieldsNeedEverySampleMap = {\n  ...fieldsNeedSamplesMap,\n  slowDurationInSeconds: false\n};\nvar needsToIterateOverEverySample = ({\n  fields,\n  emittedFields\n}) => {\n  const keys = Object.keys(fields ?? {});\n  const selectedKeys = keys.filter((k) => fields[k]);\n  return selectedKeys.some((k) => fieldsNeedEverySampleMap[k] && !emittedFields[k]);\n};\n\n// src/disallow-forward-seek-if-samples-are-needed.ts\nvar disallowForwardSeekIfSamplesAreNeeded = ({\n  seekTo,\n  previousPosition,\n  fields\n}) => {\n  const fieldsNeedingSamples = Object.entries(fields).filter(([, value]) => value).map(([key]) => key).filter((key) => fieldsNeedSamplesMap[key]);\n  if (fieldsNeedingSamples.length > 0) {\n    throw new Error(`Forward seeking is not allowed when the following fields are requested from parseMedia(): ${fieldsNeedingSamples.join(\", \")}. Seek was from 0x${previousPosition.toString(16)} to 0x${seekTo.toString(16)}. Either don't seek forward, or don't request these fields.`);\n  }\n};\n\n// src/seek-forwards.ts\nvar seekForward = async ({\n  seekTo,\n  userInitiated,\n  iterator,\n  fields,\n  logLevel,\n  currentReader,\n  readerInterface,\n  src,\n  controller,\n  discardReadBytes,\n  prefetchCache\n}) => {\n  if (userInitiated) {\n    disallowForwardSeekIfSamplesAreNeeded({\n      fields,\n      seekTo,\n      previousPosition: iterator.counter.getOffset()\n    });\n  }\n  const alreadyHasBuffer = iterator.bytesRemaining() >= seekTo - iterator.counter.getOffset();\n  Log.verbose(logLevel, `Performing seek from ${iterator.counter.getOffset()} to ${seekTo}`);\n  if (alreadyHasBuffer) {\n    iterator.skipTo(seekTo);\n    Log.verbose(logLevel, `Already read ahead enough, skipping forward`);\n    return;\n  }\n  const time = Date.now();\n  Log.verbose(logLevel, `Skipping over video data from position ${iterator.counter.getOffset()} -> ${seekTo}. Re-reading because this portion is not available`);\n  await currentReader.getCurrent().abort();\n  const { reader: newReader } = await readerInterface.read({\n    src,\n    range: seekTo,\n    controller,\n    logLevel,\n    prefetchCache\n  });\n  iterator.skipTo(seekTo);\n  await discardReadBytes(true);\n  Log.verbose(logLevel, `Re-reading took ${Date.now() - time}ms. New position: ${iterator.counter.getOffset()}`);\n  currentReader.setCurrent(newReader);\n};\n\n// src/perform-seek.ts\nvar performSeek = async ({\n  seekTo,\n  userInitiated,\n  controller,\n  mediaSection,\n  iterator,\n  seekInfiniteLoop,\n  logLevel,\n  mode,\n  contentLength,\n  currentReader,\n  readerInterface,\n  src,\n  discardReadBytes,\n  fields,\n  prefetchCache\n}) => {\n  const byteInMediaSection = isByteInMediaSection({\n    position: seekTo,\n    mediaSections: mediaSection.getMediaSections()\n  });\n  if (byteInMediaSection !== \"in-section\" && userInitiated) {\n    const sections = mediaSection.getMediaSections();\n    const sectionStrings = sections.map((section) => {\n      return `start: ${section.start}, end: ${section.size + section.start}`;\n    });\n    throw new Error(`Cannot seek to a byte that is not in the video section. Seeking to: ${seekTo}, sections: ${sectionStrings.join(\" | \")}`);\n  }\n  seekInfiniteLoop.registerSeek(seekTo);\n  if (seekTo <= iterator.counter.getOffset() && mode === \"download\") {\n    throw new Error(`Seeking backwards is not supported in parseAndDownloadMedia() mode. Current position: ${iterator.counter.getOffset()}, seekTo: ${seekTo}`);\n  }\n  if (seekTo > contentLength) {\n    throw new Error(`Cannot seek beyond the end of the file: ${seekTo} > ${contentLength}`);\n  }\n  if (mode === \"download\") {\n    Log.verbose(logLevel, `Skipping over video data from position ${iterator.counter.getOffset()} -> ${seekTo}. Fetching but not reading all the data inbetween because in download mode`);\n    iterator.discard(seekTo - iterator.counter.getOffset());\n    return;\n  }\n  await controller._internals.checkForAbortAndPause();\n  const alreadyAtByte = iterator.counter.getOffset() === seekTo;\n  if (alreadyAtByte) {\n    Log.verbose(logLevel, `Already at the desired position, seeking done`);\n    controller._internals.performedSeeksSignal.markLastSeekAsUserInitiated();\n    return;\n  }\n  const skippingForward = seekTo > iterator.counter.getOffset();\n  controller._internals.performedSeeksSignal.recordSeek({\n    from: iterator.counter.getOffset(),\n    to: seekTo,\n    type: userInitiated ? \"user-initiated\" : \"internal\"\n  });\n  if (skippingForward) {\n    await seekForward({\n      seekTo,\n      userInitiated,\n      iterator,\n      fields,\n      logLevel,\n      currentReader,\n      readerInterface,\n      src,\n      controller,\n      discardReadBytes,\n      prefetchCache\n    });\n  } else {\n    await seekBackwards({\n      controller,\n      seekTo,\n      iterator,\n      logLevel,\n      currentReader,\n      readerInterface,\n      src,\n      prefetchCache\n    });\n  }\n  await controller._internals.checkForAbortAndPause();\n};\n\n// src/work-on-seek-request.ts\nvar turnSeekIntoByte = async ({\n  seek: seek2,\n  mediaSectionState: mediaSectionState2,\n  logLevel,\n  iterator,\n  structureState,\n  m3uPlaylistContext,\n  isoState,\n  transportStream,\n  tracksState,\n  webmState,\n  keyframes,\n  flacState,\n  samplesObserved,\n  riffState,\n  mp3State,\n  contentLength,\n  aacState,\n  m3uState,\n  avcState\n}) => {\n  const mediaSections = mediaSectionState2.getMediaSections();\n  if (mediaSections.length === 0) {\n    Log.trace(logLevel, \"No media sections defined, cannot seek yet\");\n    return {\n      type: \"valid-but-must-wait\"\n    };\n  }\n  if (seek2 < 0) {\n    throw new Error(`Cannot seek to a negative time: ${JSON.stringify(seek2)}`);\n  }\n  const seekingHints = getSeekingHints({\n    riffState,\n    samplesObserved,\n    structureState,\n    mediaSectionState: mediaSectionState2,\n    isoState,\n    transportStream,\n    tracksState,\n    keyframesState: keyframes,\n    webmState,\n    flacState,\n    mp3State,\n    contentLength,\n    aacState,\n    m3uPlaylistContext\n  });\n  if (!seekingHints) {\n    Log.trace(logLevel, \"No seeking info, cannot seek yet\");\n    return {\n      type: \"valid-but-must-wait\"\n    };\n  }\n  const seekingByte = await getSeekingByte({\n    info: seekingHints,\n    time: seek2,\n    logLevel,\n    currentPosition: iterator.counter.getOffset(),\n    isoState,\n    transportStream,\n    webmState,\n    mediaSection: mediaSectionState2,\n    m3uPlaylistContext,\n    structure: structureState,\n    riffState,\n    m3uState,\n    avcState\n  });\n  return seekingByte;\n};\nvar getWorkOnSeekRequestOptions = (state) => {\n  return {\n    logLevel: state.logLevel,\n    controller: state.controller,\n    isoState: state.iso,\n    iterator: state.iterator,\n    structureState: state.structure,\n    src: state.src,\n    contentLength: state.contentLength,\n    readerInterface: state.readerInterface,\n    mediaSection: state.mediaSection,\n    m3uPlaylistContext: state.m3uPlaylistContext,\n    mode: state.mode,\n    seekInfiniteLoop: state.seekInfiniteLoop,\n    currentReader: state.currentReader,\n    discardReadBytes: state.discardReadBytes,\n    fields: state.fields,\n    transportStream: state.transportStream,\n    tracksState: state.callbacks.tracks,\n    webmState: state.webm,\n    keyframes: state.keyframes,\n    flacState: state.flac,\n    samplesObserved: state.samplesObserved,\n    riffState: state.riff,\n    mp3State: state.mp3,\n    aacState: state.aac,\n    m3uState: state.m3u,\n    prefetchCache: state.prefetchCache,\n    avcState: state.avc\n  };\n};\nvar workOnSeekRequest = async (options) => {\n  const {\n    logLevel,\n    controller,\n    mediaSection,\n    m3uPlaylistContext,\n    isoState,\n    iterator,\n    structureState,\n    src,\n    contentLength,\n    readerInterface,\n    mode,\n    seekInfiniteLoop,\n    currentReader,\n    discardReadBytes,\n    fields,\n    transportStream,\n    tracksState,\n    webmState,\n    keyframes,\n    flacState,\n    samplesObserved,\n    riffState,\n    mp3State,\n    aacState,\n    prefetchCache,\n    m3uState,\n    avcState\n  } = options;\n  const seek2 = controller._internals.seekSignal.getSeek();\n  if (seek2 === null) {\n    return;\n  }\n  Log.trace(logLevel, `Has seek request for ${src}: ${JSON.stringify(seek2)}`);\n  const resolution = await turnSeekIntoByte({\n    seek: seek2,\n    mediaSectionState: mediaSection,\n    logLevel,\n    iterator,\n    structureState,\n    m3uPlaylistContext,\n    isoState,\n    transportStream,\n    tracksState,\n    webmState,\n    keyframes,\n    flacState,\n    samplesObserved,\n    riffState,\n    mp3State,\n    contentLength,\n    aacState,\n    m3uState,\n    avcState\n  });\n  Log.trace(logLevel, `Seek action: ${JSON.stringify(resolution)}`);\n  if (resolution.type === \"intermediary-seek\") {\n    await performSeek({\n      seekTo: resolution.byte,\n      userInitiated: false,\n      controller,\n      mediaSection,\n      iterator,\n      logLevel,\n      mode,\n      contentLength,\n      seekInfiniteLoop,\n      currentReader,\n      readerInterface,\n      src,\n      discardReadBytes,\n      fields,\n      prefetchCache\n    });\n    return;\n  }\n  if (resolution.type === \"do-seek\") {\n    await performSeek({\n      seekTo: resolution.byte,\n      userInitiated: true,\n      controller,\n      mediaSection,\n      iterator,\n      logLevel,\n      mode,\n      contentLength,\n      seekInfiniteLoop,\n      currentReader,\n      readerInterface,\n      src,\n      discardReadBytes,\n      fields,\n      prefetchCache\n    });\n    const { hasChanged } = controller._internals.seekSignal.clearSeekIfStillSame(seek2);\n    if (hasChanged) {\n      Log.trace(logLevel, `Seek request has changed while seeking, seeking again`);\n      await workOnSeekRequest(options);\n    }\n    return;\n  }\n  if (resolution.type === \"invalid\") {\n    throw new Error(`The seek request ${JSON.stringify(seek2)} cannot be processed`);\n  }\n  if (resolution.type === \"valid-but-must-wait\") {\n    Log.trace(logLevel, \"Seek request is valid but cannot be processed yet\");\n  }\n};\n\n// src/emit-available-info.ts\nvar emitAvailableInfo = async ({\n  hasInfo,\n  state\n}) => {\n  const keys = Object.keys(hasInfo);\n  const {\n    emittedFields,\n    fieldsInReturnValue,\n    returnValue,\n    name,\n    callbackFunctions\n  } = state;\n  for (const key of keys) {\n    await workOnSeekRequest(getWorkOnSeekRequestOptions(state));\n    if (key === \"slowStructure\") {\n      if (hasInfo.slowStructure && !emittedFields.slowStructure) {\n        await callbackFunctions.onSlowStructure?.(state.structure.getStructure());\n        if (fieldsInReturnValue.slowStructure) {\n          returnValue.slowStructure = state.structure.getStructure();\n        }\n        emittedFields.slowStructure = true;\n      }\n      continue;\n    }\n    if (key === \"durationInSeconds\") {\n      if (hasInfo.durationInSeconds) {\n        if (!emittedFields.durationInSeconds) {\n          const durationInSeconds = getDuration(state);\n          await callbackFunctions.onDurationInSeconds?.(durationInSeconds);\n          if (fieldsInReturnValue.durationInSeconds) {\n            returnValue.durationInSeconds = durationInSeconds;\n          }\n          emittedFields.durationInSeconds = true;\n        }\n      }\n      continue;\n    }\n    if (key === \"slowDurationInSeconds\") {\n      if (hasInfo.slowDurationInSeconds && !emittedFields.slowDurationInSeconds) {\n        const slowDurationInSeconds = getDuration(state) ?? state.samplesObserved.getSlowDurationInSeconds();\n        await callbackFunctions.onSlowDurationInSeconds?.(slowDurationInSeconds);\n        if (fieldsInReturnValue.slowDurationInSeconds) {\n          returnValue.slowDurationInSeconds = slowDurationInSeconds;\n        }\n        emittedFields.slowDurationInSeconds = true;\n      }\n      continue;\n    }\n    if (key === \"fps\") {\n      if (hasInfo.fps) {\n        if (!emittedFields.fps) {\n          const fps = getFps(state);\n          await callbackFunctions.onFps?.(fps);\n          if (fieldsInReturnValue.fps) {\n            returnValue.fps = fps;\n          }\n          emittedFields.fps = true;\n        }\n        if (!emittedFields.slowFps) {\n          const fps = getFps(state);\n          if (fps) {\n            await callbackFunctions.onSlowFps?.(fps);\n            if (fieldsInReturnValue.slowFps) {\n              returnValue.slowFps = fps;\n            }\n            emittedFields.slowFps = true;\n          }\n        }\n      }\n      continue;\n    }\n    if (key === \"slowFps\") {\n      if (hasInfo.slowFps && !emittedFields.slowFps) {\n        const slowFps = getFps(state) ?? state.samplesObserved.getFps();\n        await callbackFunctions.onSlowFps?.(slowFps);\n        if (fieldsInReturnValue.slowFps) {\n          returnValue.slowFps = slowFps;\n        }\n        emittedFields.slowFps = true;\n      }\n      continue;\n    }\n    if (key === \"dimensions\") {\n      if (hasInfo.dimensions && !emittedFields.dimensions) {\n        const dimensionsQueried = getDimensions(state);\n        const dimensions = dimensionsQueried === null ? null : {\n          height: dimensionsQueried.height,\n          width: dimensionsQueried.width\n        };\n        await callbackFunctions.onDimensions?.(dimensions);\n        if (fieldsInReturnValue.dimensions) {\n          returnValue.dimensions = dimensions;\n        }\n        emittedFields.dimensions = true;\n      }\n      continue;\n    }\n    if (key === \"unrotatedDimensions\") {\n      if (hasInfo.unrotatedDimensions && !emittedFields.unrotatedDimensions) {\n        const dimensionsQueried = getDimensions(state);\n        const unrotatedDimensions = dimensionsQueried === null ? null : {\n          height: dimensionsQueried.unrotatedHeight,\n          width: dimensionsQueried.unrotatedWidth\n        };\n        await callbackFunctions.onUnrotatedDimensions?.(unrotatedDimensions);\n        if (fieldsInReturnValue.unrotatedDimensions) {\n          returnValue.unrotatedDimensions = unrotatedDimensions;\n        }\n        emittedFields.unrotatedDimensions = true;\n      }\n      continue;\n    }\n    if (key === \"rotation\") {\n      if (hasInfo.rotation && !emittedFields.rotation) {\n        const dimensionsQueried = getDimensions(state);\n        const rotation = dimensionsQueried?.rotation ?? 0;\n        await callbackFunctions.onRotation?.(rotation);\n        if (fieldsInReturnValue.rotation) {\n          returnValue.rotation = rotation;\n        }\n        emittedFields.rotation = true;\n      }\n      continue;\n    }\n    if (key === \"videoCodec\") {\n      if (!emittedFields.videoCodec && hasInfo.videoCodec) {\n        const videoCodec = getVideoCodec(state);\n        await callbackFunctions.onVideoCodec?.(videoCodec);\n        if (fieldsInReturnValue.videoCodec) {\n          returnValue.videoCodec = videoCodec;\n        }\n        emittedFields.videoCodec = true;\n      }\n      continue;\n    }\n    if (key === \"audioCodec\") {\n      if (!emittedFields.audioCodec && hasInfo.audioCodec) {\n        const audioCodec = getAudioCodec(state);\n        await callbackFunctions.onAudioCodec?.(audioCodec);\n        if (fieldsInReturnValue.audioCodec) {\n          returnValue.audioCodec = audioCodec;\n        }\n        emittedFields.audioCodec = true;\n      }\n      continue;\n    }\n    if (key === \"tracks\") {\n      if (!emittedFields.tracks && hasInfo.tracks) {\n        const tracks2 = getTracks(state, true);\n        await callbackFunctions.onTracks?.(tracks2);\n        if (fieldsInReturnValue.tracks) {\n          returnValue.tracks = tracks2;\n        }\n        emittedFields.tracks = true;\n      }\n      continue;\n    }\n    if (key === \"internalStats\") {\n      if (hasInfo.internalStats) {\n        const internalStats = state.getInternalStats();\n        if (fieldsInReturnValue.internalStats) {\n          returnValue.internalStats = internalStats;\n        }\n        emittedFields.internalStats = true;\n      }\n      continue;\n    }\n    if (key === \"size\") {\n      if (!emittedFields.size && hasInfo.size) {\n        await callbackFunctions.onSize?.(state.contentLength);\n        if (fieldsInReturnValue.size) {\n          returnValue.size = state.contentLength;\n        }\n        emittedFields.size = true;\n      }\n      continue;\n    }\n    if (key === \"mimeType\") {\n      if (!emittedFields.mimeType && hasInfo.mimeType) {\n        await callbackFunctions.onMimeType?.(state.mimeType);\n        if (fieldsInReturnValue.mimeType) {\n          returnValue.mimeType = state.mimeType;\n        }\n        emittedFields.mimeType = true;\n      }\n      continue;\n    }\n    if (key === \"name\") {\n      if (!emittedFields.name && hasInfo.name) {\n        await callbackFunctions.onName?.(name);\n        if (fieldsInReturnValue.name) {\n          returnValue.name = name;\n        }\n        emittedFields.name = true;\n      }\n      continue;\n    }\n    if (key === \"isHdr\") {\n      if (!returnValue.isHdr && hasInfo.isHdr) {\n        const isHdr = getIsHdr(state);\n        await callbackFunctions.onIsHdr?.(isHdr);\n        if (fieldsInReturnValue.isHdr) {\n          returnValue.isHdr = isHdr;\n        }\n        emittedFields.isHdr = true;\n      }\n      continue;\n    }\n    if (key === \"container\") {\n      if (!returnValue.container && hasInfo.container) {\n        const container = getContainer(state.structure.getStructure());\n        await callbackFunctions.onContainer?.(container);\n        if (fieldsInReturnValue.container) {\n          returnValue.container = container;\n        }\n        emittedFields.container = true;\n      }\n      continue;\n    }\n    if (key === \"metadata\") {\n      if (!emittedFields.metadata && hasInfo.metadata) {\n        const metadata = getMetadata(state);\n        await callbackFunctions.onMetadata?.(metadata);\n        if (fieldsInReturnValue.metadata) {\n          returnValue.metadata = metadata;\n        }\n        emittedFields.metadata = true;\n      }\n      continue;\n    }\n    if (key === \"location\") {\n      if (!emittedFields.location && hasInfo.location) {\n        const location = getLocation(state);\n        await callbackFunctions.onLocation?.(location);\n        if (fieldsInReturnValue.location) {\n          returnValue.location = location;\n        }\n        emittedFields.location = true;\n      }\n      continue;\n    }\n    if (key === \"slowKeyframes\") {\n      if (!emittedFields.slowKeyframes && hasInfo.slowKeyframes) {\n        await callbackFunctions.onSlowKeyframes?.(state.keyframes.getKeyframes());\n        if (fieldsInReturnValue.slowKeyframes) {\n          returnValue.slowKeyframes = state.keyframes.getKeyframes();\n        }\n        emittedFields.slowKeyframes = true;\n      }\n      continue;\n    }\n    if (key === \"slowNumberOfFrames\") {\n      if (!emittedFields.slowNumberOfFrames && hasInfo.slowNumberOfFrames) {\n        await callbackFunctions.onSlowNumberOfFrames?.(state.samplesObserved.getSlowNumberOfFrames());\n        if (fieldsInReturnValue.slowNumberOfFrames) {\n          returnValue.slowNumberOfFrames = state.samplesObserved.getSlowNumberOfFrames();\n        }\n        emittedFields.slowNumberOfFrames = true;\n      }\n      continue;\n    }\n    if (key === \"slowAudioBitrate\") {\n      if (!emittedFields.slowAudioBitrate && hasInfo.slowAudioBitrate) {\n        await callbackFunctions.onSlowAudioBitrate?.(state.samplesObserved.getAudioBitrate());\n        if (fieldsInReturnValue.slowAudioBitrate) {\n          returnValue.slowAudioBitrate = state.samplesObserved.getAudioBitrate();\n        }\n        emittedFields.slowAudioBitrate = true;\n      }\n      continue;\n    }\n    if (key === \"slowVideoBitrate\") {\n      if (!emittedFields.slowVideoBitrate && hasInfo.slowVideoBitrate) {\n        await callbackFunctions.onSlowVideoBitrate?.(state.samplesObserved.getVideoBitrate());\n        if (fieldsInReturnValue.slowVideoBitrate) {\n          returnValue.slowVideoBitrate = state.samplesObserved.getVideoBitrate();\n        }\n        emittedFields.slowVideoBitrate = true;\n      }\n      continue;\n    }\n    if (key === \"keyframes\") {\n      if (!emittedFields.keyframes && hasInfo.keyframes) {\n        await callbackFunctions.onKeyframes?.(getKeyframes(state));\n        if (fieldsInReturnValue.keyframes) {\n          returnValue.keyframes = getKeyframes(state);\n        }\n        emittedFields.keyframes = true;\n      }\n      continue;\n    }\n    if (key === \"images\") {\n      if (!emittedFields.images && hasInfo.images) {\n        await callbackFunctions.onImages?.(state.images.images);\n        if (fieldsInReturnValue.images) {\n          returnValue.images = state.images.images;\n        }\n        emittedFields.images = true;\n      }\n      continue;\n    }\n    if (key === \"sampleRate\") {\n      if (!emittedFields.sampleRate && hasInfo.sampleRate) {\n        const sampleRate = getSampleRate3(state);\n        await callbackFunctions.onSampleRate?.(sampleRate);\n        if (fieldsInReturnValue.sampleRate) {\n          returnValue.sampleRate = sampleRate;\n        }\n        emittedFields.sampleRate = true;\n      }\n      continue;\n    }\n    if (key === \"numberOfAudioChannels\") {\n      if (!emittedFields.numberOfAudioChannels && hasInfo.numberOfAudioChannels) {\n        const numberOfAudioChannels = getNumberOfAudioChannels(state);\n        await callbackFunctions.onNumberOfAudioChannels?.(numberOfAudioChannels);\n        if (fieldsInReturnValue.numberOfAudioChannels) {\n          returnValue.numberOfAudioChannels = numberOfAudioChannels;\n        }\n        emittedFields.numberOfAudioChannels = true;\n      }\n      continue;\n    }\n    if (key === \"m3uStreams\") {\n      if (!emittedFields.m3uStreams && hasInfo.m3uStreams) {\n        const streams = getM3uStreams({\n          structure: state.structure.getStructureOrNull(),\n          originalSrc: state.src,\n          readerInterface: state.readerInterface\n        });\n        await callbackFunctions.onM3uStreams?.(streams);\n        if (fieldsInReturnValue.m3uStreams) {\n          returnValue.m3uStreams = streams;\n        }\n        emittedFields.m3uStreams = true;\n      }\n      continue;\n    }\n    throw new Error(`Unhandled key: ${key}`);\n  }\n  await workOnSeekRequest(getWorkOnSeekRequestOptions(state));\n};\n\n// src/state/may-skip-video-data.ts\nvar getHasCallbacks = (state) => {\n  const hasNoTrackHandlers = !state.callbacks.hasAudioTrackHandlers && !state.callbacks.hasVideoTrackHandlers;\n  if (hasNoTrackHandlers) {\n    return false;\n  }\n  const hasAllTracksAndNoCallbacks = !state.callbacks.tracks.hasAllTracks() || Object.values(state.callbacks.videoSampleCallbacks).length > 0 || Object.values(state.callbacks.audioSampleCallbacks).length > 0;\n  return hasAllTracksAndNoCallbacks;\n};\nvar missesMatroskaTracks = (state) => {\n  const struct = state.structure.getStructureOrNull();\n  if (struct === null) {\n    return false;\n  }\n  if (struct.type !== \"matroska\") {\n    return false;\n  }\n  const mainSegment = getMainSegment(struct.boxes);\n  if (mainSegment === null) {\n    return false;\n  }\n  return getTracksFromMatroska({\n    structureState: state.structure,\n    webmState: state.webm\n  }).missingInfo.length > 0;\n};\nvar maySkipVideoData = ({ state }) => {\n  const hasCallbacks = getHasCallbacks(state);\n  return !hasCallbacks && !needsToIterateOverSamples({\n    emittedFields: state.emittedFields,\n    fields: state.fields\n  }) && !missesMatroskaTracks(state);\n};\nvar maySkipOverSamplesInTheMiddle = ({\n  state\n}) => {\n  const hasCallbacks = getHasCallbacks(state);\n  return !hasCallbacks && !needsToIterateOverEverySample({\n    emittedFields: state.emittedFields,\n    fields: state.fields\n  });\n};\n\n// src/has-all-info.ts\nvar getAvailableInfo = ({\n  state\n}) => {\n  const keys = Object.entries(state.fields).filter(([, value]) => value);\n  const structure = state.structure.getStructureOrNull();\n  const infos = keys.map(([_key]) => {\n    const key = _key;\n    if (key === \"slowStructure\") {\n      return false;\n    }\n    if (key === \"durationInSeconds\") {\n      return Boolean(structure && hasDuration(state));\n    }\n    if (key === \"slowDurationInSeconds\") {\n      const res = Boolean(structure && hasSlowDuration(state));\n      return res;\n    }\n    if (key === \"dimensions\" || key === \"rotation\" || key === \"unrotatedDimensions\") {\n      return Boolean(structure && hasDimensions(state));\n    }\n    if (key === \"fps\") {\n      return Boolean(structure && hasFps(state));\n    }\n    if (key === \"slowFps\") {\n      return Boolean(structure && hasFpsSuitedForSlowFps(state));\n    }\n    if (key === \"isHdr\") {\n      return Boolean(structure && hasHdr(state));\n    }\n    if (key === \"videoCodec\") {\n      return Boolean(structure && hasVideoCodec(state));\n    }\n    if (key === \"audioCodec\") {\n      return Boolean(structure && hasAudioCodec(state));\n    }\n    if (key === \"tracks\") {\n      return Boolean(structure && getHasTracks(state, true));\n    }\n    if (key === \"keyframes\") {\n      return Boolean(structure && hasKeyframes(state));\n    }\n    if (key === \"internalStats\") {\n      return true;\n    }\n    if (key === \"size\") {\n      return true;\n    }\n    if (key === \"mimeType\") {\n      return true;\n    }\n    if (key === \"name\") {\n      return true;\n    }\n    if (key === \"container\") {\n      return Boolean(structure && hasContainer(structure));\n    }\n    if (key === \"metadata\" || key === \"location\" || key === \"images\") {\n      return Boolean(structure && hasMetadata(structure));\n    }\n    if (key === \"slowKeyframes\" || key === \"slowVideoBitrate\" || key === \"slowAudioBitrate\" || key === \"slowNumberOfFrames\") {\n      return false;\n    }\n    if (key === \"numberOfAudioChannels\") {\n      return hasNumberOfAudioChannels(state);\n    }\n    if (key === \"sampleRate\") {\n      return hasSampleRate(state);\n    }\n    if (key === \"m3uStreams\") {\n      return m3uHasStreams(state);\n    }\n    throw new Error(`Unknown field passed: ${key}. Available fields: ${Object.keys(state.fields).join(\", \")}`);\n  });\n  const entries = [];\n  let i = 0;\n  for (const [key] of keys) {\n    entries.push([key, infos[i++]]);\n  }\n  return Object.fromEntries(entries);\n};\nvar hasAllInfo = ({ state }) => {\n  const availableInfo = getAvailableInfo({\n    state\n  });\n  if (!Object.values(availableInfo).every(Boolean)) {\n    return false;\n  }\n  if (maySkipVideoData({ state })) {\n    return true;\n  }\n  if (state.callbacks.canSkipTracksState.canSkipTracks()) {\n    return true;\n  }\n  return false;\n};\n\n// src/emit-all-info.ts\nvar emitAllInfo = async (state) => {\n  const allFields = Object.keys(state.fields).reduce((acc, key) => {\n    if (state.fields?.[key]) {\n      acc[key] = true;\n    }\n    return acc;\n  }, {});\n  await emitAvailableInfo({\n    hasInfo: allFields,\n    state\n  });\n};\nvar triggerInfoEmit = async (state) => {\n  const availableInfo = getAvailableInfo({\n    state\n  });\n  await emitAvailableInfo({\n    hasInfo: availableInfo,\n    state\n  });\n};\n\n// src/check-if-done.ts\nvar checkIfDone = async (state) => {\n  const startCheck = Date.now();\n  const hasAll = hasAllInfo({\n    state\n  });\n  state.timings.timeCheckingIfDone += Date.now() - startCheck;\n  if (hasAll && state.mode === \"query\") {\n    Log.verbose(state.logLevel, \"Got all info, skipping to the end.\");\n    state.increaseSkippedBytes(state.contentLength - state.iterator.counter.getOffset());\n    return true;\n  }\n  if (state.iterator.counter.getOffset() === state.contentLength) {\n    if (state.structure.getStructure().type === \"m3u\" && !state.m3u.getAllChunksProcessedOverall()) {\n      return false;\n    }\n    state.riff.queuedBFrames.flush();\n    if (state.riff.queuedBFrames.hasReleasedFrames()) {\n      return false;\n    }\n    Log.verbose(state.logLevel, \"Reached end of file\");\n    await state.discardReadBytes(true);\n    return true;\n  }\n  if (state.iterator.counter.getOffset() + state.iterator.bytesRemaining() === state.contentLength && state.errored) {\n    Log.verbose(state.logLevel, \"Reached end of file and errorred\");\n    return true;\n  }\n  return false;\n};\n\n// src/make-progress-object.ts\nvar makeProgressObject = (state) => {\n  return {\n    bytes: state.iterator.counter.getOffset(),\n    percentage: state.contentLength ? state.iterator.counter.getOffset() / state.contentLength : null,\n    totalBytes: state.contentLength\n  };\n};\n\n// src/containers/aac/parse-aac.ts\nvar parseAac = async (state) => {\n  const { iterator } = state;\n  const startOffset = iterator.counter.getOffset();\n  iterator.startReadingBits();\n  const syncWord = iterator.getBits(12);\n  if (syncWord !== 4095) {\n    throw new Error(\"Invalid syncword: \" + syncWord);\n  }\n  const id = iterator.getBits(1);\n  if (id !== 0) {\n    throw new Error(\"Only supporting MPEG-4 for .aac\");\n  }\n  const layer = iterator.getBits(2);\n  if (layer !== 0) {\n    throw new Error(\"Only supporting layer 0 for .aac\");\n  }\n  const protectionAbsent = iterator.getBits(1);\n  const audioObjectType = iterator.getBits(2);\n  const samplingFrequencyIndex = iterator.getBits(4);\n  const sampleRate = getSampleRateFromSampleFrequencyIndex(samplingFrequencyIndex);\n  iterator.getBits(1);\n  const channelConfiguration = iterator.getBits(3);\n  const codecPrivate2 = createAacCodecPrivate({\n    audioObjectType,\n    sampleRate,\n    channelConfiguration,\n    codecPrivate: null\n  });\n  iterator.getBits(1);\n  iterator.getBits(1);\n  iterator.getBits(1);\n  iterator.getBits(1);\n  const frameLength = iterator.getBits(13);\n  iterator.getBits(11);\n  iterator.getBits(2);\n  if (!protectionAbsent) {\n    iterator.getBits(16);\n  }\n  iterator.stopReadingBits();\n  iterator.counter.decrement(iterator.counter.getOffset() - startOffset);\n  const data = iterator.getSlice(frameLength);\n  if (state.callbacks.tracks.getTracks().length === 0) {\n    state.mediaSection.addMediaSection({\n      start: startOffset,\n      size: state.contentLength - startOffset\n    });\n    await registerAudioTrack({\n      container: \"aac\",\n      track: {\n        codec: mapAudioObjectTypeToCodecString(audioObjectType),\n        codecEnum: \"aac\",\n        codecData: { type: \"aac-config\", data: codecPrivate2 },\n        description: codecPrivate2,\n        numberOfChannels: channelConfiguration,\n        sampleRate,\n        originalTimescale: WEBCODECS_TIMESCALE,\n        trackId: 0,\n        type: \"audio\",\n        startInSeconds: 0,\n        timescale: WEBCODECS_TIMESCALE\n      },\n      registerAudioSampleCallback: state.callbacks.registerAudioSampleCallback,\n      tracks: state.callbacks.tracks,\n      logLevel: state.logLevel,\n      onAudioTrack: state.onAudioTrack\n    });\n    state.callbacks.tracks.setIsDone(state.logLevel);\n  }\n  const duration2 = 1024 / sampleRate;\n  const { index } = state.aac.addSample({ offset: startOffset, size: frameLength });\n  const timestamp = 1024 / sampleRate * index;\n  state.aac.audioSamples.addSample({\n    timeInSeconds: timestamp,\n    offset: startOffset,\n    durationInSeconds: duration2\n  });\n  const audioSample = convertAudioOrVideoSampleToWebCodecsTimestamps({\n    sample: {\n      duration: duration2,\n      type: \"key\",\n      data,\n      offset: startOffset,\n      decodingTimestamp: timestamp,\n      timestamp\n    },\n    timescale: 1\n  });\n  await state.callbacks.onAudioSample({\n    audioSample,\n    trackId: 0\n  });\n  return Promise.resolve(null);\n};\n\n// src/skip.ts\nvar makeSkip = (skipTo) => ({\n  action: \"skip\",\n  skipTo\n});\nvar makeFetchMoreData = (bytesNeeded) => ({\n  action: \"fetch-more-data\",\n  bytesNeeded\n});\n\n// src/containers/flac/get-block-size.ts\nvar getBlockSize = (iterator) => {\n  const bits = iterator.getBits(4);\n  if (bits === 0) {\n    throw new Error(\"Reserved block size\");\n  }\n  if (bits === 1) {\n    return 192;\n  }\n  if (bits >= 2 && bits <= 5) {\n    return 144 * 2 ** bits;\n  }\n  if (bits === 6) {\n    return \"uncommon-u8\";\n  }\n  if (bits === 7) {\n    return \"uncommon-u16\";\n  }\n  if (bits >= 8 && bits <= 15) {\n    return 2 ** bits;\n  }\n  throw new Error(\"Invalid block size\");\n};\n\n// src/containers/flac/get-channel-count.ts\nvar getChannelCount = (iterator) => {\n  const bits = iterator.getBits(4);\n  if (bits === 0) {\n    return 1;\n  }\n  if (bits === 1) {\n    return 2;\n  }\n  if (bits === 2) {\n    return 3;\n  }\n  if (bits === 3) {\n    return 4;\n  }\n  if (bits === 4) {\n    return 5;\n  }\n  if (bits === 5) {\n    return 6;\n  }\n  if (bits === 6) {\n    return 7;\n  }\n  if (bits === 7) {\n    return 8;\n  }\n  if (bits === 8 || bits === 9 || bits === 10) {\n    return 2;\n  }\n  throw new Error(`Invalid channel count: ${bits.toString(2)}`);\n};\n\n// src/containers/flac/get-sample-rate.ts\nvar getSampleRate4 = (iterator, state) => {\n  const mode = iterator.getBits(4);\n  if (mode === 0) {\n    const structure = state.structure.getFlacStructure();\n    const sampleRate = structure.boxes.find((box) => box.type === \"flac-streaminfo\")?.sampleRate ?? null;\n    if (sampleRate === null) {\n      throw new Error(\"Sample rate not found\");\n    }\n    return sampleRate;\n  }\n  if (mode === 1) {\n    return 88200;\n  }\n  if (mode === 2) {\n    return 176400;\n  }\n  if (mode === 3) {\n    return 192000;\n  }\n  if (mode === 4) {\n    return 8000;\n  }\n  if (mode === 5) {\n    return 16000;\n  }\n  if (mode === 6) {\n    return 22050;\n  }\n  if (mode === 7) {\n    return 24000;\n  }\n  if (mode === 8) {\n    return 32000;\n  }\n  if (mode === 9) {\n    return 44100;\n  }\n  if (mode === 10) {\n    return 48000;\n  }\n  if (mode === 11) {\n    return 96000;\n  }\n  if (mode === 12) {\n    return \"uncommon-u8\";\n  }\n  if (mode === 13) {\n    return \"uncommon-u16\";\n  }\n  if (mode === 14) {\n    return \"uncommon-u16-10\";\n  }\n  throw new Error(`Invalid sample rate mode: ${mode.toString(2)}`);\n};\n\n// src/containers/flac/parse-flac-frame.ts\nfunction calculateCRC8(data) {\n  const polynomial = 7;\n  let crc = 0;\n  for (const byte of data) {\n    crc ^= byte;\n    for (let i = 0;i < 8; i++) {\n      if ((crc & 128) !== 0) {\n        crc = crc << 1 ^ polynomial;\n      } else {\n        crc <<= 1;\n      }\n      crc &= 255;\n    }\n  }\n  return crc;\n}\nvar parseFrameHeader = ({\n  iterator,\n  state\n}) => {\n  if (iterator.bytesRemaining() < 10) {\n    return null;\n  }\n  const startOffset = iterator.counter.getOffset();\n  iterator.discard(2);\n  iterator.startReadingBits();\n  const blockSizeBits = getBlockSize(iterator);\n  const sampleRateBits = getSampleRate4(iterator, state);\n  getChannelCount(iterator);\n  iterator.getBits(3);\n  iterator.getBits(1);\n  const num = iterator.getFlacCodecNumber();\n  const blockSize = blockSizeBits === \"uncommon-u16\" ? iterator.getBits(16) + 1 : blockSizeBits === \"uncommon-u8\" ? iterator.getBits(8) + 1 : blockSizeBits;\n  const sampleRate = sampleRateBits === \"uncommon-u16\" ? iterator.getBits(16) : sampleRateBits === \"uncommon-u16-10\" ? iterator.getBits(16) * 10 : sampleRateBits === \"uncommon-u8\" ? iterator.getBits(8) : sampleRateBits;\n  iterator.stopReadingBits();\n  const size = iterator.counter.getOffset() - startOffset;\n  const crc = iterator.getUint8();\n  iterator.counter.decrement(size + 1);\n  const crcCalculated = calculateCRC8(iterator.getSlice(size));\n  iterator.counter.decrement(size);\n  if (crcCalculated !== crc) {\n    return null;\n  }\n  return { num, blockSize, sampleRate };\n};\nvar emitSample = async ({\n  state,\n  data,\n  offset\n}) => {\n  const iterator = getArrayBufferIterator({\n    initialData: data,\n    maxBytes: data.length,\n    logLevel: \"error\"\n  });\n  const parsed = parseFrameHeader({ iterator, state });\n  if (!parsed) {\n    throw new Error(\"Invalid CRC\");\n  }\n  const { blockSize, num, sampleRate } = parsed;\n  const duration2 = blockSize / sampleRate;\n  const structure = state.structure.getFlacStructure();\n  const streamInfo = structure.boxes.find((box) => box.type === \"flac-streaminfo\");\n  if (!streamInfo) {\n    throw new Error(\"Stream info not found\");\n  }\n  if (streamInfo.minimumBlockSize !== streamInfo.maximumBlockSize) {\n    throw new Error(\"Cannot determine timestamp\");\n  }\n  const timestamp = num * streamInfo.maximumBlockSize / streamInfo.sampleRate;\n  state.flac.audioSamples.addSample({\n    timeInSeconds: timestamp,\n    offset,\n    durationInSeconds: duration2\n  });\n  const audioSample = convertAudioOrVideoSampleToWebCodecsTimestamps({\n    sample: {\n      data,\n      duration: duration2,\n      decodingTimestamp: timestamp,\n      timestamp,\n      type: \"key\",\n      offset\n    },\n    timescale: 1\n  });\n  await state.callbacks.onAudioSample({\n    audioSample,\n    trackId: 0\n  });\n  iterator.destroy();\n};\nvar parseFlacFrame = async ({\n  state,\n  iterator\n}) => {\n  const blockingBit = state.flac.getBlockingBitStrategy();\n  const offset = iterator.counter.getOffset();\n  const { returnToCheckpoint } = iterator.startCheckpoint();\n  iterator.startReadingBits();\n  if (blockingBit === undefined) {\n    const bits = iterator.getBits(15);\n    if (bits !== 32764) {\n      throw new Error(\"Invalid sync code\");\n    }\n    state.flac.setBlockingBitStrategy(iterator.getBits(1));\n  } else if (blockingBit === 1) {\n    const bits = iterator.getBits(16);\n    if (bits !== 65529) {\n      throw new Error(\"Blocking bit changed, it should not\");\n    }\n  } else if (blockingBit === 0) {\n    const bits = iterator.getBits(16);\n    if (bits !== 65528) {\n      throw new Error(\"Blocking bit changed, it should not\");\n    }\n  }\n  const setBlockingBit = state.flac.getBlockingBitStrategy();\n  if (setBlockingBit === undefined) {\n    throw new Error(\"Blocking bit should be set\");\n  }\n  iterator.stopReadingBits();\n  const structure = state.structure.getFlacStructure();\n  const minimumFrameSize = structure.boxes.find((b) => b.type === \"flac-streaminfo\")?.minimumFrameSize ?? null;\n  if (minimumFrameSize === null) {\n    throw new Error(\"Expected flac-streaminfo\");\n  }\n  if (minimumFrameSize !== 0) {\n    iterator.getSlice(minimumFrameSize - 2);\n  }\n  while (true) {\n    if (iterator.counter.getOffset() === state.contentLength) {\n      const size = iterator.counter.getOffset() - offset;\n      returnToCheckpoint();\n      const slice = iterator.getSlice(size);\n      await emitSample({ state, data: slice, offset });\n      break;\n    }\n    if (iterator.bytesRemaining() === 0) {\n      returnToCheckpoint();\n      break;\n    }\n    const nextByte = iterator.getUint8();\n    if (nextByte === 255) {\n      const nextBits = iterator.getUint8();\n      const expected = setBlockingBit === 1 ? 249 : 248;\n      if (nextBits !== expected) {\n        iterator.counter.decrement(1);\n        continue;\n      }\n      iterator.counter.decrement(2);\n      const nextIsLegit = parseFrameHeader({ iterator, state });\n      if (!nextIsLegit) {\n        iterator.discard(1);\n        continue;\n      }\n      const size = iterator.counter.getOffset() - offset;\n      returnToCheckpoint();\n      const data = iterator.getSlice(size);\n      await emitSample({ state, data, offset });\n      break;\n    }\n  }\n  return null;\n};\n\n// src/containers/flac/parse-header.ts\nvar parseFlacHeader = ({\n  state\n}) => {\n  state.structure.getFlacStructure().boxes.push({\n    type: \"flac-header\"\n  });\n  return Promise.resolve(null);\n};\n\n// src/containers/flac/parse-metadata.ts\nvar parseVorbisComment = ({\n  state,\n  iterator,\n  size\n}) => {\n  const { expectNoMoreBytes } = iterator.startBox(size);\n  const box = {\n    type: \"flac-vorbis-comment\",\n    fields: []\n  };\n  const vendorLength = iterator.getUint32Le();\n  const vendorString = iterator.getByteString(vendorLength, true);\n  const numberOfFields = iterator.getUint32Le();\n  box.fields.push({ key: \"vendor\", value: vendorString, trackId: null });\n  for (let i = 0;i < numberOfFields; i++) {\n    const fieldLength = iterator.getUint32Le();\n    const field = iterator.getByteString(fieldLength, true);\n    const [key, value] = field.split(\"=\");\n    box.fields.push({ key: key.toLowerCase(), value, trackId: null });\n  }\n  state.structure.getFlacStructure().boxes.push(box);\n  expectNoMoreBytes();\n  return Promise.resolve(null);\n};\n\n// src/containers/flac/parse-streaminfo.ts\nvar parseStreamInfo = async ({\n  iterator,\n  state\n}) => {\n  const counter = iterator.counter.getOffset();\n  const minimumBlockSize = iterator.getUint16();\n  const maximumBlockSize = iterator.getUint16();\n  const minimumFrameSize = iterator.getUint24();\n  const maximumFrameSize = iterator.getUint24();\n  iterator.startReadingBits();\n  const sampleRate = iterator.getBits(20);\n  const channels2 = iterator.getBits(3) + 1;\n  const bitsPerSample = iterator.getBits(5);\n  const totalSamples = iterator.getBits(36);\n  iterator.getBits(128);\n  iterator.stopReadingBits();\n  const counterNow = iterator.counter.getOffset();\n  const size = counterNow - counter;\n  iterator.counter.decrement(size);\n  const asUint8Array = iterator.getSlice(size);\n  const flacStreamInfo = {\n    type: \"flac-streaminfo\",\n    bitsPerSample,\n    channels: channels2,\n    maximumBlockSize,\n    maximumFrameSize,\n    minimumBlockSize,\n    minimumFrameSize,\n    sampleRate,\n    totalSamples\n  };\n  state.structure.getFlacStructure().boxes.push(flacStreamInfo);\n  await registerAudioTrack({\n    container: \"flac\",\n    track: {\n      codec: \"flac\",\n      type: \"audio\",\n      description: asUint8Array,\n      codecData: { type: \"flac-description\", data: asUint8Array },\n      codecEnum: \"flac\",\n      numberOfChannels: channels2,\n      sampleRate,\n      originalTimescale: WEBCODECS_TIMESCALE,\n      trackId: 0,\n      startInSeconds: 0,\n      timescale: WEBCODECS_TIMESCALE\n    },\n    registerAudioSampleCallback: state.callbacks.registerAudioSampleCallback,\n    tracks: state.callbacks.tracks,\n    logLevel: state.logLevel,\n    onAudioTrack: state.onAudioTrack\n  });\n  state.callbacks.tracks.setIsDone(state.logLevel);\n  return Promise.resolve(null);\n};\n\n// src/containers/flac/parse-unknown-block.ts\nvar parseFlacUnkownBlock = ({\n  iterator,\n  state,\n  size\n}) => {\n  iterator.discard(size);\n  state.structure.getFlacStructure().boxes.push({\n    type: \"flac-header\"\n  });\n  return Promise.resolve(null);\n};\n\n// src/containers/flac/parse-meta.ts\nvar flacTypes = {\n  streaminfo: 0,\n  vorbisComment: 4\n};\nvar parseMetaBlock = ({\n  iterator,\n  state\n}) => {\n  iterator.startReadingBits();\n  const isLastMetadata = iterator.getBits(1);\n  const metaBlockType = iterator.getBits(7);\n  iterator.stopReadingBits();\n  const size = iterator.getUint24();\n  if (isLastMetadata) {\n    state.mediaSection.addMediaSection({\n      start: iterator.counter.getOffset() + size,\n      size: state.contentLength - iterator.counter.getOffset() - size\n    });\n  }\n  if (metaBlockType === flacTypes.streaminfo) {\n    return parseStreamInfo({ iterator, state });\n  }\n  if (metaBlockType === flacTypes.vorbisComment) {\n    return parseVorbisComment({ iterator, state, size });\n  }\n  return parseFlacUnkownBlock({ iterator, state, size });\n};\n\n// src/containers/flac/parse-flac.ts\nvar parseFlac = ({\n  iterator,\n  state\n}) => {\n  const mediaSectionState2 = state.mediaSection.isCurrentByteInMediaSection(iterator);\n  if (mediaSectionState2 === \"in-section\") {\n    if (maySkipVideoData({ state })) {\n      return Promise.resolve(makeSkip(state.contentLength));\n    }\n    return parseFlacFrame({ state, iterator });\n  }\n  const bytes = iterator.getByteString(4, true);\n  if (bytes === \"fLaC\") {\n    return parseFlacHeader({ state, iterator });\n  }\n  iterator.counter.decrement(4);\n  return parseMetaBlock({\n    iterator,\n    state\n  });\n};\n\n// src/state/iso-base-media/cached-sample-positions.ts\nvar calculateFlatSamples = ({\n  state,\n  mediaSectionStart\n}) => {\n  const tracks2 = getTracks(state, true);\n  const moofBoxes = getMoofBoxes(state.structure.getIsoStructure().boxes);\n  const tfraBoxes = deduplicateTfraBoxesByOffset([\n    ...state.iso.tfra.getTfraBoxes(),\n    ...getTfraBoxes(state.structure.getIsoStructure().boxes)\n  ]);\n  const moofComplete = areSamplesComplete({ moofBoxes, tfraBoxes });\n  const relevantMoofBox = moofBoxes.find((moofBox) => moofBox.offset + moofBox.size + 8 === mediaSectionStart);\n  if (moofBoxes.length > 0 && !relevantMoofBox) {\n    throw new Error(\"No relevant moof box found\");\n  }\n  const moov = getMoovBoxFromState({\n    structureState: state.structure,\n    isoState: state.iso,\n    mp4HeaderSegment: state.m3uPlaylistContext?.mp4HeaderSegment ?? null,\n    mayUsePrecomputed: true\n  });\n  if (!moov) {\n    throw new Error(\"No moov box found\");\n  }\n  const flatSamples = tracks2.map((track) => {\n    const trakBox = getTrakBoxByTrackId(moov, track.trackId);\n    if (!trakBox) {\n      throw new Error(\"No trak box found\");\n    }\n    const { samplePositions } = getSamplePositionsFromTrack({\n      trakBox,\n      moofBoxes: relevantMoofBox ? [relevantMoofBox] : [],\n      moofComplete,\n      trexBoxes: getTrexBoxes(moov)\n    });\n    return samplePositions.map((samplePosition) => {\n      return {\n        track,\n        samplePosition\n      };\n    });\n  });\n  return flatSamples;\n};\nvar cachedSamplePositionsState = () => {\n  const cachedForMdatStart = {};\n  const jumpMarksForMdatStart = {};\n  return {\n    getSamples: (mdatStart) => {\n      return cachedForMdatStart[mdatStart] ?? null;\n    },\n    setSamples: (mdatStart, samples) => {\n      cachedForMdatStart[mdatStart] = samples;\n    },\n    setJumpMarks: (mdatStart, marks) => {\n      jumpMarksForMdatStart[mdatStart] = marks;\n    },\n    getJumpMarks: (mdatStart) => {\n      return jumpMarksForMdatStart[mdatStart];\n    }\n  };\n};\n\n// src/state/iso-base-media/last-moof-box.ts\nvar getLastMoofBox = (boxes) => {\n  if (boxes) {\n    const tfras = boxes.filter((b) => b.type === \"tfra-box\");\n    const lastMoofOffsets = tfras.map((f) => {\n      if (f.entries.length <= 1) {\n        return null;\n      }\n      return f.entries[f.entries.length - 1].moofOffset;\n    });\n    if (lastMoofOffsets.length > 0) {\n      const maxOffset = Math.max(...lastMoofOffsets.filter(truthy));\n      return maxOffset;\n    }\n    return null;\n  }\n};\nvar getMaxFirstMoofOffset = (boxes) => {\n  const tfras = boxes.filter((b) => b.type === \"tfra-box\");\n  const firstMoofOffsets = tfras.map((f) => {\n    return f.entries[0].moofOffset;\n  });\n  return Math.max(...firstMoofOffsets.filter(truthy));\n};\n\n// src/state/can-skip-tracks.ts\nvar needsTracksForField = ({\n  field,\n  structure\n}) => {\n  if (field === \"dimensions\") {\n    if (structure?.type === \"riff\") {\n      return false;\n    }\n    return true;\n  }\n  if (field === \"audioCodec\" || field === \"durationInSeconds\" || field === \"slowDurationInSeconds\" || field === \"slowFps\" || field === \"fps\" || field === \"isHdr\" || field === \"rotation\" || field === \"slowStructure\" || field === \"tracks\" || field === \"unrotatedDimensions\" || field === \"videoCodec\" || field === \"metadata\" || field === \"location\" || field === \"slowKeyframes\" || field === \"slowNumberOfFrames\" || field === \"keyframes\" || field === \"images\" || field === \"sampleRate\" || field === \"numberOfAudioChannels\" || field === \"slowAudioBitrate\" || field === \"slowVideoBitrate\" || field === \"m3uStreams\") {\n    return true;\n  }\n  if (field === \"container\" || field === \"internalStats\" || field === \"mimeType\" || field === \"name\" || field === \"size\") {\n    return false;\n  }\n  throw new Error(`field not implemeted ${field}`);\n};\nvar makeCanSkipTracksState = ({\n  hasAudioTrackHandlers,\n  fields,\n  hasVideoTrackHandlers,\n  structure\n}) => {\n  const doFieldsNeedTracks = () => {\n    const keys = Object.keys(fields ?? {});\n    const selectedKeys = keys.filter((k) => fields[k]);\n    return selectedKeys.some((k) => needsTracksForField({\n      field: k,\n      structure: structure.getStructureOrNull()\n    }));\n  };\n  return {\n    doFieldsNeedTracks,\n    canSkipTracks: () => {\n      if (hasAudioTrackHandlers || hasVideoTrackHandlers) {\n        return false;\n      }\n      return !doFieldsNeedTracks();\n    }\n  };\n};\n\n// src/state/has-tracks-section.ts\nvar makeTracksSectionState = (canSkipTracksState, src) => {\n  const tracks2 = [];\n  let doneWithTracks = false;\n  return {\n    hasAllTracks: () => doneWithTracks,\n    getIsDone: () => doneWithTracks,\n    setIsDone: (logLevel) => {\n      if (doneWithTracks) {\n        throw new Error(\"Error in Media Parser: Tracks have already been parsed\");\n      }\n      Log.verbose(logLevel, \"All tracks have been parsed\");\n      doneWithTracks = true;\n    },\n    addTrack: (track) => {\n      tracks2.push(track);\n    },\n    getTracks: () => {\n      return tracks2;\n    },\n    ensureHasTracksAtEnd: (fields) => {\n      if (canSkipTracksState.canSkipTracks()) {\n        return;\n      }\n      if (!fields.tracks) {\n        return;\n      }\n      if (!doneWithTracks) {\n        throw new Error(\"Error in Media Parser: End of parsing of \" + src + \" has been reached, but no tracks have been found \");\n      }\n    }\n  };\n};\n\n// src/state/structure.ts\nvar structureState = () => {\n  let structure = null;\n  const getStructure = () => {\n    if (structure === null) {\n      throw new Error(\"Expected structure\");\n    }\n    return structure;\n  };\n  return {\n    getStructureOrNull: () => {\n      return structure;\n    },\n    getStructure,\n    setStructure: (value) => {\n      structure = value;\n    },\n    getFlacStructure: () => {\n      const struc = getStructure();\n      if (struc.type !== \"flac\") {\n        throw new Error(\"Invalid structure type\");\n      }\n      return struc;\n    },\n    getIsoStructure: () => {\n      const struc = getStructure();\n      if (struc.type !== \"iso-base-media\") {\n        throw new Error(\"Invalid structure type\");\n      }\n      return struc;\n    },\n    getMp3Structure: () => {\n      const struc = getStructure();\n      if (struc.type !== \"mp3\") {\n        throw new Error(\"Invalid structure type\");\n      }\n      return struc;\n    },\n    getM3uStructure: () => {\n      const struc = getStructure();\n      if (struc.type !== \"m3u\") {\n        throw new Error(\"Invalid structure type\");\n      }\n      return struc;\n    },\n    getRiffStructure: () => {\n      const struc = getStructure();\n      if (struc.type !== \"riff\") {\n        throw new Error(\"Invalid structure type\");\n      }\n      return struc;\n    },\n    getTsStructure: () => {\n      const struc = getStructure();\n      if (struc.type !== \"transport-stream\") {\n        throw new Error(\"Invalid structure type\");\n      }\n      return struc;\n    },\n    getWavStructure: () => {\n      const struc = getStructure();\n      if (struc.type !== \"wav\") {\n        throw new Error(\"Invalid structure type\");\n      }\n      return struc;\n    },\n    getMatroskaStructure: () => {\n      const struc = getStructure();\n      if (struc.type !== \"matroska\") {\n        throw new Error(\"Invalid structure type\");\n      }\n      return struc;\n    }\n  };\n};\n\n// src/containers/iso-base-media/elst.ts\nvar parseElst = ({\n  iterator,\n  size,\n  offset\n}) => {\n  const { expectNoMoreBytes } = iterator.startBox(size - 8);\n  const version = iterator.getUint8();\n  const flags = iterator.getUint24();\n  const entryCount = iterator.getUint32();\n  const entries = [];\n  for (let i = 0;i < entryCount; i++) {\n    const editDuration = iterator.getUint32();\n    const mediaTime = iterator.getInt32();\n    const mediaRateInteger = iterator.getUint16();\n    const mediaRateFraction = iterator.getUint16();\n    entries.push({\n      editDuration,\n      mediaTime,\n      mediaRateInteger,\n      mediaRateFraction\n    });\n  }\n  expectNoMoreBytes();\n  const result = {\n    type: \"elst-box\",\n    version,\n    flags,\n    entries,\n    boxSize: size,\n    offset\n  };\n  return result;\n};\n\n// src/containers/iso-base-media/esds/decoder-specific-config.ts\nvar parseDecoderSpecificConfig = (iterator) => {\n  const layerTag = iterator.getUint8();\n  const layerSize = iterator.getPaddedFourByteNumber();\n  const start = iterator.counter.getOffset();\n  if (layerTag !== 5) {\n    iterator.discard(layerSize);\n    return {\n      type: \"unknown-decoder-specific-config\"\n    };\n  }\n  const bytes = iterator.getSlice(layerSize);\n  iterator.counter.decrement(layerSize);\n  iterator.startReadingBits();\n  const audioObjectType = iterator.getBits(5);\n  const samplingFrequencyIndex = iterator.getBits(4);\n  if (samplingFrequencyIndex === 15) {\n    iterator.getBits(24);\n  }\n  const channelConfiguration = iterator.getBits(4);\n  iterator.stopReadingBits();\n  const read = iterator.counter.getOffset() - start;\n  if (read < layerSize) {\n    iterator.discard(layerSize - read);\n  }\n  return {\n    type: \"mp4a-specific-config\",\n    audioObjectType,\n    samplingFrequencyIndex,\n    channelConfiguration,\n    asBytes: bytes\n  };\n};\n\n// src/containers/iso-base-media/esds/esds-descriptors.ts\nvar mapToObjectAudioIndicator = (num) => {\n  if (num === 64) {\n    return \"aac\";\n  }\n  if (num === 107) {\n    return \"mp3\";\n  }\n  return \"unknown\";\n};\nvar processDescriptor = ({\n  iterator\n}) => {\n  const tag = iterator.getUint8();\n  if (tag === 4) {\n    const size = iterator.getPaddedFourByteNumber();\n    const initialOffset = iterator.counter.getOffset();\n    const objectTypeIndication = iterator.getUint8();\n    iterator.startReadingBits();\n    const streamType = iterator.getBits(6);\n    const upStream = iterator.getBits(1);\n    iterator.getBits(1);\n    const bufferSizeDB = iterator.getBits(24);\n    iterator.stopReadingBits();\n    const maxBitrate = iterator.getUint32();\n    const avgBitrate = iterator.getUint32();\n    const decoderSpecificConfigs = [];\n    while (size - (iterator.counter.getOffset() - initialOffset) > 0) {\n      const decoderSpecificConfig = parseDecoderSpecificConfig(iterator);\n      decoderSpecificConfigs.push(decoderSpecificConfig);\n    }\n    return {\n      descriptor: {\n        type: \"decoder-config-descriptor\",\n        objectTypeIndication: mapToObjectAudioIndicator(objectTypeIndication),\n        asNumber: objectTypeIndication,\n        bufferSizeDB,\n        streamType,\n        upStream,\n        avgBitrate,\n        maxBitrate,\n        decoderSpecificConfigs\n      }\n    };\n  }\n  if (tag === 6) {\n    const size = iterator.getPaddedFourByteNumber();\n    iterator.discard(size);\n    return {\n      descriptor: {\n        type: \"sl-config-descriptor\"\n      }\n    };\n  }\n  return {\n    descriptor: null\n  };\n};\nvar parseDescriptors = (iterator, maxBytes) => {\n  const descriptors = [];\n  const initialOffset = iterator.counter.getOffset();\n  while (iterator.bytesRemaining() > 0 && iterator.counter.getOffset() - initialOffset < maxBytes) {\n    const { descriptor } = processDescriptor({\n      iterator\n    });\n    if (descriptor) {\n      descriptors.push(descriptor);\n    } else {\n      break;\n    }\n  }\n  return descriptors;\n};\n\n// src/containers/iso-base-media/esds/esds.ts\nvar parseEsds = ({\n  data,\n  size,\n  fileOffset\n}) => {\n  const version = data.getUint8();\n  data.discard(3);\n  const tag = data.getUint8();\n  const sizeOfInstance = data.getPaddedFourByteNumber();\n  const esId = data.getUint16();\n  data.discard(1);\n  const remaining = size - (data.counter.getOffset() - fileOffset);\n  const descriptors = parseDescriptors(data, remaining);\n  const remainingNow = size - (data.counter.getOffset() - fileOffset);\n  data.discard(remainingNow);\n  return {\n    type: \"esds-box\",\n    version,\n    tag,\n    sizeOfInstance,\n    esId,\n    descriptors\n  };\n};\n\n// src/containers/iso-base-media/ftyp.ts\nvar parseFtyp = ({\n  iterator,\n  size,\n  offset\n}) => {\n  const majorBrand = iterator.getByteString(4, false);\n  const minorVersion = iterator.getFourByteNumber();\n  const types = (size - iterator.counter.getOffset()) / 4;\n  const compatibleBrands = [];\n  for (let i = 0;i < types; i++) {\n    compatibleBrands.push(iterator.getByteString(4, false).trim());\n  }\n  const offsetAtEnd = iterator.counter.getOffset();\n  return {\n    type: \"ftyp-box\",\n    majorBrand,\n    minorVersion,\n    compatibleBrands,\n    offset,\n    boxSize: offsetAtEnd - offset\n  };\n};\n\n// src/containers/iso-base-media/get-children.ts\nvar getIsoBaseMediaChildren = async ({\n  size,\n  iterator,\n  logLevel,\n  onlyIfMoovAtomExpected,\n  contentLength\n}) => {\n  const boxes = [];\n  const initial = iterator.counter.getOffset();\n  while (iterator.counter.getOffset() < size + initial) {\n    const parsed = await processBox({\n      iterator,\n      logLevel,\n      onlyIfMoovAtomExpected,\n      onlyIfMdatAtomExpected: null,\n      contentLength\n    });\n    if (parsed.type !== \"box\") {\n      throw new Error(\"Expected box\");\n    }\n    boxes.push(parsed.box);\n  }\n  if (iterator.counter.getOffset() > size + initial) {\n    throw new Error(`read too many bytes - size: ${size}, read: ${iterator.counter.getOffset() - initial}. initial offset: ${initial}`);\n  }\n  return boxes;\n};\n\n// src/containers/iso-base-media/mdhd.ts\nvar parseMdhd = ({\n  data,\n  size,\n  fileOffset\n}) => {\n  const version = data.getUint8();\n  data.discard(3);\n  const creationTime = version === 1 ? Number(data.getUint64()) : data.getUint32();\n  const modificationTime = version === 1 ? Number(data.getUint64()) : data.getUint32();\n  const timescale = data.getUint32();\n  const duration2 = version === 1 ? data.getUint64() : data.getUint32();\n  const language2 = data.getUint16();\n  const quality = data.getUint16();\n  const remaining = size - (data.counter.getOffset() - fileOffset);\n  if (remaining !== 0) {\n    throw new Error(`Expected remaining bytes to be 0, got ${remaining}`);\n  }\n  return {\n    type: \"mdhd-box\",\n    duration: Number(duration2),\n    timescale,\n    version,\n    language: language2,\n    quality,\n    creationTime,\n    modificationTime\n  };\n};\n\n// src/containers/iso-base-media/meta/hdlr.ts\nvar parseHdlr = ({\n  iterator,\n  size,\n  offset\n}) => {\n  const box = iterator.startBox(size - 8);\n  const version = iterator.getUint8();\n  if (version !== 0) {\n    throw new Error(`Unsupported hdlr version: ${version}`);\n  }\n  iterator.discard(3);\n  iterator.discard(4);\n  const hdlrType = iterator.getByteString(4, false);\n  iterator.discard(4);\n  iterator.discard(4);\n  iterator.discard(4);\n  const componentName = iterator.readUntilNullTerminator();\n  box.discardRest();\n  return Promise.resolve({\n    type: \"hdlr-box\",\n    boxSize: size,\n    offset,\n    hdlrType,\n    componentName\n  });\n};\n\n// src/containers/iso-base-media/meta/ilst.ts\nvar parseFromWellKnownType = (wellKnownType, iterator, size) => {\n  if (wellKnownType === 1) {\n    const value = iterator.getByteString(size, false);\n    return { type: \"text\", value };\n  }\n  if (wellKnownType === 21) {\n    if (size === 1) {\n      return { type: \"number\", value: iterator.getInt8() };\n    }\n    if (size === 2) {\n      return { type: \"number\", value: iterator.getInt16() };\n    }\n    if (size === 3) {\n      return { type: \"number\", value: iterator.getInt24() };\n    }\n    if (size === 4) {\n      return { type: \"number\", value: iterator.getInt32() };\n    }\n    if (size === 8) {\n      return { type: \"number\", value: Number(iterator.getInt64()) };\n    }\n    throw new Error(`Weird size for number ${size}`);\n  }\n  if (wellKnownType === 22) {\n    if (size === 1) {\n      return { type: \"number\", value: iterator.getUint8() };\n    }\n    if (size === 2) {\n      return { type: \"number\", value: iterator.getUint16() };\n    }\n    if (size === 3) {\n      return { type: \"number\", value: iterator.getUint24() };\n    }\n    if (size === 4) {\n      return { type: \"number\", value: iterator.getUint32() };\n    }\n    throw new Error(`Weird size for number ${size}`);\n  }\n  if (wellKnownType === 23) {\n    if (size === 4) {\n      return { type: \"number\", value: iterator.getFloat32() };\n    }\n    if (size === 8) {\n      return { type: \"number\", value: iterator.getFloat64() };\n    }\n    throw new Error(`Weird size for number ${size}`);\n  }\n  iterator.discard(size);\n  return { type: \"unknown\", value: null };\n};\nvar parseIlstBox = ({\n  iterator,\n  size,\n  offset\n}) => {\n  const box = iterator.startBox(size - 8);\n  const entries = [];\n  while (iterator.counter.getOffset() < size + offset) {\n    const metadataSize = iterator.getUint32();\n    const index = iterator.getAtom();\n    if (!index.startsWith(\"\") && !index.startsWith(\"\\x00\")) {\n      if (index === \"skip\") {\n        iterator.discard(metadataSize - 8);\n        continue;\n      }\n      if (index === \"----\") {\n        iterator.discard(metadataSize - 8);\n        continue;\n      }\n      iterator.discard(metadataSize - 8);\n      continue;\n    }\n    const innerSize = iterator.getUint32();\n    const type = iterator.getAtom();\n    const typeIndicator = iterator.getUint8();\n    if (typeIndicator !== 0) {\n      throw new Error(\"Expected type indicator to be 0\");\n    }\n    const wellKnownType = iterator.getUint24();\n    iterator.discard(4);\n    const value = parseFromWellKnownType(wellKnownType, iterator, innerSize - 16);\n    entries.push({ index, type, wellKnownType, value });\n  }\n  box.discardRest();\n  return {\n    type: \"ilst-box\",\n    boxSize: size,\n    offset,\n    entries\n  };\n};\n\n// src/containers/iso-base-media/mfra/tfra.ts\nvar readTrafNumber = (iterator, lengthSizeOfTrafNum) => {\n  const uintTypeTrafNum = (lengthSizeOfTrafNum + 1) * 8;\n  if (uintTypeTrafNum === 8) {\n    return iterator.getUint8();\n  }\n  if (uintTypeTrafNum === 16) {\n    return iterator.getUint16();\n  }\n  if (uintTypeTrafNum === 32) {\n    return iterator.getUint32();\n  }\n  if (uintTypeTrafNum === 64) {\n    return Number(iterator.getUint64());\n  }\n  throw new Error(\"Invalid traf number size\");\n};\nvar readTrunNumber = (iterator, lengthSizeOfTrunNum) => {\n  const uintTypeTrunNum = (lengthSizeOfTrunNum + 1) * 8;\n  if (uintTypeTrunNum === 8) {\n    return iterator.getUint8();\n  }\n  if (uintTypeTrunNum === 16) {\n    return iterator.getUint16();\n  }\n  if (uintTypeTrunNum === 32) {\n    return iterator.getUint32();\n  }\n  if (uintTypeTrunNum === 64) {\n    return Number(iterator.getUint64());\n  }\n  throw new Error(\"Invalid trun number size\");\n};\nvar readSampleNumber = (iterator, lengthSizeOfSampleNum) => {\n  const uintTypeSampleNum = (lengthSizeOfSampleNum + 1) * 8;\n  if (uintTypeSampleNum === 8) {\n    return iterator.getUint8();\n  }\n  if (uintTypeSampleNum === 16) {\n    return iterator.getUint16();\n  }\n  if (uintTypeSampleNum === 32) {\n    return iterator.getUint32();\n  }\n  if (uintTypeSampleNum === 64) {\n    return Number(iterator.getUint64());\n  }\n  throw new Error(\"Invalid sample number size\");\n};\nvar readTime = (iterator, version) => {\n  if (version === 1) {\n    return Number(iterator.getUint64());\n  }\n  return iterator.getUint32();\n};\nvar readMoofOffset = (iterator, version) => {\n  if (version === 1) {\n    return Number(iterator.getUint64());\n  }\n  return iterator.getUint32();\n};\nvar parseTfraBox = ({\n  iterator,\n  size,\n  offset\n}) => {\n  const box = iterator.startBox(size - 8);\n  const version = iterator.getUint8();\n  iterator.discard(3);\n  const trackId = iterator.getUint32();\n  iterator.getUint24();\n  const tmpByte = iterator.getUint8();\n  const lengthSizeOfTrafNum = tmpByte >> 4 & 3;\n  const lengthSizeOfTrunNum = tmpByte >> 2 & 3;\n  const lengthSizeOfSampleNum = tmpByte & 3;\n  const numberOfEntries = iterator.getUint32();\n  const entries = [];\n  for (let i = 0;i < numberOfEntries; i++) {\n    const time = readTime(iterator, version);\n    const moofOffset = readMoofOffset(iterator, version);\n    const trafNumber = readTrafNumber(iterator, lengthSizeOfTrafNum);\n    const trunNumber = readTrunNumber(iterator, lengthSizeOfTrunNum);\n    const sampleNumber = readSampleNumber(iterator, lengthSizeOfSampleNum);\n    entries.push({\n      time,\n      moofOffset,\n      trafNumber,\n      trunNumber,\n      sampleNumber\n    });\n  }\n  box.expectNoMoreBytes();\n  return {\n    offset,\n    boxSize: size,\n    type: \"tfra-box\",\n    entries,\n    trackId\n  };\n};\n\n// src/containers/iso-base-media/moov/moov.ts\nvar parseMoov = async ({\n  offset,\n  size,\n  onlyIfMoovAtomExpected,\n  iterator,\n  logLevel,\n  contentLength\n}) => {\n  const children = await getIsoBaseMediaChildren({\n    onlyIfMoovAtomExpected,\n    size: size - 8,\n    iterator,\n    logLevel,\n    contentLength\n  });\n  return {\n    offset,\n    boxSize: size,\n    type: \"moov-box\",\n    children\n  };\n};\n\n// src/containers/iso-base-media/to-date.ts\nvar toUnixTimestamp = (value) => {\n  if (value === 0) {\n    return null;\n  }\n  const baseDate = new Date(\"1904-01-01T00:00:00Z\");\n  return Math.floor(value + baseDate.getTime() / 1000) * 1000;\n};\n\n// src/containers/iso-base-media/moov/mvhd.ts\nvar parseMvhd = ({\n  iterator,\n  offset,\n  size\n}) => {\n  const version = iterator.getUint8();\n  iterator.discard(3);\n  const creationTime = version === 1 ? iterator.getUint64() : iterator.getUint32();\n  const modificationTime = version === 1 ? iterator.getUint64() : iterator.getUint32();\n  const timeScale = iterator.getUint32();\n  const durationInUnits = version === 1 ? iterator.getUint64() : iterator.getUint32();\n  const durationInSeconds = Number(durationInUnits) / timeScale;\n  const rateArray = iterator.getSlice(4);\n  const rateView = getArrayBufferIterator({\n    initialData: rateArray,\n    maxBytes: rateArray.length,\n    logLevel: \"error\"\n  });\n  const rate = rateView.getInt8() * 10 + rateView.getInt8() + rateView.getInt8() * 0.1 + rateView.getInt8() * 0.01;\n  const volumeArray = iterator.getSlice(2);\n  const volumeView = getArrayBufferIterator({\n    initialData: volumeArray,\n    maxBytes: volumeArray.length,\n    logLevel: \"error\"\n  });\n  const volume = volumeView.getInt8() + volumeView.getInt8() * 0.1;\n  iterator.discard(2);\n  iterator.discard(4);\n  iterator.discard(4);\n  const matrix = [\n    iterator.getFixedPointSigned1616Number(),\n    iterator.getFixedPointSigned1616Number(),\n    iterator.getFixedPointSigned230Number(),\n    iterator.getFixedPointSigned1616Number(),\n    iterator.getFixedPointSigned1616Number(),\n    iterator.getFixedPointSigned230Number(),\n    iterator.getFixedPointSigned1616Number(),\n    iterator.getFixedPointSigned1616Number(),\n    iterator.getFixedPointSigned230Number()\n  ];\n  iterator.discard(4 * 6);\n  const nextTrackId = iterator.getUint32();\n  volumeView.destroy();\n  const bytesRemaining = size - (iterator.counter.getOffset() - offset);\n  if (bytesRemaining !== 0) {\n    throw new Error(\"expected 0 bytes \" + bytesRemaining);\n  }\n  return {\n    creationTime: toUnixTimestamp(Number(creationTime)),\n    modificationTime: toUnixTimestamp(Number(modificationTime)),\n    timeScale,\n    durationInUnits: Number(durationInUnits),\n    durationInSeconds,\n    rate,\n    volume,\n    matrix,\n    nextTrackId,\n    type: \"mvhd-box\",\n    boxSize: size,\n    offset\n  };\n};\n\n// src/containers/iso-base-media/moov/trex.ts\nvar parseTrex = ({\n  iterator,\n  offset,\n  size\n}) => {\n  const box = iterator.startBox(size - 8);\n  const version = iterator.getUint8();\n  iterator.discard(3);\n  const trackId = iterator.getUint32();\n  const defaultSampleDescriptionIndex = iterator.getUint32();\n  const defaultSampleDuration = iterator.getUint32();\n  const defaultSampleSize = iterator.getUint32();\n  const defaultSampleFlags = iterator.getUint32();\n  box.expectNoMoreBytes();\n  return {\n    type: \"trex-box\",\n    boxSize: size,\n    offset,\n    trackId,\n    version,\n    defaultSampleDescriptionIndex,\n    defaultSampleDuration,\n    defaultSampleSize,\n    defaultSampleFlags\n  };\n};\n\n// src/containers/iso-base-media/stsd/av1c.ts\nvar parseAv1C = ({\n  data,\n  size\n}) => {\n  return {\n    type: \"av1C-box\",\n    privateData: data.getSlice(size - 8)\n  };\n};\n\n// src/containers/iso-base-media/stsd/avcc.ts\nvar parseAvcc = ({\n  data,\n  size\n}) => {\n  const confVersion = data.getUint8();\n  if (confVersion !== 1) {\n    throw new Error(`Unsupported AVCC version ${confVersion}`);\n  }\n  const profile = data.getUint8();\n  const profileCompatibility = data.getUint8();\n  const level = data.getUint8();\n  const str = `${profile.toString(16).padStart(2, \"0\")}${profileCompatibility.toString(16).padStart(2, \"0\")}${level.toString(16).padStart(2, \"0\")}`;\n  data.counter.decrement(4);\n  const privateData = data.getSlice(size - 8);\n  return {\n    type: \"avcc-box\",\n    privateData,\n    configurationString: str\n  };\n};\n\n// src/containers/iso-base-media/parse-icc-profile.ts\nvar parseIccProfile = (data) => {\n  const iterator = getArrayBufferIterator({\n    initialData: data,\n    maxBytes: data.length,\n    logLevel: \"error\"\n  });\n  const size = iterator.getUint32();\n  if (size !== data.length) {\n    throw new Error(\"Invalid ICC profile size\");\n  }\n  const preferredCMMType = iterator.getByteString(4, false);\n  const profileVersion = iterator.getByteString(4, false);\n  const profileDeviceClass = iterator.getByteString(4, false);\n  const colorSpace = iterator.getByteString(4, false);\n  const pcs = iterator.getByteString(4, false);\n  const dateTime = iterator.getSlice(12);\n  const signature = iterator.getByteString(4, false);\n  if (signature !== \"acsp\") {\n    throw new Error(\"Invalid ICC profile signature\");\n  }\n  const primaryPlatform = iterator.getByteString(4, false);\n  const profileFlags = iterator.getUint32();\n  const deviceManufacturer = iterator.getByteString(4, false);\n  const deviceModel = iterator.getByteString(4, false);\n  const deviceAttributes = iterator.getUint64();\n  const renderingIntent = iterator.getUint32();\n  const pcsIlluminant1 = iterator.getUint32();\n  const pcsIlluminant2 = iterator.getUint32();\n  const pcsIlluminant3 = iterator.getUint32();\n  const profileCreator = iterator.getByteString(4, false);\n  const profileId = iterator.getByteString(16, false);\n  iterator.discard(28);\n  const tagCount = iterator.getUint32();\n  const entries = [];\n  for (let i = 0;i < tagCount; i++) {\n    const entry = {\n      tag: iterator.getByteString(4, false),\n      offset: iterator.getUint32(),\n      size: iterator.getUint32()\n    };\n    entries.push(entry);\n  }\n  let lastOffset = -1;\n  let rXYZ = null;\n  let gXYZ = null;\n  let bXYZ = null;\n  let whitePoint = null;\n  for (const entry of entries) {\n    const found = data.slice(entry.offset, entry.offset + entry.size);\n    if (entry.tag === \"rXYZ\" || entry.tag === \"gXYZ\" || entry.tag === \"bXYZ\" || entry.tag === \"wtpt\") {\n      const it = getArrayBufferIterator({\n        initialData: found,\n        maxBytes: found.length,\n        logLevel: \"error\"\n      });\n      it.discard(4);\n      const x = it.getInt32() / 65536;\n      const y = it.getInt32() / 65536;\n      const z = it.getInt32() / 65536;\n      it.destroy();\n      const point = { x, y, z };\n      if (entry.tag === \"rXYZ\") {\n        rXYZ = point;\n      } else if (entry.tag === \"gXYZ\") {\n        gXYZ = point;\n      } else if (entry.tag === \"bXYZ\") {\n        bXYZ = point;\n      } else if (entry.tag === \"wtpt\") {\n        whitePoint = point;\n      }\n    }\n    if (lastOffset !== -1) {\n      const bytesToAdvance = entry.offset - lastOffset;\n      const bytesToGoBackwards = entry.size - bytesToAdvance;\n      if (bytesToGoBackwards > 0) {\n        iterator.counter.decrement(bytesToGoBackwards);\n      }\n    }\n    lastOffset = entry.offset;\n  }\n  const profile = {\n    size,\n    preferredCMMType,\n    profileVersion,\n    profileDeviceClass,\n    colorSpace,\n    pcs,\n    dateTime,\n    signature,\n    primaryPlatform,\n    profileFlags,\n    deviceManufacturer,\n    deviceModel,\n    deviceAttributes,\n    renderingIntent,\n    pcsIlluminant: [\n      pcsIlluminant1 / 65536,\n      pcsIlluminant2 / 65536,\n      pcsIlluminant3 / 65536\n    ],\n    profileCreator,\n    profileId,\n    entries,\n    bXYZ,\n    gXYZ,\n    rXYZ,\n    whitePoint\n  };\n  iterator.destroy();\n  return profile;\n};\n\n// src/containers/iso-base-media/stsd/colr.ts\nvar parseColorParameterBox = ({\n  iterator,\n  size\n}) => {\n  const byteString = iterator.getByteString(4, false);\n  if (byteString === \"nclx\") {\n    const primaries2 = iterator.getUint16();\n    const transfer = iterator.getUint16();\n    const matrixIndex = iterator.getUint16();\n    iterator.startReadingBits();\n    const fullRangeFlag = Boolean(iterator.getBits(1));\n    iterator.stopReadingBits();\n    return {\n      type: \"colr-box\",\n      colorType: \"transfer-characteristics\",\n      fullRangeFlag,\n      matrixIndex,\n      primaries: primaries2,\n      transfer\n    };\n  }\n  if (byteString === \"nclc\") {\n    const primaries2 = iterator.getUint16();\n    const transfer = iterator.getUint16();\n    const matrixIndex = iterator.getUint16();\n    return {\n      type: \"colr-box\",\n      colorType: \"transfer-characteristics\",\n      fullRangeFlag: false,\n      matrixIndex,\n      primaries: primaries2,\n      transfer\n    };\n  }\n  if (byteString === \"prof\") {\n    const profile = iterator.getSlice(size - 12);\n    return {\n      type: \"colr-box\",\n      colorType: \"icc-profile\",\n      profile,\n      parsed: parseIccProfile(profile)\n    };\n  }\n  throw new Error(\"Unexpected box type \" + byteString);\n};\n\n// src/containers/iso-base-media/stsd/ctts.ts\nvar parseCtts = ({\n  iterator,\n  offset,\n  size\n}) => {\n  const version = iterator.getUint8();\n  if (version !== 0 && version !== 1) {\n    throw new Error(`Unsupported CTTS version ${version}`);\n  }\n  const flags = iterator.getSlice(3);\n  const entryCount = iterator.getUint32();\n  const entries = [];\n  for (let i = 0;i < entryCount; i++) {\n    const sampleCount = iterator.getUint32();\n    const sampleOffset = iterator.getInt32();\n    entries.push({\n      sampleCount,\n      sampleOffset\n    });\n  }\n  return {\n    type: \"ctts-box\",\n    boxSize: size,\n    offset,\n    version,\n    flags: [...flags],\n    entryCount,\n    entries\n  };\n};\n\n// src/containers/iso-base-media/stsd/hvcc.ts\nvar parseHvcc = ({\n  data,\n  size,\n  offset\n}) => {\n  const privateData = data.getSlice(size - 8);\n  data.counter.decrement(size - 8);\n  const constraintString = getHvc1CodecString(data);\n  const remaining = size - (data.counter.getOffset() - offset);\n  data.discard(remaining);\n  return {\n    type: \"hvcc-box\",\n    privateData,\n    configurationString: constraintString\n  };\n};\n\n// src/containers/iso-base-media/stsd/keys.ts\nvar parseKeys = ({\n  iterator,\n  offset,\n  size\n}) => {\n  const box = iterator.startBox(size - 8);\n  const version = iterator.getUint8();\n  iterator.discard(3);\n  const entryCount = iterator.getUint32();\n  const entries = [];\n  for (let i = 0;i < entryCount; i++) {\n    const keySize = iterator.getUint32();\n    const namespace = iterator.getAtom();\n    const value = iterator.getByteString(keySize - 8, false);\n    const entry = {\n      keySize,\n      namespace,\n      value\n    };\n    entries.push(entry);\n  }\n  box.discardRest();\n  return {\n    type: \"keys-box\",\n    boxSize: size,\n    offset,\n    version,\n    entryCount,\n    entries\n  };\n};\n\n// src/containers/iso-base-media/stsd/mebx.ts\nvar parseMebx = async ({\n  offset,\n  size,\n  iterator,\n  logLevel,\n  contentLength\n}) => {\n  iterator.discard(6);\n  const dataReferenceIndex = iterator.getUint16();\n  const children = await getIsoBaseMediaChildren({\n    iterator,\n    size: size - 8,\n    logLevel,\n    onlyIfMoovAtomExpected: null,\n    contentLength\n  });\n  return {\n    type: \"mebx-box\",\n    boxSize: size,\n    offset,\n    dataReferenceIndex,\n    format: \"mebx\",\n    children\n  };\n};\n\n// src/containers/iso-base-media/stsd/pasp.ts\nvar parsePasp = ({\n  iterator,\n  offset,\n  size\n}) => {\n  const hSpacing = iterator.getUint32();\n  const vSpacing = iterator.getUint32();\n  const bytesRemainingInBox = size - (iterator.counter.getOffset() - offset);\n  iterator.discard(bytesRemainingInBox);\n  return {\n    type: \"pasp-box\",\n    boxSize: size,\n    offset,\n    hSpacing,\n    vSpacing\n  };\n};\n\n// src/containers/iso-base-media/stsd/stco.ts\nvar parseStco = ({\n  iterator,\n  offset,\n  size,\n  mode64Bit\n}) => {\n  const version = iterator.getUint8();\n  if (version !== 0) {\n    throw new Error(`Unsupported STSD version ${version}`);\n  }\n  const flags = iterator.getSlice(3);\n  const entryCount = iterator.getUint32();\n  const entries = [];\n  for (let i = 0;i < entryCount; i++) {\n    const bytesRemaining = size - (iterator.counter.getOffset() - offset);\n    if (bytesRemaining < 4) {\n      break;\n    }\n    entries.push(mode64Bit ? iterator.getUint64() : iterator.getUint32());\n  }\n  iterator.discard(size - (iterator.counter.getOffset() - offset));\n  return {\n    type: \"stco-box\",\n    boxSize: size,\n    offset,\n    version,\n    flags: [...flags],\n    entries,\n    entryCount\n  };\n};\n\n// src/containers/iso-base-media/stsd/stsc.ts\nvar parseStsc = ({\n  iterator,\n  offset,\n  size\n}) => {\n  const version = iterator.getUint8();\n  if (version !== 0) {\n    throw new Error(`Unsupported STSD version ${version}`);\n  }\n  const flags = iterator.getSlice(3);\n  const entryCount = iterator.getUint32();\n  const entries = new Map;\n  for (let i = 0;i < entryCount; i++) {\n    const firstChunk = iterator.getUint32();\n    const samplesPerChunk = iterator.getUint32();\n    const sampleDescriptionIndex = iterator.getUint32();\n    if (sampleDescriptionIndex !== 1) {\n      throw new Error(`Expected sampleDescriptionIndex to be 1, but got ${sampleDescriptionIndex}`);\n    }\n    entries.set(firstChunk, samplesPerChunk);\n  }\n  return {\n    type: \"stsc-box\",\n    boxSize: size,\n    offset,\n    version,\n    flags: [...flags],\n    entryCount,\n    entries\n  };\n};\n\n// src/containers/iso-base-media/stsd/samples.ts\nvar videoTags = [\n  \"cvid\",\n  \"jpeg\",\n  \"smc \",\n  \"rle \",\n  \"rpza\",\n  \"kpcd\",\n  \"png \",\n  \"mjpa\",\n  \"mjpb\",\n  \"SVQ1\",\n  \"SVQ3\",\n  \"mp4v\",\n  \"avc1\",\n  \"dvc \",\n  \"dvcp\",\n  \"gif \",\n  \"h263\",\n  \"tiff\",\n  \"raw \",\n  \"2vuY\",\n  \"yuv2\",\n  \"v308\",\n  \"v408\",\n  \"v216\",\n  \"v410\",\n  \"v210\",\n  \"hvc1\",\n  \"hev1\",\n  \"ap4h\",\n  \"av01\"\n];\nvar audioTags = [\n  0,\n  \"NONE\",\n  \"raw \",\n  \"twos\",\n  \"sowt\",\n  \"MAC3 \",\n  \"MAC6 \",\n  \"ima4\",\n  \"fl32\",\n  \"lpcm\",\n  \"fl64\",\n  \"in24\",\n  \"in32\",\n  \"ulaw\",\n  \"alaw\",\n  1836253186,\n  1836253201,\n  \"dvca\",\n  \"QDMC\",\n  \"QDM2\",\n  \"Qclp\",\n  1836253269,\n  \".mp3\",\n  \"mp4a\",\n  \"ac-3\",\n  \"Opus\"\n];\nvar processIsoFormatBox = async ({\n  iterator,\n  logLevel,\n  contentLength\n}) => {\n  const fileOffset = iterator.counter.getOffset();\n  const bytesRemaining = iterator.bytesRemaining();\n  const boxSize = iterator.getUint32();\n  if (bytesRemaining < boxSize) {\n    throw new Error(`Expected box size of ${bytesRemaining}, got ${boxSize}`);\n  }\n  const boxFormat = iterator.getAtom();\n  const isVideo = videoTags.includes(boxFormat);\n  const isAudio = audioTags.includes(boxFormat) || audioTags.includes(Number(boxFormat));\n  iterator.discard(6);\n  const dataReferenceIndex = iterator.getUint16();\n  if (!isVideo && !isAudio) {\n    const bytesRemainingInBox = boxSize - (iterator.counter.getOffset() - fileOffset);\n    iterator.discard(bytesRemainingInBox);\n    return {\n      sample: {\n        type: \"unknown\",\n        offset: fileOffset,\n        dataReferenceIndex,\n        size: boxSize,\n        format: boxFormat\n      }\n    };\n  }\n  if (isAudio) {\n    const version = iterator.getUint16();\n    const revisionLevel = iterator.getUint16();\n    const vendor = iterator.getSlice(4);\n    if (version === 0) {\n      const numberOfChannels = iterator.getUint16();\n      const sampleSize = iterator.getUint16();\n      const compressionId = iterator.getUint16();\n      const packetSize = iterator.getUint16();\n      const sampleRate = iterator.getFixedPointUnsigned1616Number();\n      const children = await getIsoBaseMediaChildren({\n        iterator,\n        logLevel,\n        size: boxSize - (iterator.counter.getOffset() - fileOffset),\n        onlyIfMoovAtomExpected: null,\n        contentLength\n      });\n      return {\n        sample: {\n          format: boxFormat,\n          offset: fileOffset,\n          dataReferenceIndex,\n          version,\n          revisionLevel,\n          vendor: [...Array.from(new Uint8Array(vendor))],\n          size: boxSize,\n          type: \"audio\",\n          numberOfChannels,\n          sampleSize,\n          compressionId,\n          packetSize,\n          sampleRate,\n          samplesPerPacket: null,\n          bytesPerPacket: null,\n          bytesPerFrame: null,\n          bitsPerSample: null,\n          children\n        }\n      };\n    }\n    if (version === 1) {\n      const numberOfChannels = iterator.getUint16();\n      const sampleSize = iterator.getUint16();\n      const compressionId = iterator.getInt16();\n      const packetSize = iterator.getUint16();\n      const sampleRate = iterator.getFixedPointUnsigned1616Number();\n      const samplesPerPacket = iterator.getUint32();\n      const bytesPerPacket = iterator.getUint32();\n      const bytesPerFrame = iterator.getUint32();\n      const bytesPerSample = iterator.getUint32();\n      const children = await getIsoBaseMediaChildren({\n        iterator,\n        logLevel,\n        size: boxSize - (iterator.counter.getOffset() - fileOffset),\n        onlyIfMoovAtomExpected: null,\n        contentLength\n      });\n      return {\n        sample: {\n          format: boxFormat,\n          offset: fileOffset,\n          dataReferenceIndex,\n          version,\n          revisionLevel,\n          vendor: [...Array.from(new Uint8Array(vendor))],\n          size: boxSize,\n          type: \"audio\",\n          numberOfChannels,\n          sampleSize,\n          compressionId,\n          packetSize,\n          sampleRate,\n          samplesPerPacket,\n          bytesPerPacket,\n          bytesPerFrame,\n          bitsPerSample: bytesPerSample,\n          children\n        }\n      };\n    }\n    if (version === 2) {\n      iterator.getUint16();\n      const sampleSize = iterator.getUint16();\n      const compressionId = iterator.getUint16();\n      const packetSize = iterator.getUint16();\n      iterator.getFixedPointUnsigned1616Number();\n      iterator.getUint32();\n      const higherSampleRate = iterator.getFloat64();\n      const numAudioChannel = iterator.getUint32();\n      iterator.getUint32();\n      const bitsPerChannel = iterator.getUint32();\n      iterator.getUint32();\n      const bytesPerFrame = iterator.getUint32();\n      const samplesPerPacket = iterator.getUint32();\n      const children = await getIsoBaseMediaChildren({\n        iterator,\n        logLevel,\n        size: boxSize - (iterator.counter.getOffset() - fileOffset),\n        onlyIfMoovAtomExpected: null,\n        contentLength\n      });\n      return {\n        sample: {\n          format: boxFormat,\n          offset: fileOffset,\n          dataReferenceIndex,\n          version,\n          revisionLevel,\n          vendor: [...Array.from(new Uint8Array(vendor))],\n          size: boxSize,\n          type: \"audio\",\n          numberOfChannels: numAudioChannel,\n          sampleSize,\n          compressionId,\n          packetSize,\n          sampleRate: higherSampleRate,\n          samplesPerPacket,\n          bytesPerPacket: null,\n          bytesPerFrame,\n          bitsPerSample: bitsPerChannel,\n          children\n        }\n      };\n    }\n    throw new Error(`Unsupported version ${version}`);\n  }\n  if (isVideo) {\n    const version = iterator.getUint16();\n    const revisionLevel = iterator.getUint16();\n    const vendor = iterator.getSlice(4);\n    const temporalQuality = iterator.getUint32();\n    const spacialQuality = iterator.getUint32();\n    const width = iterator.getUint16();\n    const height = iterator.getUint16();\n    const horizontalResolution = iterator.getFixedPointUnsigned1616Number();\n    const verticalResolution = iterator.getFixedPointUnsigned1616Number();\n    const dataSize = iterator.getUint32();\n    const frameCountPerSample = iterator.getUint16();\n    const compressorName = iterator.getPascalString();\n    const depth = iterator.getUint16();\n    const colorTableId = iterator.getInt16();\n    const bytesRemainingInBox = boxSize - (iterator.counter.getOffset() - fileOffset);\n    const children = bytesRemainingInBox > 8 ? await getIsoBaseMediaChildren({\n      onlyIfMoovAtomExpected: null,\n      iterator,\n      logLevel,\n      size: bytesRemainingInBox,\n      contentLength\n    }) : (iterator.discard(bytesRemainingInBox), []);\n    return {\n      sample: {\n        format: boxFormat,\n        offset: fileOffset,\n        dataReferenceIndex,\n        version,\n        revisionLevel,\n        vendor: [...Array.from(new Uint8Array(vendor))],\n        size: boxSize,\n        type: \"video\",\n        width,\n        height,\n        horizontalResolutionPpi: horizontalResolution,\n        verticalResolutionPpi: verticalResolution,\n        spacialQuality,\n        temporalQuality,\n        dataSize,\n        frameCountPerSample,\n        compressorName,\n        depth,\n        colorTableId,\n        descriptors: children\n      }\n    };\n  }\n  throw new Error(`Unknown sample format ${boxFormat}`);\n};\nvar parseIsoFormatBoxes = async ({\n  maxBytes,\n  logLevel,\n  iterator,\n  contentLength\n}) => {\n  const samples = [];\n  const initialOffset = iterator.counter.getOffset();\n  while (iterator.bytesRemaining() > 0 && iterator.counter.getOffset() - initialOffset < maxBytes) {\n    const { sample } = await processIsoFormatBox({\n      iterator,\n      logLevel,\n      contentLength\n    });\n    if (sample) {\n      samples.push(sample);\n    }\n  }\n  return samples;\n};\n\n// src/containers/iso-base-media/stsd/stsd.ts\nvar parseStsd = async ({\n  offset,\n  size,\n  iterator,\n  logLevel,\n  contentLength\n}) => {\n  const version = iterator.getUint8();\n  if (version !== 0) {\n    throw new Error(`Unsupported STSD version ${version}`);\n  }\n  iterator.discard(3);\n  const numberOfEntries = iterator.getUint32();\n  const bytesRemainingInBox = size - (iterator.counter.getOffset() - offset);\n  const boxes = await parseIsoFormatBoxes({\n    maxBytes: bytesRemainingInBox,\n    logLevel,\n    iterator,\n    contentLength\n  });\n  if (boxes.length !== numberOfEntries) {\n    throw new Error(`Expected ${numberOfEntries} sample descriptions, got ${boxes.length}`);\n  }\n  return {\n    type: \"stsd-box\",\n    boxSize: size,\n    offset,\n    numberOfEntries,\n    samples: boxes\n  };\n};\n\n// src/containers/iso-base-media/stsd/stss.ts\nvar parseStss = ({\n  iterator,\n  offset,\n  boxSize\n}) => {\n  const version = iterator.getUint8();\n  if (version !== 0) {\n    throw new Error(`Unsupported STSS version ${version}`);\n  }\n  const flags = iterator.getSlice(3);\n  const sampleCount = iterator.getUint32();\n  const sampleNumber = new Set;\n  for (let i = 0;i < sampleCount; i++) {\n    sampleNumber.add(iterator.getUint32());\n  }\n  const bytesRemainingInBox = boxSize - (iterator.counter.getOffset() - offset);\n  if (bytesRemainingInBox > 0) {\n    throw new Error(`Unexpected bytes remaining in box stss`);\n  }\n  return {\n    type: \"stss-box\",\n    version,\n    flags: [...flags],\n    sampleNumber,\n    boxSize,\n    offset\n  };\n};\n\n// src/containers/iso-base-media/stsd/stsz.ts\nvar parseStsz = ({\n  iterator,\n  offset,\n  size\n}) => {\n  const version = iterator.getUint8();\n  if (version !== 0) {\n    throw new Error(`Unsupported STSD version ${version}`);\n  }\n  const flags = iterator.getSlice(3);\n  const sampleSize = iterator.getUint32();\n  const sampleCount = iterator.getUint32();\n  if (sampleSize !== 0) {\n    return {\n      type: \"stsz-box\",\n      boxSize: size,\n      offset,\n      version,\n      flags: [...flags],\n      sampleCount,\n      countType: \"fixed\",\n      sampleSize\n    };\n  }\n  const samples = [];\n  for (let i = 0;i < sampleCount; i++) {\n    const bytesRemaining = size - (iterator.counter.getOffset() - offset);\n    if (bytesRemaining < 4) {\n      break;\n    }\n    samples.push(iterator.getUint32());\n  }\n  iterator.discard(size - (iterator.counter.getOffset() - offset));\n  return {\n    type: \"stsz-box\",\n    boxSize: size,\n    offset,\n    version,\n    flags: [...flags],\n    sampleCount,\n    countType: \"variable\",\n    entries: samples\n  };\n};\n\n// src/containers/iso-base-media/stsd/stts.ts\nvar parseStts = ({\n  data,\n  size,\n  fileOffset\n}) => {\n  const initialOffset = data.counter.getOffset();\n  const initialCounter = initialOffset - fileOffset;\n  const version = data.getUint8();\n  if (version !== 0) {\n    throw new Error(`Unsupported STTS version ${version}`);\n  }\n  data.discard(3);\n  const entryCount = data.getUint32();\n  const sampleDistributions = [];\n  for (let i = 0;i < entryCount; i++) {\n    const sampleCount = data.getUint32();\n    const sampleDelta = data.getUint32();\n    const sampleDistribution = {\n      sampleCount,\n      sampleDelta\n    };\n    sampleDistributions.push(sampleDistribution);\n  }\n  const bytesUsed = data.counter.getOffset() - initialOffset + initialCounter;\n  if (bytesUsed !== size) {\n    throw new Error(`Expected stts box to be ${size} bytes, but was ${bytesUsed} bytes`);\n  }\n  return {\n    type: \"stts-box\",\n    sampleDistribution: sampleDistributions\n  };\n};\n\n// src/containers/iso-base-media/tfdt.ts\nvar parseTfdt = ({\n  iterator,\n  size,\n  offset\n}) => {\n  const version = iterator.getUint8();\n  iterator.discard(3);\n  const num = version === 0 ? iterator.getUint32() : Number(iterator.getUint64());\n  const bytesRemaining = size - (iterator.counter.getOffset() - offset);\n  if (bytesRemaining !== 0) {\n    throw new Error(\"expected 0 bytes \" + bytesRemaining);\n  }\n  return {\n    type: \"tfdt-box\",\n    version,\n    baseMediaDecodeTime: num,\n    offset\n  };\n};\n\n// src/containers/iso-base-media/tfhd.ts\nvar getTfhd = ({\n  iterator,\n  offset,\n  size\n}) => {\n  const version = iterator.getUint8();\n  const flags = iterator.getUint24();\n  const trackId = iterator.getUint32();\n  const baseDataOffsetPresent = flags & 1;\n  const baseDataOffset = baseDataOffsetPresent ? Number(iterator.getUint64()) : 0;\n  const baseSampleDescriptionIndexPresent = flags & 2;\n  const baseSampleDescriptionIndex = baseSampleDescriptionIndexPresent ? iterator.getUint32() : 0;\n  const defaultSampleDurationPresent = flags & 8;\n  const defaultSampleDuration = defaultSampleDurationPresent ? iterator.getUint32() : 0;\n  const defaultSampleSizePresent = flags & 16;\n  const defaultSampleSize = defaultSampleSizePresent ? iterator.getUint32() : 0;\n  const defaultSampleFlagsPresent = flags & 32;\n  const defaultSampleFlags = defaultSampleFlagsPresent ? iterator.getUint32() : 0;\n  const bytesRemaining = size - (iterator.counter.getOffset() - offset);\n  if (bytesRemaining !== 0) {\n    throw new Error(\"expected 0 bytes \" + bytesRemaining);\n  }\n  return {\n    type: \"tfhd-box\",\n    version,\n    trackId,\n    baseDataOffset,\n    baseSampleDescriptionIndex,\n    defaultSampleDuration,\n    defaultSampleSize,\n    defaultSampleFlags\n  };\n};\n\n// src/containers/iso-base-media/tkhd.ts\nfunction getRotationAngleFromMatrix(matrix) {\n  const [a, b, c, d] = matrix;\n  if (a === 0 && b === 0 && c === 0 && d === 0) {\n    return 0;\n  }\n  if (Math.round(a * a + b * b) !== 1 || Math.round(c * c + d * d) !== 1) {\n    throw new Error(\"The provided matrix is not a valid rotation matrix.\");\n  }\n  const angleRadians = Math.atan2(c, a);\n  const angleDegrees = angleRadians * (180 / Math.PI);\n  return angleDegrees;\n}\nvar applyRotation = ({\n  matrix,\n  width,\n  height\n}) => {\n  const newWidth = matrix[0] * width + matrix[1] * height;\n  const newHeight = matrix[2] * width + matrix[3] * height;\n  return {\n    width: Math.abs(newWidth),\n    height: Math.abs(newHeight)\n  };\n};\nvar parseTkhd = ({\n  iterator,\n  offset,\n  size\n}) => {\n  const version = iterator.getUint8();\n  iterator.discard(3);\n  const creationTime = version === 1 ? iterator.getUint64() : iterator.getUint32();\n  const modificationTime = version === 1 ? iterator.getUint64() : iterator.getUint32();\n  const trackId = iterator.getUint32();\n  iterator.discard(4);\n  const duration2 = version === 1 ? iterator.getUint64() : iterator.getUint32();\n  iterator.discard(4);\n  iterator.discard(4);\n  const layer = iterator.getUint16();\n  const alternateGroup = iterator.getUint16();\n  const volume = iterator.getUint16();\n  iterator.discard(2);\n  const matrix = [\n    iterator.getFixedPointSigned1616Number(),\n    iterator.getFixedPointSigned1616Number(),\n    iterator.getFixedPointSigned230Number(),\n    iterator.getFixedPointSigned1616Number(),\n    iterator.getFixedPointSigned1616Number(),\n    iterator.getFixedPointSigned230Number(),\n    iterator.getFixedPointSigned1616Number(),\n    iterator.getFixedPointSigned1616Number(),\n    iterator.getFixedPointSigned230Number()\n  ];\n  const rotationMatrix = [matrix[0], matrix[1], matrix[3], matrix[4]];\n  const widthWithoutRotationApplied = iterator.getFixedPointUnsigned1616Number();\n  const heightWithoutRotationApplied = iterator.getFixedPointSigned1616Number();\n  const { width, height } = applyRotation({\n    matrix: rotationMatrix,\n    width: widthWithoutRotationApplied,\n    height: heightWithoutRotationApplied\n  });\n  const rotation = getRotationAngleFromMatrix(rotationMatrix);\n  return {\n    offset,\n    boxSize: size,\n    type: \"tkhd-box\",\n    creationTime: toUnixTimestamp(Number(creationTime)),\n    modificationTime: toUnixTimestamp(Number(modificationTime)),\n    trackId,\n    duration: Number(duration2),\n    layer,\n    alternateGroup,\n    volume,\n    matrix,\n    width,\n    height,\n    version,\n    rotation,\n    unrotatedWidth: widthWithoutRotationApplied,\n    unrotatedHeight: heightWithoutRotationApplied\n  };\n};\n\n// src/containers/iso-base-media/trak/trak.ts\nvar parseTrak = async ({\n  size,\n  offsetAtStart,\n  iterator,\n  logLevel,\n  contentLength\n}) => {\n  const children = await getIsoBaseMediaChildren({\n    onlyIfMoovAtomExpected: null,\n    size: size - 8,\n    iterator,\n    logLevel,\n    contentLength\n  });\n  return {\n    offset: offsetAtStart,\n    boxSize: size,\n    type: \"trak-box\",\n    children\n  };\n};\n\n// src/containers/iso-base-media/trun.ts\nvar parseTrun = ({\n  iterator,\n  offset,\n  size\n}) => {\n  const version = iterator.getUint8();\n  if (version !== 0 && version !== 1) {\n    throw new Error(`Unsupported TRUN version ${version}`);\n  }\n  const flags = iterator.getUint24();\n  const sampleCount = iterator.getUint32();\n  const dataOffset = flags & 1 ? iterator.getInt32() : null;\n  const firstSampleFlags = flags & 4 ? iterator.getUint32() : null;\n  const samples = [];\n  for (let i = 0;i < sampleCount; i++) {\n    const sampleDuration = flags & 256 ? iterator.getUint32() : null;\n    const sampleSize = flags & 512 ? iterator.getUint32() : null;\n    const sampleFlags = flags & 1024 ? iterator.getUint32() : null;\n    const sampleCompositionTimeOffset = flags & 2048 ? version === 0 ? iterator.getUint32() : iterator.getInt32() : null;\n    samples.push({\n      sampleDuration,\n      sampleSize,\n      sampleFlags,\n      sampleCompositionTimeOffset\n    });\n  }\n  const currentOffset = iterator.counter.getOffset();\n  const left = size - (currentOffset - offset);\n  if (left !== 0) {\n    throw new Error(`Unexpected data left in TRUN box: ${left}`);\n  }\n  return {\n    type: \"trun-box\",\n    version,\n    sampleCount,\n    dataOffset,\n    firstSampleFlags,\n    samples\n  };\n};\n\n// src/containers/iso-base-media/process-box.ts\nvar processBox = async ({\n  iterator,\n  logLevel,\n  onlyIfMoovAtomExpected,\n  onlyIfMdatAtomExpected,\n  contentLength\n}) => {\n  const fileOffset = iterator.counter.getOffset();\n  const { returnToCheckpoint } = iterator.startCheckpoint();\n  const bytesRemaining = iterator.bytesRemaining();\n  const startOff = iterator.counter.getOffset();\n  const boxSizeRaw = iterator.getFourByteNumber();\n  if (boxSizeRaw === 0) {\n    return {\n      type: \"box\",\n      box: {\n        type: \"void-box\",\n        boxSize: 0\n      }\n    };\n  }\n  if (boxSizeRaw === 1 && iterator.bytesRemaining() < 12 || iterator.bytesRemaining() < 4) {\n    iterator.counter.decrement(iterator.counter.getOffset() - fileOffset);\n    throw new Error(`Expected box size of ${bytesRemaining}, got ${boxSizeRaw}. Incomplete boxes are not allowed.`);\n  }\n  const maxSize = contentLength - startOff;\n  const boxType = iterator.getByteString(4, false);\n  const boxSizeUnlimited = boxSizeRaw === 1 ? iterator.getEightByteNumber() : boxSizeRaw;\n  const boxSize = Math.min(boxSizeUnlimited, maxSize);\n  const headerLength = iterator.counter.getOffset() - startOff;\n  if (boxType === \"mdat\") {\n    if (!onlyIfMdatAtomExpected) {\n      return { type: \"nothing\" };\n    }\n    const { mediaSectionState: mediaSectionState2 } = onlyIfMdatAtomExpected;\n    mediaSectionState2.addMediaSection({\n      size: boxSize - headerLength,\n      start: iterator.counter.getOffset()\n    });\n    return { type: \"nothing\" };\n  }\n  if (bytesRemaining < boxSize) {\n    returnToCheckpoint();\n    return {\n      type: \"fetch-more-data\",\n      bytesNeeded: makeFetchMoreData(boxSize - bytesRemaining)\n    };\n  }\n  if (boxType === \"ftyp\") {\n    return {\n      type: \"box\",\n      box: parseFtyp({ iterator, size: boxSize, offset: fileOffset })\n    };\n  }\n  if (boxType === \"elst\") {\n    return {\n      type: \"box\",\n      box: parseElst({\n        iterator,\n        size: boxSize,\n        offset: fileOffset\n      })\n    };\n  }\n  if (boxType === \"colr\") {\n    return {\n      type: \"box\",\n      box: parseColorParameterBox({\n        iterator,\n        size: boxSize\n      })\n    };\n  }\n  if (boxType === \"mvhd\") {\n    const mvhdBox = parseMvhd({\n      iterator,\n      offset: fileOffset,\n      size: boxSize\n    });\n    if (!onlyIfMoovAtomExpected) {\n      throw new Error(\"State is required\");\n    }\n    onlyIfMoovAtomExpected.movieTimeScaleState.setTrackTimescale(mvhdBox.timeScale);\n    return {\n      type: \"box\",\n      box: mvhdBox\n    };\n  }\n  if (boxType === \"tkhd\") {\n    return {\n      type: \"box\",\n      box: parseTkhd({ iterator, offset: fileOffset, size: boxSize })\n    };\n  }\n  if (boxType === \"trun\") {\n    return {\n      type: \"box\",\n      box: parseTrun({ iterator, offset: fileOffset, size: boxSize })\n    };\n  }\n  if (boxType === \"tfdt\") {\n    return {\n      type: \"box\",\n      box: parseTfdt({ iterator, size: boxSize, offset: fileOffset })\n    };\n  }\n  if (boxType === \"stsd\") {\n    return {\n      type: \"box\",\n      box: await parseStsd({\n        offset: fileOffset,\n        size: boxSize,\n        iterator,\n        logLevel,\n        contentLength\n      })\n    };\n  }\n  if (boxType === \"stsz\") {\n    return {\n      type: \"box\",\n      box: await parseStsz({\n        iterator,\n        offset: fileOffset,\n        size: boxSize\n      })\n    };\n  }\n  if (boxType === \"stco\" || boxType === \"co64\") {\n    return {\n      type: \"box\",\n      box: await parseStco({\n        iterator,\n        offset: fileOffset,\n        size: boxSize,\n        mode64Bit: boxType === \"co64\"\n      })\n    };\n  }\n  if (boxType === \"pasp\") {\n    return {\n      type: \"box\",\n      box: await parsePasp({\n        iterator,\n        offset: fileOffset,\n        size: boxSize\n      })\n    };\n  }\n  if (boxType === \"stss\") {\n    return {\n      type: \"box\",\n      box: await parseStss({\n        iterator,\n        offset: fileOffset,\n        boxSize\n      })\n    };\n  }\n  if (boxType === \"ctts\") {\n    return {\n      type: \"box\",\n      box: await parseCtts({\n        iterator,\n        offset: fileOffset,\n        size: boxSize\n      })\n    };\n  }\n  if (boxType === \"stsc\") {\n    return {\n      type: \"box\",\n      box: await parseStsc({\n        iterator,\n        offset: fileOffset,\n        size: boxSize\n      })\n    };\n  }\n  if (boxType === \"mebx\") {\n    return {\n      type: \"box\",\n      box: await parseMebx({\n        offset: fileOffset,\n        size: boxSize,\n        iterator,\n        logLevel,\n        contentLength\n      })\n    };\n  }\n  if (boxType === \"hdlr\") {\n    return {\n      type: \"box\",\n      box: await parseHdlr({ iterator, size: boxSize, offset: fileOffset })\n    };\n  }\n  if (boxType === \"keys\") {\n    return {\n      type: \"box\",\n      box: await parseKeys({ iterator, size: boxSize, offset: fileOffset })\n    };\n  }\n  if (boxType === \"ilst\") {\n    return {\n      type: \"box\",\n      box: await parseIlstBox({\n        iterator,\n        offset: fileOffset,\n        size: boxSize\n      })\n    };\n  }\n  if (boxType === \"tfra\") {\n    return {\n      type: \"box\",\n      box: await parseTfraBox({\n        iterator,\n        offset: fileOffset,\n        size: boxSize\n      })\n    };\n  }\n  if (boxType === \"moov\") {\n    if (!onlyIfMoovAtomExpected) {\n      throw new Error(\"State is required\");\n    }\n    const { tracks: tracks2, isoState } = onlyIfMoovAtomExpected;\n    if (tracks2.hasAllTracks()) {\n      iterator.discard(boxSize - 8);\n      return { type: \"nothing\" };\n    }\n    if (isoState && isoState.moov.getMoovBoxAndPrecomputed() && !isoState.moov.getMoovBoxAndPrecomputed()?.precomputed) {\n      Log.verbose(logLevel, \"Moov box already parsed, skipping\");\n      iterator.discard(boxSize - 8);\n      return { type: \"nothing\" };\n    }\n    const box = await parseMoov({\n      offset: fileOffset,\n      size: boxSize,\n      onlyIfMoovAtomExpected,\n      iterator,\n      logLevel,\n      contentLength\n    });\n    tracks2.setIsDone(logLevel);\n    return { type: \"box\", box };\n  }\n  if (boxType === \"trak\") {\n    if (!onlyIfMoovAtomExpected) {\n      throw new Error(\"State is required\");\n    }\n    const { tracks: tracks2, onAudioTrack, onVideoTrack } = onlyIfMoovAtomExpected;\n    const trakBox = await parseTrak({\n      size: boxSize,\n      offsetAtStart: fileOffset,\n      iterator,\n      logLevel,\n      contentLength\n    });\n    const movieTimeScale = onlyIfMoovAtomExpected.movieTimeScaleState.getTrackTimescale();\n    if (movieTimeScale === null) {\n      throw new Error(\"Movie timescale is not set\");\n    }\n    const editList = findTrackStartTimeInSeconds({ movieTimeScale, trakBox });\n    const transformedTrack = makeBaseMediaTrack(trakBox, editList);\n    if (transformedTrack && transformedTrack.type === \"video\") {\n      await registerVideoTrack({\n        track: transformedTrack,\n        container: \"mp4\",\n        logLevel,\n        onVideoTrack,\n        registerVideoSampleCallback: onlyIfMoovAtomExpected.registerVideoSampleCallback,\n        tracks: tracks2\n      });\n    }\n    if (transformedTrack && transformedTrack.type === \"audio\") {\n      await registerAudioTrack({\n        track: transformedTrack,\n        container: \"mp4\",\n        registerAudioSampleCallback: onlyIfMoovAtomExpected.registerAudioSampleCallback,\n        tracks: tracks2,\n        logLevel,\n        onAudioTrack\n      });\n    }\n    return { type: \"box\", box: trakBox };\n  }\n  if (boxType === \"stts\") {\n    return {\n      type: \"box\",\n      box: await parseStts({\n        data: iterator,\n        size: boxSize,\n        fileOffset\n      })\n    };\n  }\n  if (boxType === \"avcC\") {\n    return {\n      type: \"box\",\n      box: await parseAvcc({\n        data: iterator,\n        size: boxSize\n      })\n    };\n  }\n  if (boxType === \"av1C\") {\n    return {\n      type: \"box\",\n      box: await parseAv1C({\n        data: iterator,\n        size: boxSize\n      })\n    };\n  }\n  if (boxType === \"hvcC\") {\n    return {\n      type: \"box\",\n      box: await parseHvcc({\n        data: iterator,\n        size: boxSize,\n        offset: fileOffset\n      })\n    };\n  }\n  if (boxType === \"tfhd\") {\n    return {\n      type: \"box\",\n      box: await getTfhd({\n        iterator,\n        offset: fileOffset,\n        size: boxSize\n      })\n    };\n  }\n  if (boxType === \"mdhd\") {\n    return {\n      type: \"box\",\n      box: await parseMdhd({\n        data: iterator,\n        size: boxSize,\n        fileOffset\n      })\n    };\n  }\n  if (boxType === \"esds\") {\n    return {\n      type: \"box\",\n      box: await parseEsds({\n        data: iterator,\n        size: boxSize,\n        fileOffset\n      })\n    };\n  }\n  if (boxType === \"trex\") {\n    return {\n      type: \"box\",\n      box: await parseTrex({ iterator, offset: fileOffset, size: boxSize })\n    };\n  }\n  if (boxType === \"moof\") {\n    await onlyIfMoovAtomExpected?.isoState?.mfra.triggerLoad();\n  }\n  if (boxType === \"mdia\" || boxType === \"minf\" || boxType === \"stbl\" || boxType === \"udta\" || boxType === \"moof\" || boxType === \"dims\" || boxType === \"meta\" || boxType === \"wave\" || boxType === \"traf\" || boxType === \"mfra\" || boxType === \"edts\" || boxType === \"mvex\" || boxType === \"stsb\") {\n    const children = await getIsoBaseMediaChildren({\n      iterator,\n      size: boxSize - 8,\n      logLevel,\n      onlyIfMoovAtomExpected,\n      contentLength\n    });\n    return {\n      type: \"box\",\n      box: {\n        type: \"regular-box\",\n        boxType,\n        boxSize,\n        children,\n        offset: fileOffset\n      }\n    };\n  }\n  iterator.discard(boxSize - 8);\n  Log.verbose(logLevel, \"Unknown ISO Base Media Box:\", boxType);\n  return {\n    type: \"box\",\n    box: {\n      type: \"regular-box\",\n      boxType,\n      boxSize,\n      children: [],\n      offset: fileOffset\n    }\n  };\n};\n\n// src/containers/iso-base-media/get-moov-atom.ts\nvar getMoovAtom = async ({\n  endOfMdat,\n  state\n}) => {\n  const headerSegment = state.m3uPlaylistContext?.mp4HeaderSegment;\n  if (headerSegment) {\n    const segment = getMoovFromFromIsoStructure(headerSegment);\n    if (!segment) {\n      throw new Error(\"No moov box found in header segment\");\n    }\n    return segment;\n  }\n  const start = Date.now();\n  Log.verbose(state.logLevel, \"Starting second fetch to get moov atom\");\n  const { reader } = await state.readerInterface.read({\n    src: state.src,\n    range: endOfMdat,\n    controller: state.controller,\n    logLevel: state.logLevel,\n    prefetchCache: state.prefetchCache\n  });\n  const onAudioTrack = state.onAudioTrack ? async ({ track, container }) => {\n    await registerAudioTrack({\n      track,\n      container,\n      logLevel: state.logLevel,\n      onAudioTrack: state.onAudioTrack,\n      registerAudioSampleCallback: state.callbacks.registerAudioSampleCallback,\n      tracks: state.callbacks.tracks\n    });\n    return null;\n  } : null;\n  const onVideoTrack = state.onVideoTrack ? async ({ track, container }) => {\n    await registerVideoTrack({\n      track,\n      container,\n      logLevel: state.logLevel,\n      onVideoTrack: state.onVideoTrack,\n      registerVideoSampleCallback: state.callbacks.registerVideoSampleCallback,\n      tracks: state.callbacks.tracks\n    });\n    return null;\n  } : null;\n  const iterator = getArrayBufferIterator({\n    initialData: new Uint8Array([]),\n    maxBytes: state.contentLength - endOfMdat,\n    logLevel: \"error\"\n  });\n  while (true) {\n    const result = await reader.reader.read();\n    if (result.value) {\n      iterator.addData(result.value);\n    }\n    if (result.done) {\n      break;\n    }\n  }\n  const boxes = [];\n  const canSkipTracksState = makeCanSkipTracksState({\n    hasAudioTrackHandlers: false,\n    fields: { slowStructure: true },\n    hasVideoTrackHandlers: false,\n    structure: structureState()\n  });\n  const tracksState = makeTracksSectionState(canSkipTracksState, state.src);\n  while (true) {\n    const box = await processBox({\n      iterator,\n      logLevel: state.logLevel,\n      onlyIfMoovAtomExpected: {\n        tracks: tracksState,\n        isoState: null,\n        movieTimeScaleState: state.iso.movieTimeScale,\n        onAudioTrack,\n        onVideoTrack,\n        registerVideoSampleCallback: () => Promise.resolve(),\n        registerAudioSampleCallback: () => Promise.resolve()\n      },\n      onlyIfMdatAtomExpected: null,\n      contentLength: state.contentLength - endOfMdat\n    });\n    if (box.type === \"box\") {\n      boxes.push(box.box);\n    }\n    if (iterator.counter.getOffset() + endOfMdat > state.contentLength) {\n      throw new Error(\"Read past end of file\");\n    }\n    if (iterator.counter.getOffset() + endOfMdat === state.contentLength) {\n      break;\n    }\n  }\n  const moov = boxes.find((b) => b.type === \"moov-box\");\n  if (!moov) {\n    throw new Error(\"No moov box found\");\n  }\n  Log.verbose(state.logLevel, `Finished fetching moov atom in ${Date.now() - start}ms`);\n  return moov;\n};\n\n// src/containers/iso-base-media/mdat/calculate-jump-marks.ts\nvar MAX_SPREAD_IN_SECONDS = 8;\nvar getKey = (samplePositionTrack) => {\n  return `${samplePositionTrack.track.trackId}-${samplePositionTrack.samplePosition.decodingTimestamp}`;\n};\nvar findBestJump = ({\n  allSamplesSortedByOffset,\n  visited,\n  progresses\n}) => {\n  const minProgress = Math.min(...Object.values(progresses));\n  const trackNumberWithLowestProgress = Object.entries(progresses).find(([, progress]) => progress === minProgress)?.[0];\n  const firstSampleAboveMinProgress = allSamplesSortedByOffset.findIndex((sample) => sample.track.trackId === Number(trackNumberWithLowestProgress) && !visited.has(getKey(sample)));\n  return firstSampleAboveMinProgress;\n};\nvar calculateJumpMarks = (samplePositionTracks, endOfMdat) => {\n  const progresses = {};\n  for (const track of samplePositionTracks) {\n    progresses[track[0].track.trackId] = 0;\n  }\n  const jumpMarks = [];\n  const allSamplesSortedByOffset = samplePositionTracks.flat(1).filter((s) => s.track.type === \"audio\" || s.track.type === \"video\").sort((a, b) => a.samplePosition.offset - b.samplePosition.offset);\n  let indexToVisit = 0;\n  const visited = new Set;\n  let rollOverToProcess = false;\n  const increaseIndex = () => {\n    indexToVisit++;\n    if (indexToVisit >= allSamplesSortedByOffset.length) {\n      rollOverToProcess = true;\n      indexToVisit = 0;\n    }\n  };\n  let lastVisitedSample = null;\n  const addJumpMark = ({\n    firstSampleAboveMinProgress\n  }) => {\n    if (!lastVisitedSample) {\n      throw new Error(\"no last visited sample\");\n    }\n    const jumpMark = {\n      afterSampleWithOffset: lastVisitedSample.samplePosition.offset,\n      jumpToOffset: allSamplesSortedByOffset[firstSampleAboveMinProgress].samplePosition.offset\n    };\n    indexToVisit = firstSampleAboveMinProgress;\n    jumpMarks.push(jumpMark);\n  };\n  const addFinalJumpIfNecessary = () => {\n    if (indexToVisit === allSamplesSortedByOffset.length - 1) {\n      return;\n    }\n    jumpMarks.push({\n      afterSampleWithOffset: allSamplesSortedByOffset[indexToVisit].samplePosition.offset,\n      jumpToOffset: endOfMdat\n    });\n  };\n  const considerJump = () => {\n    const firstSampleAboveMinProgress = findBestJump({\n      allSamplesSortedByOffset,\n      visited,\n      progresses\n    });\n    if (firstSampleAboveMinProgress > -1 && firstSampleAboveMinProgress !== indexToVisit + 1) {\n      addJumpMark({ firstSampleAboveMinProgress });\n      indexToVisit = firstSampleAboveMinProgress;\n    } else {\n      while (true) {\n        increaseIndex();\n        if (!visited.has(getKey(allSamplesSortedByOffset[indexToVisit]))) {\n          break;\n        }\n      }\n    }\n  };\n  while (true) {\n    const currentSamplePosition = allSamplesSortedByOffset[indexToVisit];\n    const sampleKey = getKey(currentSamplePosition);\n    if (visited.has(sampleKey)) {\n      considerJump();\n      continue;\n    }\n    visited.add(sampleKey);\n    if (rollOverToProcess) {\n      if (!lastVisitedSample) {\n        throw new Error(\"no last visited sample\");\n      }\n      jumpMarks.push({\n        afterSampleWithOffset: lastVisitedSample.samplePosition.offset,\n        jumpToOffset: currentSamplePosition.samplePosition.offset\n      });\n      rollOverToProcess = false;\n    }\n    lastVisitedSample = currentSamplePosition;\n    if (visited.size === allSamplesSortedByOffset.length) {\n      addFinalJumpIfNecessary();\n      break;\n    }\n    const timestamp = currentSamplePosition.samplePosition.decodingTimestamp / currentSamplePosition.track.originalTimescale;\n    progresses[currentSamplePosition.track.trackId] = timestamp;\n    const progressValues = Object.values(progresses);\n    const maxProgress = Math.max(...progressValues);\n    const minProgress = Math.min(...progressValues);\n    const spread = maxProgress - minProgress;\n    if (visited.size === allSamplesSortedByOffset.length) {\n      addFinalJumpIfNecessary();\n      break;\n    }\n    if (spread > MAX_SPREAD_IN_SECONDS) {\n      considerJump();\n    } else {\n      increaseIndex();\n    }\n  }\n  return jumpMarks;\n};\n\n// src/containers/iso-base-media/mdat/postprocess-bytes.ts\nvar postprocessBytes = ({\n  bytes,\n  bigEndian,\n  chunkSize\n}) => {\n  if (!bigEndian) {\n    return bytes;\n  }\n  if (chunkSize === null) {\n    return bytes;\n  }\n  const newBuffer = new Uint8Array(bytes);\n  for (let i = 0;i < newBuffer.length; i += chunkSize) {\n    const slice = newBuffer.slice(i, i + chunkSize);\n    slice.reverse();\n    newBuffer.set(slice, i);\n  }\n  return newBuffer;\n};\n\n// src/containers/iso-base-media/mdat/mdat.ts\nvar parseMdatSection = async (state) => {\n  const mediaSection = getCurrentMediaSection({\n    offset: state.iterator.counter.getOffset(),\n    mediaSections: state.mediaSection.getMediaSections()\n  });\n  if (!mediaSection) {\n    throw new Error(\"No video section defined\");\n  }\n  const endOfMdat = mediaSection.size + mediaSection.start;\n  if (maySkipVideoData({ state })) {\n    const mfra = state.iso.mfra.getIfAlreadyLoaded();\n    if (mfra) {\n      const lastMoof = getLastMoofBox(mfra);\n      if (lastMoof && lastMoof > endOfMdat) {\n        Log.verbose(state.logLevel, \"Skipping to last moof\", lastMoof);\n        return makeSkip(lastMoof);\n      }\n    }\n    return makeSkip(endOfMdat);\n  }\n  if (maySkipOverSamplesInTheMiddle({ state })) {\n    const mfra = state.iso.mfra.getIfAlreadyLoaded();\n    if (mfra) {\n      const lastMoof = getLastMoofBox(mfra);\n      const firstMax = getMaxFirstMoofOffset(mfra);\n      const mediaSectionsBiggerThanMoof = state.mediaSection.getMediaSections().filter((m) => m.start > firstMax).length;\n      if (mediaSectionsBiggerThanMoof > 1 && lastMoof && lastMoof > endOfMdat) {\n        Log.verbose(state.logLevel, \"Skipping to last moof because only first and last samples are needed\");\n        return makeSkip(lastMoof);\n      }\n    }\n  }\n  const alreadyHasMoov = getHasTracks(state, true);\n  if (!alreadyHasMoov) {\n    const moov = await getMoovAtom({\n      endOfMdat,\n      state\n    });\n    state.iso.moov.setMoovBox({\n      moovBox: moov,\n      precomputed: false\n    });\n    state.callbacks.tracks.setIsDone(state.logLevel);\n    state.structure.getIsoStructure().boxes.push(moov);\n    return parseMdatSection(state);\n  }\n  if (!state.iso.flatSamples.getSamples(mediaSection.start)) {\n    const flattedSamples = calculateFlatSamples({\n      state,\n      mediaSectionStart: mediaSection.start\n    });\n    const calcedJumpMarks = calculateJumpMarks(flattedSamples, endOfMdat);\n    state.iso.flatSamples.setJumpMarks(mediaSection.start, calcedJumpMarks);\n    state.iso.flatSamples.setSamples(mediaSection.start, flattedSamples.flat(1));\n  }\n  const flatSamples = state.iso.flatSamples.getSamples(mediaSection.start);\n  const jumpMarks = state.iso.flatSamples.getJumpMarks(mediaSection.start);\n  const { iterator } = state;\n  const samplesWithIndex = flatSamples.find((sample) => {\n    return sample.samplePosition.offset === iterator.counter.getOffset();\n  });\n  if (!samplesWithIndex) {\n    const nextSample_ = flatSamples.filter((s) => s.samplePosition.offset > iterator.counter.getOffset()).sort((a, b) => a.samplePosition.offset - b.samplePosition.offset)[0];\n    if (nextSample_) {\n      iterator.discard(nextSample_.samplePosition.offset - iterator.counter.getOffset());\n      return null;\n    }\n    Log.verbose(state.logLevel, \"Could not find sample at offset\", iterator.counter.getOffset(), \"skipping to end of mdat\");\n    return makeSkip(endOfMdat);\n  }\n  if (samplesWithIndex.samplePosition.offset + samplesWithIndex.samplePosition.size > state.contentLength) {\n    Log.verbose(state.logLevel, \"Sample is beyond the end of the file. Don't process it.\", samplesWithIndex.samplePosition.offset + samplesWithIndex.samplePosition.size, endOfMdat);\n    return makeSkip(endOfMdat);\n  }\n  if (iterator.bytesRemaining() < samplesWithIndex.samplePosition.size) {\n    return makeFetchMoreData(samplesWithIndex.samplePosition.size - iterator.bytesRemaining());\n  }\n  const {\n    timestamp: rawCts,\n    decodingTimestamp: rawDts,\n    duration: duration2,\n    isKeyframe,\n    offset,\n    bigEndian,\n    chunkSize\n  } = samplesWithIndex.samplePosition;\n  const { originalTimescale, startInSeconds } = samplesWithIndex.track;\n  const cts = rawCts + startInSeconds * originalTimescale;\n  const dts = rawDts + startInSeconds * originalTimescale;\n  const bytes = postprocessBytes({\n    bytes: iterator.getSlice(samplesWithIndex.samplePosition.size),\n    bigEndian,\n    chunkSize\n  });\n  if (samplesWithIndex.track.type === \"audio\") {\n    const audioSample = convertAudioOrVideoSampleToWebCodecsTimestamps({\n      sample: {\n        data: bytes,\n        timestamp: cts,\n        duration: duration2,\n        decodingTimestamp: dts,\n        type: isKeyframe ? \"key\" : \"delta\",\n        offset\n      },\n      timescale: originalTimescale\n    });\n    await state.callbacks.onAudioSample({\n      audioSample,\n      trackId: samplesWithIndex.track.trackId\n    });\n  }\n  if (samplesWithIndex.track.type === \"video\") {\n    const nalUnitType = bytes[4] & 31;\n    let isRecoveryPoint = false;\n    if (nalUnitType === 6) {\n      const seiType = bytes[5];\n      isRecoveryPoint = seiType === 6;\n    }\n    const videoSample = convertAudioOrVideoSampleToWebCodecsTimestamps({\n      sample: {\n        data: bytes,\n        timestamp: cts,\n        duration: duration2,\n        decodingTimestamp: dts,\n        type: isKeyframe && !isRecoveryPoint ? \"key\" : \"delta\",\n        offset\n      },\n      timescale: originalTimescale\n    });\n    await state.callbacks.onVideoSample({\n      videoSample,\n      trackId: samplesWithIndex.track.trackId\n    });\n  }\n  const jump = jumpMarks.find((j) => j.afterSampleWithOffset === offset);\n  if (jump) {\n    Log.verbose(state.logLevel, \"Found jump mark\", jump.jumpToOffset, \"skipping to jump mark\");\n    return makeSkip(jump.jumpToOffset);\n  }\n  return null;\n};\n\n// src/containers/iso-base-media/parse-boxes.ts\nvar parseIsoBaseMedia = async (state) => {\n  const mediaSectionState2 = state.mediaSection.isCurrentByteInMediaSection(state.iterator);\n  if (mediaSectionState2 === \"in-section\") {\n    const skipTo = await parseMdatSection(state);\n    return skipTo;\n  }\n  const result = await processBox({\n    iterator: state.iterator,\n    logLevel: state.logLevel,\n    onlyIfMoovAtomExpected: {\n      tracks: state.callbacks.tracks,\n      isoState: state.iso,\n      movieTimeScaleState: state.iso.movieTimeScale,\n      onAudioTrack: state.onAudioTrack,\n      onVideoTrack: state.onVideoTrack,\n      registerAudioSampleCallback: state.callbacks.registerAudioSampleCallback,\n      registerVideoSampleCallback: state.callbacks.registerVideoSampleCallback\n    },\n    onlyIfMdatAtomExpected: {\n      mediaSectionState: state.mediaSection\n    },\n    contentLength: state.contentLength\n  });\n  if (result.type === \"fetch-more-data\") {\n    return result.bytesNeeded;\n  }\n  if (result.type === \"box\") {\n    state.structure.getIsoStructure().boxes.push(result.box);\n  }\n  return null;\n};\n\n// src/containers/m3u/parse-stream-inf.ts\nfunction splitRespectingQuotes(input) {\n  const result = [];\n  let currentPart = \"\";\n  let insideQuote = false;\n  for (let i = 0;i < input.length; i++) {\n    const char = input[i];\n    if (char === '\"') {\n      insideQuote = !insideQuote;\n      currentPart += char;\n    } else if (char === \",\" && !insideQuote) {\n      result.push(currentPart);\n      currentPart = \"\";\n    } else {\n      currentPart += char;\n    }\n  }\n  if (currentPart) {\n    result.push(currentPart);\n  }\n  return result;\n}\nvar parseStreamInf = (str) => {\n  const quotes = splitRespectingQuotes(str);\n  const map = {};\n  for (const quote of quotes) {\n    const firstColon = quote.indexOf(\"=\");\n    const key = firstColon === -1 ? quote : quote.slice(0, firstColon);\n    const value = firstColon === -1 ? null : quote.slice(firstColon + 1);\n    if (value === null) {\n      throw new Error(\"Value is null\");\n    }\n    const actualValue = value?.startsWith('\"') && value?.endsWith('\"') ? value.slice(1, -1) : value;\n    map[key] = actualValue;\n  }\n  return {\n    type: \"m3u-stream-info\",\n    averageBandwidthInBitsPerSec: map[\"AVERAGE-BANDWIDTH\"] ? parseInt(map[\"AVERAGE-BANDWIDTH\"], 10) : null,\n    bandwidthInBitsPerSec: map.BANDWIDTH ? parseInt(map.BANDWIDTH, 10) : null,\n    codecs: map.CODECS ? map.CODECS.split(\",\") : null,\n    dimensions: map.RESOLUTION ? {\n      width: parseInt(map.RESOLUTION.split(\"x\")[0], 10),\n      height: parseInt(map.RESOLUTION.split(\"x\")[1], 10)\n    } : null,\n    audio: map.AUDIO || null\n  };\n};\n\n// src/containers/m3u/parse-m3u-media-directive.ts\nvar parseM3uKeyValue = (str) => {\n  const quotes = splitRespectingQuotes(str);\n  const map = {};\n  for (const quote of quotes) {\n    const firstColon = quote.indexOf(\"=\");\n    const key = firstColon === -1 ? quote : quote.slice(0, firstColon);\n    const value = firstColon === -1 ? null : quote.slice(firstColon + 1);\n    if (value === null) {\n      throw new Error(\"Value is null\");\n    }\n    const actualValue = value?.startsWith('\"') && value?.endsWith('\"') ? value.slice(1, -1) : value;\n    map[key] = actualValue;\n  }\n  return map;\n};\nvar parseM3uMediaDirective = (str) => {\n  const map = parseM3uKeyValue(str);\n  return {\n    type: \"m3u-media-info\",\n    autoselect: map.AUTOSELECT === \"YES\",\n    channels: map.CHANNELS ? parseInt(map.CHANNELS, 10) : null,\n    default: map.DEFAULT === \"YES\",\n    groupId: map[\"GROUP-ID\"],\n    language: map.LANGUAGE || null,\n    name: map.NAME || null,\n    uri: map.URI,\n    mediaType: map.TYPE || null\n  };\n};\n\n// src/containers/m3u/parse-directive.ts\nvar parseM3uDirective = (str) => {\n  const firstColon = str.indexOf(\":\");\n  const directive = (firstColon === -1 ? str : str.slice(0, firstColon)).trim();\n  const value = firstColon === -1 ? null : str.slice(firstColon + 1);\n  if (directive === \"#EXT-X-VERSION\") {\n    if (!value) {\n      throw new Error(\"EXT-X-VERSION directive must have a value\");\n    }\n    return {\n      type: \"m3u-version\",\n      version: value\n    };\n  }\n  if (directive === \"#EXT-X-INDEPENDENT-SEGMENTS\") {\n    return {\n      type: \"m3u-independent-segments\"\n    };\n  }\n  if (directive === \"#EXT-X-MEDIA\") {\n    if (!value) {\n      throw new Error(\"EXT-X-MEDIA directive must have a value\");\n    }\n    const parsed = parseM3uMediaDirective(value);\n    return parsed;\n  }\n  if (directive === \"#EXT-X-TARGETDURATION\") {\n    if (!value) {\n      throw new Error(\"EXT-X-TARGETDURATION directive must have a value\");\n    }\n    return {\n      type: \"m3u-target-duration\",\n      duration: parseFloat(value)\n    };\n  }\n  if (directive === \"#EXTINF\") {\n    if (!value) {\n      throw new Error(\"EXTINF has no value\");\n    }\n    return {\n      type: \"m3u-extinf\",\n      value: parseFloat(value)\n    };\n  }\n  if (directive === \"#EXT-X-ENDLIST\") {\n    return {\n      type: \"m3u-endlist\"\n    };\n  }\n  if (directive === \"#EXT-X-PLAYLIST-TYPE\") {\n    if (!value) {\n      throw new Error(\"#EXT-X-PLAYLIST-TYPE. directive must have a value\");\n    }\n    return {\n      type: \"m3u-playlist-type\",\n      playlistType: value\n    };\n  }\n  if (directive === \"#EXT-X-MEDIA-SEQUENCE\") {\n    if (!value) {\n      throw new Error(\"#EXT-X-MEDIA-SEQUENCE directive must have a value\");\n    }\n    return {\n      type: \"m3u-media-sequence\",\n      value: Number(value)\n    };\n  }\n  if (directive === \"#EXT-X-DISCONTINUITY-SEQUENCE\") {\n    if (!value) {\n      throw new Error(\"#EXT-X-DISCONTINUITY-SEQUENCE directive must have a value\");\n    }\n    return {\n      type: \"m3u-discontinuity-sequence\",\n      value: Number(value)\n    };\n  }\n  if (directive === \"#EXT-X-STREAM-INF\") {\n    if (!value) {\n      throw new Error(\"EXT-X-STREAM-INF directive must have a value\");\n    }\n    const res = parseStreamInf(value);\n    return res;\n  }\n  if (directive === \"#EXT-X-I-FRAME-STREAM-INF\") {\n    return {\n      type: \"m3u-i-frame-stream-info\"\n    };\n  }\n  if (directive === \"#EXT-X-ALLOW-CACHE\") {\n    if (!value) {\n      throw new Error(\"#EXT-X-ALLOW-CACHE directive must have a value\");\n    }\n    return {\n      type: \"m3u-allow-cache\",\n      allowsCache: value === \"YES\"\n    };\n  }\n  if (directive === \"#EXT-X-MAP\") {\n    if (!value) {\n      throw new Error(\"#EXT-X-MAP directive must have a value\");\n    }\n    const p = parseM3uKeyValue(value);\n    if (!p.URI) {\n      throw new Error(\"EXT-X-MAP directive must have a URI\");\n    }\n    return {\n      type: \"m3u-map\",\n      value: p.URI\n    };\n  }\n  throw new Error(`Unknown directive ${directive}. Value: ${value}`);\n};\n\n// src/containers/m3u/parse-m3u8-text.ts\nvar parseM3u8Text = (line, boxes) => {\n  if (line === \"#EXTM3U\") {\n    boxes.push({\n      type: \"m3u-header\"\n    });\n    return;\n  }\n  if (line.startsWith(\"#\")) {\n    boxes.push(parseM3uDirective(line));\n    return;\n  }\n  if (line.trim()) {\n    boxes.push({\n      type: \"m3u-text-value\",\n      value: line\n    });\n  }\n};\n\n// src/containers/m3u/fetch-m3u8-stream.ts\nvar fetchM3u8Stream = async ({\n  url,\n  readerInterface\n}) => {\n  const text = await readerInterface.readWholeAsText(url);\n  const lines = text.split(`\n`);\n  const boxes = [];\n  for (const line of lines) {\n    parseM3u8Text(line.trim(), boxes);\n  }\n  return boxes;\n};\n\n// src/containers/m3u/after-manifest-fetch.ts\nvar afterManifestFetch = async ({\n  structure,\n  m3uState,\n  src,\n  selectM3uStreamFn,\n  logLevel,\n  selectAssociatedPlaylistsFn,\n  readerInterface,\n  onAudioTrack,\n  canSkipTracks\n}) => {\n  const independentSegments = isIndependentSegments(structure);\n  if (!independentSegments) {\n    if (!src) {\n      throw new Error(\"No src\");\n    }\n    m3uState.setSelectedMainPlaylist({\n      type: \"initial-url\",\n      url: src\n    });\n    return m3uState.setReadyToIterateOverM3u();\n  }\n  const streams = getM3uStreams({ structure, originalSrc: src, readerInterface });\n  if (streams === null) {\n    throw new Error(\"No streams found\");\n  }\n  const selectedPlaylist = await selectStream({ streams, fn: selectM3uStreamFn });\n  if (!selectedPlaylist.dimensions) {\n    throw new Error(\"Stream does not have a resolution\");\n  }\n  m3uState.setSelectedMainPlaylist({\n    type: \"selected-stream\",\n    stream: selectedPlaylist\n  });\n  const skipAudioTracks = onAudioTrack === null && canSkipTracks.doFieldsNeedTracks() === false;\n  const associatedPlaylists = await selectAssociatedPlaylists({\n    playlists: selectedPlaylist.associatedPlaylists,\n    fn: selectAssociatedPlaylistsFn,\n    skipAudioTracks\n  });\n  m3uState.setAssociatedPlaylists(associatedPlaylists);\n  const playlistUrls = [\n    selectedPlaylist.src,\n    ...associatedPlaylists.map((p) => p.src)\n  ];\n  const struc = await Promise.all(playlistUrls.map(async (url) => {\n    Log.verbose(logLevel, `Fetching playlist ${url}`);\n    const boxes = await fetchM3u8Stream({ url, readerInterface });\n    return {\n      type: \"m3u-playlist\",\n      boxes,\n      src: url\n    };\n  }));\n  structure.boxes.push(...struc);\n  m3uState.setReadyToIterateOverM3u();\n};\n\n// src/containers/m3u/parse-m3u-manifest.ts\nvar parseM3uManifest = ({\n  iterator,\n  structure,\n  contentLength\n}) => {\n  const start = iterator.startCheckpoint();\n  const line = iterator.readUntilLineEnd();\n  if (iterator.counter.getOffset() > contentLength) {\n    throw new Error(\"Unexpected end of file\");\n  }\n  if (line === null) {\n    start.returnToCheckpoint();\n    return Promise.resolve(null);\n  }\n  parseM3u8Text(line.trim(), structure.boxes);\n  return Promise.resolve(null);\n};\n\n// src/forward-controller-pause-resume-abort.ts\nvar forwardMediaParserControllerPauseResume = ({\n  parentController,\n  childController\n}) => {\n  const onAbort = ({ detail }) => {\n    childController.abort(detail.reason);\n  };\n  const onResume = () => {\n    childController.resume();\n  };\n  const onPause = () => {\n    childController.pause();\n  };\n  parentController.addEventListener(\"abort\", onAbort);\n  parentController.addEventListener(\"resume\", onResume);\n  parentController.addEventListener(\"pause\", onPause);\n  return {\n    cleanup: () => {\n      parentController.removeEventListener(\"abort\", onAbort);\n      parentController.removeEventListener(\"resume\", onResume);\n      parentController.removeEventListener(\"pause\", onPause);\n    }\n  };\n};\n// src/parse-media.ts\nvar parseMedia = (options) => {\n  if (!options) {\n    return Promise.reject(new Error(\"No options provided. See https://www.remotion.dev/media-parser for how to get started.\"));\n  }\n  return internalParseMedia({\n    fields: options.fields ?? null,\n    logLevel: options.logLevel ?? \"info\",\n    onAudioCodec: options.onAudioCodec ?? null,\n    onAudioTrack: options.onAudioTrack ?? null,\n    onContainer: options.onContainer ?? null,\n    onDimensions: options.onDimensions ?? null,\n    onDurationInSeconds: options.onDurationInSeconds ?? null,\n    onFps: options.onFps ?? null,\n    onImages: options.onImages ?? null,\n    onInternalStats: options.onInternalStats ?? null,\n    onIsHdr: options.onIsHdr ?? null,\n    onKeyframes: options.onKeyframes ?? null,\n    onLocation: options.onLocation ?? null,\n    onMetadata: options.onMetadata ?? null,\n    onMimeType: options.onMimeType ?? null,\n    onName: options.onName ?? null,\n    onNumberOfAudioChannels: options.onNumberOfAudioChannels ?? null,\n    onParseProgress: options.onParseProgress ?? null,\n    onRotation: options.onRotation ?? null,\n    onSampleRate: options.onSampleRate ?? null,\n    onSize: options.onSize ?? null,\n    onSlowAudioBitrate: options.onSlowAudioBitrate ?? null,\n    onSlowDurationInSeconds: options.onSlowDurationInSeconds ?? null,\n    onSlowFps: options.onSlowFps ?? null,\n    onSlowKeyframes: options.onSlowKeyframes ?? null,\n    onSlowNumberOfFrames: options.onSlowNumberOfFrames ?? null,\n    onSlowVideoBitrate: options.onSlowVideoBitrate ?? null,\n    onSlowStructure: options.onSlowStructure ?? null,\n    onM3uStreams: options.onM3uStreams ?? null,\n    onTracks: options.onTracks ?? null,\n    onUnrotatedDimensions: options.onUnrotatedDimensions ?? null,\n    onVideoCodec: options.onVideoCodec ?? null,\n    onVideoTrack: options.onVideoTrack ?? null,\n    progressIntervalInMs: options.progressIntervalInMs ?? null,\n    reader: options.reader ?? webReader,\n    controller: options.controller ?? undefined,\n    selectM3uStream: options.selectM3uStream ?? defaultSelectM3uStreamFn,\n    selectM3uAssociatedPlaylists: options.selectM3uAssociatedPlaylists ?? defaultSelectM3uAssociatedPlaylists,\n    m3uPlaylistContext: options.m3uPlaylistContext ?? null,\n    src: options.src,\n    mode: \"query\",\n    onDiscardedData: null,\n    onError: () => ({ action: \"fail\" }),\n    acknowledgeRemotionLicense: Boolean(options.acknowledgeRemotionLicense),\n    apiName: \"parseMedia()\",\n    makeSamplesStartAtZero: options.makeSamplesStartAtZero ?? true,\n    seekingHints: options.seekingHints ?? null\n  });\n};\n\n// src/containers/m3u/first-sample-in-m3u-chunk.ts\nvar considerSeekBasedOnChunk = async ({\n  sample,\n  parentController,\n  childController,\n  callback,\n  m3uState,\n  playlistUrl,\n  subtractChunks,\n  chunkIndex\n}) => {\n  const pendingSeek = m3uState.getSeekToSecondsToProcess(playlistUrl);\n  if (pendingSeek === null) {\n    await callback(sample);\n    return;\n  }\n  const timestamp = Math.min(sample.decodingTimestamp / WEBCODECS_TIMESCALE, sample.timestamp / WEBCODECS_TIMESCALE);\n  if (timestamp > pendingSeek.targetTime && chunkIndex !== null && chunkIndex > 0) {\n    m3uState.setNextSeekShouldSubtractChunks(playlistUrl, subtractChunks + 1);\n    parentController.seek(pendingSeek.targetTime);\n    return;\n  }\n  childController.seek(pendingSeek.targetTime);\n  m3uState.setNextSeekShouldSubtractChunks(playlistUrl, 0);\n  m3uState.setSeekToSecondsToProcess(playlistUrl, null);\n};\n\n// src/containers/m3u/get-chunks.ts\nvar getChunks = (playlist) => {\n  const chunks = [];\n  for (let i = 0;i < playlist.boxes.length; i++) {\n    const box = playlist.boxes[i];\n    if (box.type === \"m3u-map\") {\n      chunks.push({ duration: 0, url: box.value, isHeader: true });\n      continue;\n    }\n    if (box.type === \"m3u-extinf\") {\n      const nextBox = playlist.boxes[i + 1];\n      i++;\n      if (nextBox.type !== \"m3u-text-value\") {\n        throw new Error(\"Expected m3u-text-value\");\n      }\n      chunks.push({ duration: box.value, url: nextBox.value, isHeader: false });\n    }\n    continue;\n  }\n  return chunks;\n};\n\n// src/containers/m3u/seek/get-chunk-to-seek-to.ts\nvar getChunkToSeekTo = ({\n  chunks,\n  seekToSecondsToProcess\n}) => {\n  let duration2 = 0;\n  for (let i = 0;i < chunks.length; i++) {\n    if (duration2 >= seekToSecondsToProcess) {\n      return Math.max(0, i - 1);\n    }\n    duration2 += chunks[i].duration;\n  }\n  return Math.max(0, chunks.length - 1);\n};\n\n// src/containers/m3u/process-m3u-chunk.ts\nvar processM3uChunk = ({\n  playlistUrl,\n  state,\n  structure,\n  audioDone,\n  videoDone\n}) => {\n  const { promise, reject, resolve } = withResolvers();\n  const onGlobalAudioTrack = audioDone ? null : async (track) => {\n    const existingTracks = state.callbacks.tracks.getTracks();\n    let { trackId } = track;\n    while (existingTracks.find((t) => t.trackId === trackId)) {\n      trackId++;\n    }\n    const onAudioSample = await registerAudioTrack({\n      container: \"m3u8\",\n      track: {\n        ...track,\n        trackId\n      },\n      registerAudioSampleCallback: state.callbacks.registerAudioSampleCallback,\n      tracks: state.callbacks.tracks,\n      logLevel: state.logLevel,\n      onAudioTrack: state.onAudioTrack\n    });\n    state.m3u.sampleSorter.addToStreamWithTrack(playlistUrl);\n    if (onAudioSample === null) {\n      return null;\n    }\n    state.m3u.sampleSorter.addAudioStreamToConsider(playlistUrl, onAudioSample);\n    return async (sample) => {\n      await state.m3u.sampleSorter.addAudioSample(playlistUrl, sample);\n    };\n  };\n  const onGlobalVideoTrack = videoDone ? null : async (track) => {\n    const existingTracks = state.callbacks.tracks.getTracks();\n    let { trackId } = track;\n    while (existingTracks.find((t) => t.trackId === trackId)) {\n      trackId++;\n    }\n    const onVideoSample = await registerVideoTrack({\n      container: \"m3u8\",\n      track: {\n        ...track,\n        trackId\n      },\n      logLevel: state.logLevel,\n      onVideoTrack: state.onVideoTrack,\n      registerVideoSampleCallback: state.callbacks.registerVideoSampleCallback,\n      tracks: state.callbacks.tracks\n    });\n    state.m3u.sampleSorter.addToStreamWithTrack(playlistUrl);\n    if (onVideoSample === null) {\n      return null;\n    }\n    state.m3u.sampleSorter.addVideoStreamToConsider(playlistUrl, onVideoSample);\n    return async (sample) => {\n      await state.m3u.sampleSorter.addVideoSample(playlistUrl, sample);\n    };\n  };\n  const pausableIterator = async () => {\n    const playlist = getPlaylist(structure, playlistUrl);\n    const chunks = getChunks(playlist);\n    const seekToSecondsToProcess = state.m3u.getSeekToSecondsToProcess(playlistUrl);\n    const chunksToSubtract = state.m3u.getNextSeekShouldSubtractChunks(playlistUrl);\n    let chunkIndex = null;\n    if (seekToSecondsToProcess !== null) {\n      chunkIndex = Math.max(0, getChunkToSeekTo({\n        chunks,\n        seekToSecondsToProcess: seekToSecondsToProcess.targetTime\n      }) - chunksToSubtract);\n    }\n    const currentPromise = {\n      resolver: () => {\n        return;\n      },\n      rejector: reject\n    };\n    const requiresHeaderToBeFetched = chunks[0].isHeader;\n    for (const chunk of chunks) {\n      const mp4HeaderSegment = state.m3u.getMp4HeaderSegment(playlistUrl);\n      if (requiresHeaderToBeFetched && mp4HeaderSegment && chunk.isHeader) {\n        continue;\n      }\n      if (chunkIndex !== null && chunks.indexOf(chunk) < chunkIndex && !chunk.isHeader) {\n        continue;\n      }\n      currentPromise.resolver = (newRun) => {\n        state.m3u.setM3uStreamRun(playlistUrl, newRun);\n        resolve();\n      };\n      currentPromise.rejector = reject;\n      const childController = mediaParserController();\n      const forwarded = forwardMediaParserControllerPauseResume({\n        childController,\n        parentController: state.controller\n      });\n      const nextChunk = chunks[chunks.indexOf(chunk) + 1];\n      if (nextChunk) {\n        const nextChunkSource = state.readerInterface.createAdjacentFileSource(nextChunk.url, playlistUrl);\n        state.readerInterface.preload({\n          logLevel: state.logLevel,\n          range: null,\n          src: nextChunkSource,\n          prefetchCache: state.prefetchCache\n        });\n      }\n      const makeContinuationFn = () => {\n        return {\n          continue() {\n            const resolver = withResolvers();\n            currentPromise.resolver = resolver.resolve;\n            currentPromise.rejector = resolver.reject;\n            childController.resume();\n            return resolver.promise;\n          },\n          abort() {\n            childController.abort();\n          }\n        };\n      };\n      const isLastChunk = chunk === chunks[chunks.length - 1];\n      await childController._internals.checkForAbortAndPause();\n      const src = state.readerInterface.createAdjacentFileSource(chunk.url, playlistUrl);\n      try {\n        const data = await parseMedia({\n          src,\n          acknowledgeRemotionLicense: true,\n          logLevel: state.logLevel,\n          controller: childController,\n          progressIntervalInMs: 0,\n          onParseProgress: () => {\n            childController.pause();\n            currentPromise.resolver(makeContinuationFn());\n          },\n          fields: chunk.isHeader ? { slowStructure: true } : undefined,\n          onTracks: () => {\n            if (!state.m3u.hasEmittedDoneWithTracks(playlistUrl)) {\n              state.m3u.setHasEmittedDoneWithTracks(playlistUrl);\n              const allDone = state.m3u.setTracksDone(playlistUrl);\n              if (allDone) {\n                state.callbacks.tracks.setIsDone(state.logLevel);\n              }\n              return null;\n            }\n          },\n          onAudioTrack: onGlobalAudioTrack === null ? null : async ({ track }) => {\n            const callbackOrFalse = state.m3u.hasEmittedAudioTrack(playlistUrl);\n            if (callbackOrFalse === false) {\n              const callback = await onGlobalAudioTrack(track);\n              if (!callback) {\n                state.m3u.setHasEmittedAudioTrack(playlistUrl, null);\n                return null;\n              }\n              state.m3u.setHasEmittedAudioTrack(playlistUrl, callback);\n              return async (sample) => {\n                await considerSeekBasedOnChunk({\n                  sample,\n                  callback,\n                  parentController: state.controller,\n                  childController,\n                  m3uState: state.m3u,\n                  playlistUrl,\n                  subtractChunks: chunksToSubtract,\n                  chunkIndex\n                });\n              };\n            }\n            if (callbackOrFalse === null) {\n              return null;\n            }\n            return async (sample) => {\n              await considerSeekBasedOnChunk({\n                sample,\n                m3uState: state.m3u,\n                playlistUrl,\n                callback: callbackOrFalse,\n                parentController: state.controller,\n                childController,\n                subtractChunks: chunksToSubtract,\n                chunkIndex\n              });\n            };\n          },\n          onVideoTrack: onGlobalVideoTrack === null ? null : async ({ track }) => {\n            const callbackOrFalse = state.m3u.hasEmittedVideoTrack(playlistUrl);\n            if (callbackOrFalse === false) {\n              const callback = await onGlobalVideoTrack({\n                ...track,\n                m3uStreamFormat: chunk.isHeader || mp4HeaderSegment ? \"mp4\" : \"ts\"\n              });\n              if (!callback) {\n                state.m3u.setHasEmittedVideoTrack(playlistUrl, null);\n                return null;\n              }\n              state.m3u.setHasEmittedVideoTrack(playlistUrl, callback);\n              return async (sample) => {\n                await considerSeekBasedOnChunk({\n                  sample,\n                  m3uState: state.m3u,\n                  playlistUrl,\n                  callback,\n                  parentController: state.controller,\n                  childController,\n                  subtractChunks: chunksToSubtract,\n                  chunkIndex\n                });\n              };\n            }\n            if (callbackOrFalse === null) {\n              return null;\n            }\n            return async (sample) => {\n              await considerSeekBasedOnChunk({\n                sample,\n                m3uState: state.m3u,\n                playlistUrl,\n                callback: callbackOrFalse,\n                parentController: state.controller,\n                childController,\n                subtractChunks: chunksToSubtract,\n                chunkIndex\n              });\n            };\n          },\n          reader: state.readerInterface,\n          makeSamplesStartAtZero: false,\n          m3uPlaylistContext: {\n            mp4HeaderSegment,\n            isLastChunkInPlaylist: isLastChunk\n          }\n        });\n        if (chunk.isHeader) {\n          if (data.slowStructure.type !== \"iso-base-media\") {\n            throw new Error(\"Expected an mp4 file\");\n          }\n          state.m3u.setMp4HeaderSegment(playlistUrl, data.slowStructure);\n        }\n      } catch (e) {\n        currentPromise.rejector(e);\n        throw e;\n      }\n      forwarded.cleanup();\n      if (!isLastChunk) {\n        childController.pause();\n        currentPromise.resolver(makeContinuationFn());\n      }\n    }\n    currentPromise.resolver(null);\n  };\n  const run = pausableIterator();\n  run.catch((err) => {\n    reject(err);\n  });\n  return promise;\n};\n\n// src/containers/m3u/run-over-m3u.ts\nvar runOverM3u = async ({\n  state,\n  structure,\n  playlistUrl,\n  logLevel\n}) => {\n  const tracksDone = state.m3u.getTrackDone(playlistUrl);\n  const hasAudioStreamToConsider = state.m3u.sampleSorter.hasAudioStreamToConsider(playlistUrl);\n  const hasVideoStreamToConsider = state.m3u.sampleSorter.hasVideoStreamToConsider(playlistUrl);\n  const audioDone = !hasAudioStreamToConsider && tracksDone;\n  const videoDone = !hasVideoStreamToConsider && tracksDone;\n  const bothDone = audioDone && videoDone;\n  if (bothDone) {\n    state.m3u.setAllChunksProcessed(playlistUrl);\n    return;\n  }\n  const existingRun = state.m3u.getM3uStreamRun(playlistUrl);\n  if (existingRun) {\n    Log.trace(logLevel, \"Existing M3U parsing process found for\", playlistUrl);\n    const run = await existingRun.continue();\n    state.m3u.setM3uStreamRun(playlistUrl, run);\n    if (!run) {\n      state.m3u.setAllChunksProcessed(playlistUrl);\n    }\n    return;\n  }\n  Log.trace(logLevel, \"Starting new M3U parsing process for\", playlistUrl);\n  await processM3uChunk({\n    playlistUrl,\n    state,\n    structure,\n    audioDone,\n    videoDone\n  });\n};\n\n// src/containers/m3u/parse-m3u.ts\nvar parseM3u = async ({ state }) => {\n  const structure = state.structure.getM3uStructure();\n  if (state.m3u.isReadyToIterateOverM3u()) {\n    const selectedPlaylists = state.m3u.getSelectedPlaylists();\n    const whichPlaylistToRunOver = state.m3u.sampleSorter.getNextStreamToRun(selectedPlaylists);\n    await runOverM3u({\n      state,\n      structure,\n      playlistUrl: whichPlaylistToRunOver,\n      logLevel: state.logLevel\n    });\n    return null;\n  }\n  if (state.m3u.hasFinishedManifest()) {\n    if (typeof state.src !== \"string\" && !(state.src instanceof URL)) {\n      throw new Error(\"Expected src to be a string\");\n    }\n    state.mediaSection.addMediaSection({\n      start: 0,\n      size: state.contentLength + 1\n    });\n    await afterManifestFetch({\n      structure,\n      m3uState: state.m3u,\n      src: state.src.toString(),\n      selectM3uStreamFn: state.selectM3uStreamFn,\n      logLevel: state.logLevel,\n      selectAssociatedPlaylistsFn: state.selectM3uAssociatedPlaylistsFn,\n      readerInterface: state.readerInterface,\n      onAudioTrack: state.onAudioTrack,\n      canSkipTracks: state.callbacks.canSkipTracksState\n    });\n    return null;\n  }\n  const box = await parseM3uManifest({\n    iterator: state.iterator,\n    structure,\n    contentLength: state.contentLength\n  });\n  const isDoneNow = state.iterator.counter.getOffset() === state.contentLength;\n  if (isDoneNow) {\n    state.m3u.setHasFinishedManifest();\n  }\n  return box;\n};\n\n// src/containers/mp3/id3.ts\nfunction combine28Bits(a, b, c, d) {\n  const val1 = a & 127;\n  const val2 = b & 127;\n  const val3 = c & 127;\n  const val4 = d & 127;\n  return val1 << 21 | val2 << 14 | val3 << 7 | val4;\n}\nvar parseId3 = ({ state }) => {\n  const { iterator } = state;\n  if (iterator.bytesRemaining() < 9) {\n    return;\n  }\n  const { returnToCheckpoint } = iterator.startCheckpoint();\n  iterator.discard(3);\n  const versionMajor = iterator.getUint8();\n  const versionMinor = iterator.getUint8();\n  const flags = iterator.getUint8();\n  const sizeArr = iterator.getSlice(4);\n  const size = combine28Bits(sizeArr[0], sizeArr[1], sizeArr[2], sizeArr[3]);\n  if (iterator.bytesRemaining() < size) {\n    returnToCheckpoint();\n    return;\n  }\n  const entries = [];\n  const initial = iterator.counter.getOffset();\n  while (iterator.counter.getOffset() < size + initial) {\n    const name = versionMajor === 3 || versionMajor === 4 ? iterator.getByteString(4, true) : iterator.getByteString(3, true);\n    if (name === \"\") {\n      iterator.discard(size + initial - iterator.counter.getOffset());\n      break;\n    }\n    const s = versionMajor === 4 ? iterator.getSyncSafeInt32() : versionMajor === 3 ? iterator.getUint32() : iterator.getUint24();\n    if (versionMajor === 3 || versionMajor === 4) {\n      iterator.getUint16();\n    }\n    let subtract = 0;\n    if (!name.startsWith(\"W\")) {\n      iterator.getUint8();\n      subtract += 1;\n    }\n    if (name === \"APIC\") {\n      const { discardRest } = iterator.planBytes(s - subtract);\n      const mimeType = iterator.readUntilNullTerminator();\n      iterator.getUint16();\n      const description = iterator.readUntilNullTerminator();\n      iterator.discard(1);\n      const data = discardRest();\n      state.images.addImage({\n        data,\n        description,\n        mimeType\n      });\n    } else {\n      const information = iterator.getByteString(s - subtract, true);\n      entries.push({\n        key: name,\n        value: information,\n        trackId: null\n      });\n    }\n  }\n  state.structure.getMp3Structure().boxes.push({\n    type: \"id3-header\",\n    flags,\n    size,\n    versionMajor,\n    versionMinor,\n    metatags: entries\n  });\n};\n\n// src/containers/mp3/id3-v1.ts\nvar parseID3V1 = (iterator) => {\n  if (iterator.bytesRemaining() < 128) {\n    return;\n  }\n  iterator.discard(128);\n};\n\n// src/containers/mp3/parse-packet-header.ts\nfunction getSamplingFrequency({\n  bits,\n  mpegVersion\n}) {\n  const samplingTable = {\n    0: { MPEG1: 44100, MPEG2: 22050 },\n    1: { MPEG1: 48000, MPEG2: 24000 },\n    2: { MPEG1: 32000, MPEG2: 16000 },\n    3: { MPEG1: \"reserved\", MPEG2: \"reserved\" }\n  };\n  const key = `MPEG${mpegVersion}`;\n  const value = samplingTable[bits][key];\n  if (value === \"reserved\") {\n    throw new Error(\"Reserved sampling frequency\");\n  }\n  if (!value) {\n    throw new Error(\"Invalid sampling frequency for MPEG version: \" + JSON.stringify({ bits, version: mpegVersion }));\n  }\n  return value;\n}\nfunction getBitrateKB({\n  bits,\n  mpegVersion,\n  level\n}) {\n  const bitrateTable = {\n    0: {\n      \"V1,L1\": \"free\",\n      \"V1,L2\": \"free\",\n      \"V1,L3\": \"free\",\n      \"V2,L1\": \"free\",\n      \"V2,L2&L3\": \"free\"\n    },\n    1: { \"V1,L1\": 32, \"V1,L2\": 32, \"V1,L3\": 32, \"V2,L1\": 32, \"V2,L2&L3\": 8 },\n    2: {\n      \"V1,L1\": 64,\n      \"V1,L2\": 48,\n      \"V1,L3\": 40,\n      \"V2,L1\": 48,\n      \"V2,L2&L3\": 16\n    },\n    3: {\n      \"V1,L1\": 96,\n      \"V1,L2\": 56,\n      \"V1,L3\": 48,\n      \"V2,L1\": 56,\n      \"V2,L2&L3\": 24\n    },\n    4: {\n      \"V1,L1\": 128,\n      \"V1,L2\": 64,\n      \"V1,L3\": 56,\n      \"V2,L1\": 64,\n      \"V2,L2&L3\": 32\n    },\n    5: {\n      \"V1,L1\": 160,\n      \"V1,L2\": 80,\n      \"V1,L3\": 64,\n      \"V2,L1\": 80,\n      \"V2,L2&L3\": 40\n    },\n    6: {\n      \"V1,L1\": 192,\n      \"V1,L2\": 96,\n      \"V1,L3\": 80,\n      \"V2,L1\": 96,\n      \"V2,L2&L3\": 48\n    },\n    7: {\n      \"V1,L1\": 224,\n      \"V1,L2\": 112,\n      \"V1,L3\": 96,\n      \"V2,L1\": 112,\n      \"V2,L2&L3\": 56\n    },\n    8: {\n      \"V1,L1\": 256,\n      \"V1,L2\": 128,\n      \"V1,L3\": 112,\n      \"V2,L1\": 128,\n      \"V2,L2&L3\": 64\n    },\n    9: {\n      \"V1,L1\": 288,\n      \"V1,L2\": 160,\n      \"V1,L3\": 128,\n      \"V2,L1\": 144,\n      \"V2,L2&L3\": 80\n    },\n    10: {\n      \"V1,L1\": 320,\n      \"V1,L2\": 192,\n      \"V1,L3\": 160,\n      \"V2,L1\": 160,\n      \"V2,L2&L3\": 96\n    },\n    11: {\n      \"V1,L1\": 352,\n      \"V1,L2\": 224,\n      \"V1,L3\": 192,\n      \"V2,L1\": 176,\n      \"V2,L2&L3\": 112\n    },\n    12: {\n      \"V1,L1\": 384,\n      \"V1,L2\": 256,\n      \"V1,L3\": 224,\n      \"V2,L1\": 192,\n      \"V2,L2&L3\": 128\n    },\n    13: {\n      \"V1,L1\": 416,\n      \"V1,L2\": 320,\n      \"V1,L3\": 256,\n      \"V2,L1\": 224,\n      \"V2,L2&L3\": 144\n    },\n    14: {\n      \"V1,L1\": 448,\n      \"V1,L2\": 384,\n      \"V1,L3\": 320,\n      \"V2,L1\": 256,\n      \"V2,L2&L3\": 160\n    },\n    15: {\n      \"V1,L1\": \"bad\",\n      \"V1,L2\": \"bad\",\n      \"V1,L3\": \"bad\",\n      \"V2,L1\": \"bad\",\n      \"V2,L2&L3\": \"bad\"\n    }\n  };\n  let key;\n  if (mpegVersion === 2 && (level === 2 || level === 3)) {\n    key = \"V2,L2&L3\";\n  } else {\n    key = `V${mpegVersion},L${level}`;\n  }\n  return bitrateTable[bits][key];\n}\nvar innerParseMp3PacketHeader = (iterator) => {\n  for (let i = 0;i < 11; i++) {\n    const expectToBe1 = iterator.getBits(1);\n    if (expectToBe1 !== 1) {\n      throw new Error(\"Expected 1\");\n    }\n  }\n  const audioVersionId = iterator.getBits(2);\n  if (audioVersionId !== 3 && audioVersionId !== 2) {\n    throw new Error(\"Expected MPEG Version 1 or 2\");\n  }\n  const mpegVersion = audioVersionId === 3 ? 1 : 2;\n  const layerBits = iterator.getBits(2);\n  if (layerBits === 0) {\n    throw new Error(\"Expected Layer I, II or III\");\n  }\n  const layer = layerBits === 3 ? 1 : layerBits === 2 ? 2 : 3;\n  const protectionBit = iterator.getBits(1);\n  if (protectionBit !== 1) {\n    throw new Error(\"Does not support CRC yet\");\n  }\n  const bitrateIndex = iterator.getBits(4);\n  const bitrateInKbit = getBitrateKB({\n    bits: bitrateIndex,\n    mpegVersion,\n    level: audioVersionId\n  });\n  if (bitrateInKbit === \"bad\") {\n    throw new Error(\"Invalid bitrate\");\n  }\n  if (bitrateInKbit === \"free\") {\n    throw new Error(\"Free bitrate not supported\");\n  }\n  const samplingFrequencyIndex = iterator.getBits(2);\n  const sampleRate = getSamplingFrequency({\n    bits: samplingFrequencyIndex,\n    mpegVersion\n  });\n  const padding = Boolean(iterator.getBits(1));\n  iterator.getBits(1);\n  const channelMode = iterator.getBits(2);\n  iterator.getBits(2);\n  iterator.getBits(1);\n  iterator.getBits(1);\n  iterator.getBits(2);\n  const numberOfChannels = channelMode === 3 ? 1 : 2;\n  const samplesPerFrame = getSamplesPerMpegFrame({ mpegVersion, layer });\n  const frameLength = getMpegFrameLength({\n    bitrateKbit: bitrateInKbit,\n    padding,\n    samplesPerFrame,\n    samplingFrequency: sampleRate,\n    layer\n  });\n  return {\n    frameLength,\n    bitrateInKbit,\n    layer,\n    mpegVersion,\n    numberOfChannels,\n    sampleRate,\n    samplesPerFrame\n  };\n};\nvar parseMp3PacketHeader = (iterator) => {\n  iterator.startReadingBits();\n  const d = innerParseMp3PacketHeader(iterator);\n  iterator.stopReadingBits();\n  return d;\n};\nvar isMp3PacketHeaderHere = (iterator) => {\n  const offset = iterator.counter.getOffset();\n  iterator.startReadingBits();\n  try {\n    const res = innerParseMp3PacketHeader(iterator);\n    iterator.stopReadingBits();\n    iterator.counter.decrement(iterator.counter.getOffset() - offset);\n    return res;\n  } catch {\n    iterator.stopReadingBits();\n    iterator.counter.decrement(iterator.counter.getOffset() - offset);\n    return false;\n  }\n};\nvar isMp3PacketHeaderHereAndInNext = (iterator) => {\n  const offset = iterator.counter.getOffset();\n  const res = isMp3PacketHeaderHere(iterator);\n  if (!res) {\n    return false;\n  }\n  if (iterator.bytesRemaining() <= res.frameLength) {\n    return true;\n  }\n  iterator.counter.increment(res.frameLength);\n  const isHere = isMp3PacketHeaderHere(iterator);\n  iterator.counter.decrement(iterator.counter.getOffset() - offset);\n  return isHere;\n};\n\n// src/containers/mp3/seek/audio-sample-from-cbr.ts\nvar getAudioSampleFromCbr = ({\n  bitrateInKbit,\n  initialOffset,\n  layer,\n  sampleRate,\n  samplesPerFrame,\n  data,\n  state\n}) => {\n  const avgLength = getAverageMpegFrameLength({\n    bitrateKbit: bitrateInKbit,\n    layer,\n    samplesPerFrame,\n    samplingFrequency: sampleRate\n  });\n  const mp3Info = state.mp3.getMp3Info();\n  if (!mp3Info) {\n    throw new Error(\"No MP3 info\");\n  }\n  const nthFrame = Math.round((initialOffset - state.mediaSection.getMediaSectionAssertOnlyOne().start) / avgLength);\n  const durationInSeconds = samplesPerFrame / sampleRate;\n  const timeInSeconds = nthFrame * samplesPerFrame / sampleRate;\n  const timestamp = Math.floor(timeInSeconds * WEBCODECS_TIMESCALE);\n  const duration2 = Math.floor(durationInSeconds * WEBCODECS_TIMESCALE);\n  const audioSample = {\n    data,\n    decodingTimestamp: timestamp,\n    duration: duration2,\n    offset: initialOffset,\n    timestamp,\n    type: \"key\"\n  };\n  return { audioSample, timeInSeconds, durationInSeconds };\n};\n\n// src/containers/mp3/seek/audio-sample-from-vbr.ts\nvar getAudioSampleFromVbr = ({\n  info,\n  position,\n  mp3Info,\n  data\n}) => {\n  if (!mp3Info) {\n    throw new Error(\"No MP3 info\");\n  }\n  const samplesPerFrame = getSamplesPerMpegFrame({\n    layer: mp3Info.layer,\n    mpegVersion: mp3Info.mpegVersion\n  });\n  const wholeFileDuration = getDurationFromMp3Xing({\n    samplesPerFrame,\n    xingData: info.xingData\n  });\n  if (!info.xingData.fileSize) {\n    throw new Error(\"file size\");\n  }\n  if (!info.xingData.tableOfContents) {\n    throw new Error(\"table of contents\");\n  }\n  const timeInSeconds = getTimeFromPosition({\n    durationInSeconds: wholeFileDuration,\n    fileSize: info.xingData.fileSize,\n    position,\n    tableOfContents: info.xingData.tableOfContents\n  });\n  const durationInSeconds = samplesPerFrame / info.xingData.sampleRate;\n  const timestamp = Math.floor(timeInSeconds * WEBCODECS_TIMESCALE);\n  const duration2 = Math.floor(durationInSeconds * WEBCODECS_TIMESCALE);\n  const audioSample = {\n    data,\n    decodingTimestamp: timestamp,\n    duration: duration2,\n    offset: position,\n    timestamp,\n    type: \"key\"\n  };\n  return { timeInSeconds, audioSample, durationInSeconds };\n};\n\n// src/containers/mp3/parse-mpeg-header.ts\nvar parseMpegHeader = async ({\n  state\n}) => {\n  const { iterator } = state;\n  const initialOffset = iterator.counter.getOffset();\n  if (iterator.bytesRemaining() < 32) {\n    return;\n  }\n  const {\n    frameLength,\n    bitrateInKbit,\n    layer,\n    mpegVersion,\n    numberOfChannels,\n    sampleRate,\n    samplesPerFrame\n  } = parseMp3PacketHeader(iterator);\n  const cbrMp3Info = state.mp3.getMp3BitrateInfo();\n  if (cbrMp3Info && cbrMp3Info.type === \"constant\") {\n    if (bitrateInKbit !== cbrMp3Info.bitrateInKbit) {\n      throw new Error(`Bitrate mismatch at offset ${initialOffset}: ${bitrateInKbit} !== ${cbrMp3Info.bitrateInKbit}`);\n    }\n  }\n  const offsetNow = iterator.counter.getOffset();\n  iterator.counter.decrement(offsetNow - initialOffset);\n  const data = iterator.getSlice(frameLength);\n  if (state.callbacks.tracks.getTracks().length === 0) {\n    const info = {\n      layer,\n      mpegVersion,\n      sampleRate\n    };\n    const asText = new TextDecoder().decode(data);\n    if (asText.includes(\"VBRI\")) {\n      throw new Error(\"MP3 files with VBRI are currently unsupported because we have no sample file. Submit this file at remotion.dev/report if you would like us to support this file.\");\n    }\n    if (asText.includes(\"Info\")) {\n      return;\n    }\n    const isVbr = asText.includes(\"Xing\");\n    if (isVbr) {\n      const xingData = parseXing(data);\n      Log.verbose(state.logLevel, \"MP3 has variable bit rate. Requiring whole file to be read\");\n      state.mp3.setMp3BitrateInfo({\n        type: \"variable\",\n        xingData\n      });\n      return;\n    }\n    if (!state.mp3.getMp3BitrateInfo()) {\n      state.mp3.setMp3BitrateInfo({\n        bitrateInKbit,\n        type: \"constant\"\n      });\n    }\n    state.mp3.setMp3Info(info);\n    await registerAudioTrack({\n      container: \"mp3\",\n      track: {\n        type: \"audio\",\n        codec: \"mp3\",\n        codecData: null,\n        codecEnum: \"mp3\",\n        description: undefined,\n        numberOfChannels,\n        sampleRate,\n        originalTimescale: 1e6,\n        trackId: 0,\n        startInSeconds: 0,\n        timescale: WEBCODECS_TIMESCALE\n      },\n      registerAudioSampleCallback: state.callbacks.registerAudioSampleCallback,\n      tracks: state.callbacks.tracks,\n      logLevel: state.logLevel,\n      onAudioTrack: state.onAudioTrack\n    });\n    state.callbacks.tracks.setIsDone(state.logLevel);\n    state.mediaSection.addMediaSection({\n      start: initialOffset,\n      size: state.contentLength - initialOffset\n    });\n  }\n  const bitrateInfo = state.mp3.getMp3BitrateInfo();\n  if (!bitrateInfo) {\n    throw new Error(\"No bitrate info\");\n  }\n  const sample = bitrateInfo.type === \"constant\" ? getAudioSampleFromCbr({\n    bitrateInKbit,\n    data,\n    initialOffset,\n    layer,\n    sampleRate,\n    samplesPerFrame,\n    state\n  }) : getAudioSampleFromVbr({\n    data,\n    info: bitrateInfo,\n    mp3Info: state.mp3.getMp3Info(),\n    position: initialOffset\n  });\n  const { audioSample, timeInSeconds, durationInSeconds } = sample;\n  state.mp3.audioSamples.addSample({\n    timeInSeconds,\n    offset: initialOffset,\n    durationInSeconds\n  });\n  await state.callbacks.onAudioSample({\n    audioSample,\n    trackId: 0\n  });\n};\n\n// src/containers/mp3/seek/wait-until-syncword.ts\nvar discardUntilSyncword = ({\n  iterator\n}) => {\n  while (true) {\n    const next2Bytes = iterator.getUint8();\n    if (next2Bytes !== 255) {\n      continue;\n    }\n    const nextByte = iterator.getUint8();\n    const mask = 224;\n    if ((nextByte & mask) !== mask) {\n      continue;\n    }\n    iterator.counter.decrement(2);\n    if (isMp3PacketHeaderHereAndInNext(iterator)) {\n      break;\n    } else {\n      iterator.counter.increment(2);\n    }\n  }\n};\n\n// src/containers/mp3/parse-mp3.ts\nvar parseMp3 = async (state) => {\n  const { iterator } = state;\n  if (iterator.bytesRemaining() < 3) {\n    return null;\n  }\n  if (state.mediaSection.isCurrentByteInMediaSection(iterator) === \"in-section\") {\n    discardUntilSyncword({ iterator });\n    await parseMpegHeader({\n      state\n    });\n    return null;\n  }\n  const { returnToCheckpoint } = iterator.startCheckpoint();\n  const bytes = iterator.getSlice(3);\n  returnToCheckpoint();\n  if (bytes[0] === 84 && bytes[1] === 65 && bytes[2] === 71) {\n    parseID3V1(iterator);\n    return null;\n  }\n  if (bytes[0] === 73 && bytes[1] === 68 && bytes[2] === 51) {\n    parseId3({ state });\n    return null;\n  }\n  if (bytes[0] === 255) {\n    await parseMpegHeader({\n      state\n    });\n    return null;\n  }\n  throw new Error(\"Unknown MP3 header \" + JSON.stringify(bytes));\n};\n\n// src/containers/riff/get-strh-for-index.ts\nvar getStrhForIndex = (structure, trackId) => {\n  const boxes = getStrlBoxes(structure);\n  const box = boxes[trackId];\n  if (!box) {\n    throw new Error(\"Expected box\");\n  }\n  const strh = getStrhBox(box.children);\n  if (!strh) {\n    throw new Error(\"strh\");\n  }\n  return strh;\n};\n\n// src/containers/riff/convert-queued-sample-to-mediaparser-sample.ts\nvar getKeyFrameOffsetAndPocs = ({\n  state,\n  sample,\n  trackId\n}) => {\n  if (sample.type === \"key\") {\n    const sampleOffset = state.riff.sampleCounter.getSampleCountForTrack({\n      trackId\n    });\n    return {\n      sampleOffsetAtKeyframe: sampleOffset,\n      pocsAtKeyframeOffset: [sample.avc?.poc ?? 0]\n    };\n  }\n  const riffKeyframes = state.riff.sampleCounter.riffKeys.getKeyframes();\n  const keyframeAtOffset = riffKeyframes.findLast((k) => k.positionInBytes <= sample.offset);\n  if (!keyframeAtOffset) {\n    throw new Error(\"no keyframe at offset\");\n  }\n  const sampleOffsetAtKeyframe = keyframeAtOffset.sampleCounts[trackId];\n  const pocsAtKeyframeOffset = state.riff.sampleCounter.getPocAtKeyframeOffset({\n    keyframeOffset: keyframeAtOffset.positionInBytes\n  });\n  return {\n    sampleOffsetAtKeyframe,\n    pocsAtKeyframeOffset\n  };\n};\nvar convertQueuedSampleToMediaParserSample = ({\n  sample,\n  state,\n  trackId\n}) => {\n  const strh = getStrhForIndex(state.structure.getRiffStructure(), trackId);\n  const samplesPerSecond = strh.rate / strh.scale;\n  const { sampleOffsetAtKeyframe, pocsAtKeyframeOffset } = getKeyFrameOffsetAndPocs({\n    sample,\n    state,\n    trackId\n  });\n  const indexOfPoc = pocsAtKeyframeOffset.findIndex((poc) => poc === sample.avc?.poc);\n  if (indexOfPoc === -1) {\n    throw new Error(\"poc not found\");\n  }\n  const nthSample = indexOfPoc + sampleOffsetAtKeyframe;\n  const timestamp = nthSample / samplesPerSecond;\n  const videoSample = convertAudioOrVideoSampleToWebCodecsTimestamps({\n    sample: {\n      ...sample,\n      timestamp,\n      decodingTimestamp: timestamp\n    },\n    timescale: 1\n  });\n  return videoSample;\n};\n\n// src/containers/riff/is-movi.ts\nvar isMoviAtom = (iterator, ckId) => {\n  if (ckId !== \"LIST\") {\n    return false;\n  }\n  const listType = iterator.getByteString(4, false);\n  iterator.counter.decrement(4);\n  return listType === \"movi\";\n};\n\n// src/containers/riff/parse-avih.ts\nvar AVIF_HAS_INDEX = 16;\nvar parseAvih = ({\n  iterator,\n  size\n}) => {\n  const { expectNoMoreBytes } = iterator.startBox(size);\n  const dwMicroSecPerFrame = iterator.getUint32Le();\n  const dwMaxBytesPerSec = iterator.getUint32Le();\n  const paddingGranularity = iterator.getUint32Le();\n  const flags = iterator.getUint32Le();\n  const totalFrames = iterator.getUint32Le();\n  const initialFrames = iterator.getUint32Le();\n  const streams = iterator.getUint32Le();\n  const suggestedBufferSize = iterator.getUint32Le();\n  const width = iterator.getUint32Le();\n  const height = iterator.getUint32Le();\n  const hasIndex = (flags & AVIF_HAS_INDEX) !== 0;\n  iterator.discard(16);\n  expectNoMoreBytes();\n  return {\n    type: \"avih-box\",\n    hasIndex,\n    microSecPerFrame: dwMicroSecPerFrame,\n    maxBytesPerSecond: dwMaxBytesPerSec,\n    paddingGranularity,\n    flags,\n    totalFrames,\n    initialFrames,\n    streams,\n    suggestedBufferSize,\n    height,\n    width\n  };\n};\n\n// src/containers/riff/parse-idx1.ts\nvar AVIIF_KEYFRAME = 16;\nvar parseIdx1 = ({\n  iterator,\n  size\n}) => {\n  const box = iterator.startBox(size);\n  const offset = iterator.counter.getOffset();\n  const entries = [];\n  const sampleCounts = {};\n  let videoTrackIndex = null;\n  while (iterator.counter.getOffset() < offset + size) {\n    const chunkId = iterator.getByteString(4, false);\n    const flags = iterator.getUint32Le();\n    const moffset = iterator.getUint32Le();\n    const msize = iterator.getUint32Le();\n    const chunk = chunkId.match(/^([0-9]{2})(wb|dc)$/);\n    const isVideo = chunkId.endsWith(\"dc\");\n    if (isVideo) {\n      videoTrackIndex = chunk ? parseInt(chunk[1], 10) : null;\n    }\n    const trackId = chunk ? parseInt(chunk[1], 10) : null;\n    if (trackId === null) {\n      continue;\n    }\n    if (!sampleCounts[trackId]) {\n      sampleCounts[trackId] = 0;\n    }\n    const isKeyFrame = (flags & AVIIF_KEYFRAME) !== 0;\n    if (isKeyFrame) {\n      entries.push({\n        flags,\n        id: chunkId,\n        offset: moffset,\n        size: msize,\n        sampleCounts: { ...sampleCounts }\n      });\n    }\n    sampleCounts[trackId]++;\n  }\n  box.expectNoMoreBytes();\n  return {\n    type: \"idx1-box\",\n    entries,\n    videoTrackIndex\n  };\n};\n\n// src/containers/riff/parse-isft.ts\nvar parseIsft = ({\n  iterator,\n  size\n}) => {\n  const { expectNoMoreBytes } = iterator.startBox(size);\n  const software = iterator.getByteString(size - 1, false);\n  const last = iterator.getUint8();\n  if (last !== 0) {\n    throw new Error(`Expected 0 byte, got ${last}`);\n  }\n  expectNoMoreBytes();\n  return {\n    type: \"isft-box\",\n    software\n  };\n};\n\n// src/containers/riff/parse-list-box.ts\nvar parseListBox = async ({\n  size,\n  iterator,\n  stateIfExpectingSideEffects\n}) => {\n  const counter = iterator.counter.getOffset();\n  const listType = iterator.getByteString(4, false);\n  if (listType === \"movi\") {\n    throw new Error(\"should not be handled here\");\n  }\n  const boxes = [];\n  const maxOffset = counter + size;\n  while (iterator.counter.getOffset() < maxOffset) {\n    const box = await expectRiffBox({\n      iterator,\n      stateIfExpectingSideEffects\n    });\n    if (box === null) {\n      throw new Error(\"Unexpected result\");\n    }\n    if (stateIfExpectingSideEffects) {\n      await postProcessRiffBox(stateIfExpectingSideEffects, box);\n    }\n    boxes.push(box);\n  }\n  return {\n    type: \"list-box\",\n    listType,\n    children: boxes\n  };\n};\n\n// src/containers/riff/parse-strf.ts\nvar parseStrfAudio = ({\n  iterator,\n  size\n}) => {\n  const box = iterator.startBox(size);\n  const formatTag = iterator.getUint16Le();\n  const numberOfChannels = iterator.getUint16Le();\n  const samplesPerSec = iterator.getUint32Le();\n  const avgBytesPerSec = iterator.getUint32Le();\n  const blockAlign = iterator.getUint16Le();\n  const bitsPerSample = iterator.getUint16Le();\n  const cbSize = iterator.getUint16Le();\n  box.expectNoMoreBytes();\n  return {\n    type: \"strf-box-audio\",\n    avgBytesPerSecond: avgBytesPerSec,\n    bitsPerSample,\n    blockAlign,\n    cbSize,\n    formatTag,\n    numberOfChannels,\n    sampleRate: samplesPerSec\n  };\n};\nvar parseStrfVideo = ({\n  iterator,\n  size\n}) => {\n  const box = iterator.startBox(size);\n  const biSize = iterator.getUint32Le();\n  const width = iterator.getInt32Le();\n  const height = iterator.getInt32Le();\n  const planes = iterator.getUint16Le();\n  const bitCount = iterator.getUint16Le();\n  const compression = iterator.getByteString(4, false);\n  const sizeImage = iterator.getUint32Le();\n  const xPelsPerMeter = iterator.getInt32Le();\n  const yPelsPerMeter = iterator.getInt32Le();\n  const clrUsed = iterator.getUint32Le();\n  const clrImportant = iterator.getUint32Le();\n  box.expectNoMoreBytes();\n  return {\n    type: \"strf-box-video\",\n    biSize,\n    bitCount,\n    clrImportant,\n    clrUsed,\n    compression,\n    height,\n    planes,\n    sizeImage,\n    width,\n    xPelsPerMeter,\n    yPelsPerMeter\n  };\n};\nvar parseStrf = ({\n  iterator,\n  size,\n  fccType\n}) => {\n  if (fccType === \"vids\") {\n    return parseStrfVideo({ iterator, size });\n  }\n  if (fccType === \"auds\") {\n    return parseStrfAudio({ iterator, size });\n  }\n  throw new Error(`Unsupported fccType: ${fccType}`);\n};\n\n// src/containers/riff/parse-strh.ts\nvar parseStrh = ({\n  iterator,\n  size\n}) => {\n  const box = iterator.startBox(size);\n  const fccType = iterator.getByteString(4, false);\n  if (fccType !== \"vids\" && fccType !== \"auds\") {\n    throw new Error(\"Expected AVI handler to be vids / auds\");\n  }\n  const handler = fccType === \"vids\" ? iterator.getByteString(4, false) : iterator.getUint32Le();\n  if (typeof handler === \"string\" && handler !== \"H264\") {\n    throw new Error(`Only H264 is supported as a stream type in .avi, got ${handler}`);\n  }\n  if (fccType === \"auds\" && handler !== 1) {\n    throw new Error(`Only \"1\" is supported as a stream type in .avi, got ${handler}`);\n  }\n  const flags = iterator.getUint32Le();\n  const priority = iterator.getUint16Le();\n  const language2 = iterator.getUint16Le();\n  const initialFrames = iterator.getUint32Le();\n  const scale = iterator.getUint32Le();\n  const rate = iterator.getUint32Le();\n  const start = iterator.getUint32Le();\n  const length = iterator.getUint32Le();\n  const suggestedBufferSize = iterator.getUint32Le();\n  const quality = iterator.getUint32Le();\n  const sampleSize = iterator.getUint32Le();\n  box.discardRest();\n  const ckId = iterator.getByteString(4, false);\n  const ckSize = iterator.getUint32Le();\n  if (ckId !== \"strf\") {\n    throw new Error(`Expected strf, got ${JSON.stringify(ckId)}`);\n  }\n  if (iterator.bytesRemaining() < ckSize) {\n    throw new Error(\"Expected strf to be complete\");\n  }\n  const strf = parseStrf({ iterator, size: ckSize, fccType });\n  return {\n    type: \"strh-box\",\n    fccType,\n    handler,\n    flags,\n    priority,\n    initialFrames,\n    length,\n    quality,\n    rate,\n    sampleSize,\n    scale,\n    start,\n    suggestedBufferSize,\n    language: language2,\n    strf\n  };\n};\n\n// src/containers/riff/parse-riff-box.ts\nvar parseRiffBox = ({\n  size,\n  id,\n  iterator,\n  stateIfExpectingSideEffects\n}) => {\n  if (id === \"LIST\") {\n    return parseListBox({\n      size,\n      iterator,\n      stateIfExpectingSideEffects\n    });\n  }\n  if (id === \"ISFT\") {\n    return Promise.resolve(parseIsft({ iterator, size }));\n  }\n  if (id === \"avih\") {\n    return Promise.resolve(parseAvih({ iterator, size }));\n  }\n  if (id === \"strh\") {\n    return Promise.resolve(parseStrh({ iterator, size }));\n  }\n  if (id === \"idx1\") {\n    return Promise.resolve(parseIdx1({ iterator, size }));\n  }\n  iterator.discard(size);\n  const box = {\n    type: \"riff-box\",\n    size,\n    id\n  };\n  return Promise.resolve(box);\n};\n\n// src/containers/riff/expect-riff-box.ts\nvar postProcessRiffBox = async (state, box) => {\n  if (box.type === \"strh-box\") {\n    if (box.strf.type === \"strf-box-audio\" && state.onAudioTrack) {\n      const audioTrack = makeAviAudioTrack({\n        index: state.riff.getNextTrackIndex(),\n        strf: box.strf\n      });\n      await registerAudioTrack({\n        track: audioTrack,\n        container: \"avi\",\n        registerAudioSampleCallback: state.callbacks.registerAudioSampleCallback,\n        tracks: state.callbacks.tracks,\n        logLevel: state.logLevel,\n        onAudioTrack: state.onAudioTrack\n      });\n    }\n    if (state.onVideoTrack && box.strf.type === \"strf-box-video\") {\n      const videoTrack = makeAviVideoTrack({\n        strh: box,\n        index: state.riff.getNextTrackIndex(),\n        strf: box.strf\n      });\n      registerVideoTrackWhenProfileIsAvailable({\n        state,\n        track: videoTrack,\n        container: \"avi\"\n      });\n    }\n    state.riff.incrementNextTrackIndex();\n  }\n};\nvar expectRiffBox = async ({\n  iterator,\n  stateIfExpectingSideEffects\n}) => {\n  if (iterator.bytesRemaining() < 16) {\n    return null;\n  }\n  const checkpoint = iterator.startCheckpoint();\n  const ckId = iterator.getByteString(4, false);\n  const ckSize = iterator.getUint32Le();\n  if (isMoviAtom(iterator, ckId)) {\n    iterator.discard(4);\n    if (!stateIfExpectingSideEffects) {\n      throw new Error(\"No state if expecting side effects\");\n    }\n    stateIfExpectingSideEffects.mediaSection.addMediaSection({\n      start: iterator.counter.getOffset(),\n      size: ckSize - 4\n    });\n    if (riffHasIndex(stateIfExpectingSideEffects.structure.getRiffStructure())) {\n      stateIfExpectingSideEffects.riff.lazyIdx1.triggerLoad(iterator.counter.getOffset() + ckSize - 4);\n    }\n    return null;\n  }\n  if (iterator.bytesRemaining() < ckSize) {\n    checkpoint.returnToCheckpoint();\n    return null;\n  }\n  const box = await parseRiffBox({\n    id: ckId,\n    size: ckSize,\n    iterator,\n    stateIfExpectingSideEffects\n  });\n  return box;\n};\n\n// src/containers/riff/parse-movi.ts\nvar handleChunk = async ({\n  state,\n  ckId,\n  ckSize\n}) => {\n  const { iterator } = state;\n  const offset = iterator.counter.getOffset() - 8;\n  const videoChunk = ckId.match(/^([0-9]{2})dc$/);\n  if (videoChunk) {\n    const trackId = parseInt(videoChunk[1], 10);\n    const strh = getStrhForIndex(state.structure.getRiffStructure(), trackId);\n    const samplesPerSecond = strh.rate / strh.scale;\n    const data = iterator.getSlice(ckSize);\n    const infos = parseAvc(data, state.avc);\n    const keyOrDelta = getKeyFrameOrDeltaFromAvcInfo(infos);\n    const info = infos.find((i) => i.type === \"keyframe\" || i.type === \"delta-frame\");\n    const avcProfile = infos.find((i) => i.type === \"avc-profile\");\n    const ppsProfile = infos.find((i) => i.type === \"avc-pps\");\n    if (avcProfile && ppsProfile && !state.riff.getAvcProfile()) {\n      await state.riff.onProfile({ pps: ppsProfile, sps: avcProfile });\n      state.callbacks.tracks.setIsDone(state.logLevel);\n    }\n    const rawSample = {\n      data,\n      duration: 1 / samplesPerSecond,\n      type: keyOrDelta === \"bidirectional\" ? \"delta\" : keyOrDelta,\n      offset,\n      avc: info\n    };\n    const maxFramesInBuffer = state.avc.getMaxFramesInBuffer();\n    if (maxFramesInBuffer === null) {\n      throw new Error(\"maxFramesInBuffer is null\");\n    }\n    if ((info?.poc ?? null) === null) {\n      throw new Error(\"poc is null\");\n    }\n    const keyframeOffset = state.riff.sampleCounter.getKeyframeAtOffset(rawSample);\n    if (keyframeOffset !== null) {\n      state.riff.sampleCounter.setPocAtKeyframeOffset({\n        keyframeOffset,\n        poc: info.poc\n      });\n    }\n    state.riff.queuedBFrames.addFrame({\n      frame: rawSample,\n      trackId,\n      maxFramesInBuffer,\n      timescale: samplesPerSecond\n    });\n    const releasedFrame = state.riff.queuedBFrames.getReleasedFrame();\n    if (!releasedFrame) {\n      return;\n    }\n    const videoSample = convertQueuedSampleToMediaParserSample({\n      sample: releasedFrame.sample,\n      state,\n      trackId: releasedFrame.trackId\n    });\n    state.riff.sampleCounter.onVideoSample({\n      trackId,\n      videoSample\n    });\n    await state.callbacks.onVideoSample({\n      videoSample,\n      trackId\n    });\n  }\n  const audioChunk = ckId.match(/^([0-9]{2})wb$/);\n  if (audioChunk) {\n    const trackId = parseInt(audioChunk[1], 10);\n    const strh = getStrhForIndex(state.structure.getRiffStructure(), trackId);\n    const { strf } = strh;\n    if (strf.type !== \"strf-box-audio\") {\n      throw new Error(\"audio\");\n    }\n    const samplesPerSecond = strh.rate / strh.scale * strf.numberOfChannels;\n    const nthSample = state.riff.sampleCounter.getSampleCountForTrack({\n      trackId\n    });\n    const timeInSec = nthSample / samplesPerSecond;\n    const timestamp = Math.floor(timeInSec * WEBCODECS_TIMESCALE);\n    const data = iterator.getSlice(ckSize);\n    const audioSample = {\n      decodingTimestamp: timestamp,\n      data,\n      duration: undefined,\n      timestamp,\n      type: \"key\",\n      offset\n    };\n    state.riff.sampleCounter.onAudioSample(trackId, audioSample);\n    await state.callbacks.onAudioSample({\n      audioSample,\n      trackId\n    });\n  }\n};\nvar parseMovi = async ({\n  state\n}) => {\n  const { iterator } = state;\n  if (iterator.bytesRemaining() < 8) {\n    return Promise.resolve();\n  }\n  const checkpoint = iterator.startCheckpoint();\n  const ckId = iterator.getByteString(4, false);\n  const ckSize = iterator.getUint32Le();\n  if (iterator.bytesRemaining() < ckSize) {\n    checkpoint.returnToCheckpoint();\n    return Promise.resolve();\n  }\n  await handleChunk({ state, ckId, ckSize });\n  const mediaSection = state.mediaSection.getMediaSectionAssertOnlyOne();\n  const maxOffset = mediaSection.start + mediaSection.size;\n  while (iterator.counter.getOffset() < maxOffset && iterator.bytesRemaining() > 0) {\n    if (iterator.getUint8() !== 0) {\n      iterator.counter.decrement(1);\n      break;\n    }\n  }\n};\n\n// src/containers/riff/parse-video-section.ts\nvar parseMediaSection = async (state) => {\n  await parseMovi({\n    state\n  });\n  const tracks2 = getTracks(state, false);\n  if (!tracks2.some((t) => t.type === \"video\" && t.codec === TO_BE_OVERRIDDEN_LATER) && !state.callbacks.tracks.getIsDone()) {\n    state.callbacks.tracks.setIsDone(state.logLevel);\n  }\n};\n\n// src/containers/riff/parse-riff-body.ts\nvar parseRiffBody = async (state) => {\n  const releasedFrame = state.riff.queuedBFrames.getReleasedFrame();\n  if (releasedFrame) {\n    const converted = convertQueuedSampleToMediaParserSample({\n      sample: releasedFrame.sample,\n      state,\n      trackId: releasedFrame.trackId\n    });\n    state.riff.sampleCounter.onVideoSample({\n      trackId: releasedFrame.trackId,\n      videoSample: converted\n    });\n    await state.callbacks.onVideoSample({\n      videoSample: converted,\n      trackId: releasedFrame.trackId\n    });\n    return null;\n  }\n  if (state.mediaSection.isCurrentByteInMediaSection(state.iterator) === \"in-section\") {\n    if (maySkipVideoData({\n      state\n    }) && state.riff.getAvcProfile()) {\n      const mediaSection = getCurrentMediaSection({\n        offset: state.iterator.counter.getOffset(),\n        mediaSections: state.mediaSection.getMediaSections()\n      });\n      if (!mediaSection) {\n        throw new Error(\"No video section defined\");\n      }\n      return Promise.resolve(makeSkip(mediaSection.start + mediaSection.size));\n    }\n    await parseMediaSection(state);\n    return null;\n  }\n  const box = await expectRiffBox({\n    iterator: state.iterator,\n    stateIfExpectingSideEffects: state\n  });\n  if (box !== null) {\n    await postProcessRiffBox(state, box);\n    const structure = state.structure.getRiffStructure();\n    structure.boxes.push(box);\n  }\n  return null;\n};\n\n// src/containers/riff/parse-riff-header.ts\nvar parseRiffHeader = (state) => {\n  const riff = state.iterator.getByteString(4, false);\n  if (riff !== \"RIFF\") {\n    throw new Error(\"Not a RIFF file\");\n  }\n  const structure = state.structure.getRiffStructure();\n  const size = state.iterator.getUint32Le();\n  const fileType = state.iterator.getByteString(4, false);\n  if (fileType !== \"WAVE\" && fileType !== \"AVI\") {\n    throw new Error(`File type ${fileType} not supported`);\n  }\n  structure.boxes.push({ type: \"riff-header\", fileSize: size, fileType });\n  return null;\n};\n\n// src/containers/riff/parse-riff.ts\nvar parseRiff = (state) => {\n  if (state.iterator.counter.getOffset() === 0) {\n    return Promise.resolve(parseRiffHeader(state));\n  }\n  return parseRiffBody(state);\n};\n\n// src/containers/transport-stream/discard-rest-of-packet.ts\nvar discardRestOfPacket = (iterator) => {\n  const next188 = 188 - iterator.counter.getOffset() % 188;\n  iterator.discard(next188);\n};\nvar getRestOfPacket = (iterator) => {\n  const next188 = 188 - iterator.counter.getOffset() % 188;\n  return iterator.getSlice(next188);\n};\n\n// src/containers/transport-stream/parse-pat.ts\nvar parsePatTable = (iterator, tableId) => {\n  iterator.getUint16();\n  iterator.startReadingBits();\n  iterator.getBits(7);\n  iterator.getBits(1);\n  const sectionNumber = iterator.getBits(8);\n  const lastSectionNumber = iterator.getBits(8);\n  if (tableId !== 0) {\n    throw new Error(\"Invalid table ID: \" + tableId);\n  }\n  const tables = [];\n  for (let i = sectionNumber;i <= lastSectionNumber; i++) {\n    const programNumber = iterator.getBits(16);\n    iterator.getBits(3);\n    const programMapIdentifier = iterator.getBits(13);\n    tables.push({\n      type: \"transport-stream-program-association-table\",\n      programNumber,\n      programMapIdentifier\n    });\n  }\n  iterator.stopReadingBits();\n  return {\n    type: \"transport-stream-pat-box\",\n    tableId: tableId.toString(16),\n    pat: tables\n  };\n};\nvar parsePat = (iterator) => {\n  iterator.startReadingBits();\n  const tableId = iterator.getBits(8);\n  iterator.getBits(1);\n  iterator.getBits(1);\n  iterator.getBits(4);\n  const sectionLength = iterator.getBits(10);\n  if (sectionLength > 1021) {\n    throw new Error(\"Invalid section length\");\n  }\n  iterator.stopReadingBits();\n  const tables = parsePatTable(iterator, tableId);\n  discardRestOfPacket(iterator);\n  return tables;\n};\nvar parseSdt = (iterator) => {\n  iterator.startReadingBits();\n  iterator.getBits(8);\n  iterator.getBits(1);\n  iterator.getBits(1);\n  iterator.getBits(2);\n  const sectionLength = iterator.getBits(12);\n  iterator.stopReadingBits();\n  iterator.discard(sectionLength);\n  discardRestOfPacket(iterator);\n  return {\n    type: \"transport-stream-sdt-box\"\n  };\n};\n\n// src/containers/transport-stream/parse-pes.ts\nvar parsePes = ({\n  iterator,\n  offset\n}) => {\n  const ident = iterator.getUint24();\n  if (ident !== 1) {\n    throw new Error(`Unexpected PES packet start code: ${ident.toString(16)}`);\n  }\n  const streamId = iterator.getUint8();\n  iterator.getUint16();\n  iterator.startReadingBits();\n  const markerBits = iterator.getBits(2);\n  if (markerBits !== 2) {\n    throw new Error(`Invalid marker bits: ${markerBits}`);\n  }\n  const scrambled = iterator.getBits(2);\n  if (scrambled !== 0) {\n    throw new Error(`Only supporting non-scrambled streams`);\n  }\n  const priority = iterator.getBits(1);\n  iterator.getBits(1);\n  iterator.getBits(1);\n  iterator.getBits(1);\n  const ptsPresent = iterator.getBits(1);\n  const dtsPresent = iterator.getBits(1);\n  if (!ptsPresent && dtsPresent) {\n    throw new Error(`DTS is present but not PTS, this is not allowed in the spec`);\n  }\n  iterator.getBits(1);\n  iterator.getBits(1);\n  iterator.getBits(1);\n  iterator.getBits(1);\n  iterator.getBits(1);\n  iterator.getBits(1);\n  const pesHeaderLength = iterator.getBits(8);\n  const offsetAfterHeader = iterator.counter.getOffset();\n  let pts = null;\n  if (!ptsPresent) {\n    throw new Error(`PTS is required`);\n  }\n  const fourBits = iterator.getBits(4);\n  if (fourBits !== 3 && fourBits !== 2) {\n    throw new Error(`Invalid PTS marker bits: ${fourBits}`);\n  }\n  const pts1 = iterator.getBits(3);\n  iterator.getBits(1);\n  const pts2 = iterator.getBits(15);\n  iterator.getBits(1);\n  const pts3 = iterator.getBits(15);\n  iterator.getBits(1);\n  pts = pts1 << 30 | pts2 << 15 | pts3;\n  let dts = null;\n  if (dtsPresent) {\n    const _fourBits = iterator.getBits(4);\n    if (_fourBits !== 1) {\n      throw new Error(`Invalid DTS marker bits: ${_fourBits}`);\n    }\n    const dts1 = iterator.getBits(3);\n    iterator.getBits(1);\n    const dts2 = iterator.getBits(15);\n    iterator.getBits(1);\n    const dts3 = iterator.getBits(15);\n    iterator.getBits(1);\n    dts = dts1 << 30 | dts2 << 15 | dts3;\n  }\n  iterator.stopReadingBits();\n  iterator.discard(pesHeaderLength - (iterator.counter.getOffset() - offsetAfterHeader));\n  const packet = {\n    dts,\n    pts,\n    streamId,\n    priority,\n    offset\n  };\n  return packet;\n};\n\n// src/containers/transport-stream/parse-pmt.ts\nvar parsePmtTable = ({\n  iterator,\n  tableId,\n  sectionLength\n}) => {\n  const start = iterator.counter.getOffset();\n  iterator.getUint16();\n  iterator.startReadingBits();\n  iterator.getBits(7);\n  iterator.getBits(1);\n  const sectionNumber = iterator.getBits(8);\n  const lastSectionNumber = iterator.getBits(8);\n  const tables = [];\n  iterator.getBits(3);\n  iterator.getBits(13);\n  iterator.getBits(4);\n  const programInfoLength = iterator.getBits(12);\n  iterator.getBits(programInfoLength * 8);\n  for (let i = sectionNumber;i <= lastSectionNumber; i++) {\n    const streams = [];\n    while (true) {\n      const streamType = iterator.getBits(8);\n      iterator.getBits(3);\n      const elementaryPid = iterator.getBits(13);\n      iterator.getBits(4);\n      const esInfoLength = iterator.getBits(12);\n      iterator.getBits(esInfoLength * 8);\n      streams.push({ streamType, pid: elementaryPid });\n      const remaining = sectionLength - (iterator.counter.getOffset() - start);\n      if (remaining <= 4) {\n        break;\n      }\n    }\n    tables.push({\n      type: \"transport-stream-program-map-table\",\n      streams\n    });\n  }\n  if (tables.length !== 1) {\n    throw new Error(\"Does not PMT table with more than 1 entry, uncommon\");\n  }\n  iterator.stopReadingBits();\n  return {\n    type: \"transport-stream-pmt-box\",\n    tableId,\n    streams: tables[0].streams\n  };\n};\nvar parsePmt = (iterator) => {\n  iterator.startReadingBits();\n  const tableId = iterator.getBits(8);\n  iterator.getBits(1);\n  iterator.getBits(1);\n  iterator.getBits(4);\n  const sectionLength = iterator.getBits(10);\n  if (sectionLength > 1021) {\n    throw new Error(\"Invalid section length\");\n  }\n  iterator.stopReadingBits();\n  const tables = parsePmtTable({ iterator, tableId, sectionLength });\n  discardRestOfPacket(iterator);\n  return tables;\n};\n\n// src/containers/transport-stream/find-separator.ts\nfunction findNthSubarrayIndex({\n  array,\n  subarray,\n  n,\n  startIndex,\n  startCount\n}) {\n  const subarrayLength = subarray.length;\n  const arrayLength = array.length;\n  let count = startCount;\n  let i = startIndex;\n  for (i;i <= arrayLength - subarrayLength; i++) {\n    let match = true;\n    for (let j = 0;j < subarrayLength; j++) {\n      if (array[i + j] !== subarray[j]) {\n        match = false;\n        break;\n      }\n    }\n    if (match) {\n      count++;\n      if (count === n) {\n        return { type: \"found\", index: i };\n      }\n    }\n  }\n  return { type: \"not-found\", index: i, count };\n}\n\n// src/containers/transport-stream/adts-header.ts\nvar readAdtsHeader = (buffer) => {\n  if (buffer.byteLength < 9) {\n    return null;\n  }\n  const iterator = getArrayBufferIterator({\n    initialData: buffer,\n    maxBytes: buffer.byteLength,\n    logLevel: \"error\"\n  });\n  iterator.startReadingBits();\n  const bits = iterator.getBits(12);\n  if (bits !== 4095) {\n    throw new Error(\"Invalid ADTS header \");\n  }\n  const id = iterator.getBits(1);\n  if (id !== 0) {\n    throw new Error(\"Only supporting MPEG-4 for .ts\");\n  }\n  const layer = iterator.getBits(2);\n  if (layer !== 0) {\n    throw new Error(\"Only supporting layer 0 for .ts\");\n  }\n  const protectionAbsent = iterator.getBits(1);\n  const audioObjectType = iterator.getBits(2);\n  const samplingFrequencyIndex = iterator.getBits(4);\n  const sampleRate = getSampleRateFromSampleFrequencyIndex(samplingFrequencyIndex);\n  iterator.getBits(1);\n  const channelConfiguration = iterator.getBits(3);\n  const codecPrivate2 = createAacCodecPrivate({\n    audioObjectType,\n    sampleRate,\n    channelConfiguration,\n    codecPrivate: null\n  });\n  iterator.getBits(1);\n  iterator.getBits(1);\n  iterator.getBits(1);\n  iterator.getBits(1);\n  const frameLength = iterator.getBits(13);\n  iterator.getBits(11);\n  iterator.getBits(2);\n  if (!protectionAbsent) {\n    iterator.getBits(16);\n  }\n  iterator.stopReadingBits();\n  iterator.destroy();\n  return {\n    frameLength,\n    codecPrivate: codecPrivate2,\n    channelConfiguration,\n    sampleRate,\n    audioObjectType\n  };\n};\n\n// src/containers/transport-stream/handle-aac-packet.ts\nvar handleAacPacket = async ({\n  streamBuffer,\n  programId,\n  offset,\n  sampleCallbacks,\n  logLevel,\n  onAudioTrack,\n  transportStream,\n  makeSamplesStartAtZero\n}) => {\n  const adtsHeader = readAdtsHeader(streamBuffer.getBuffer());\n  if (!adtsHeader) {\n    throw new Error(\"Invalid ADTS header - too short\");\n  }\n  const { channelConfiguration, codecPrivate: codecPrivate2, sampleRate, audioObjectType } = adtsHeader;\n  const isTrackRegistered = sampleCallbacks.tracks.getTracks().find((t) => {\n    return t.trackId === programId;\n  });\n  if (!isTrackRegistered) {\n    const startOffset = makeSamplesStartAtZero ? Math.min(streamBuffer.pesHeader.pts, streamBuffer.pesHeader.dts ?? Infinity) : 0;\n    transportStream.startOffset.setOffset({\n      trackId: programId,\n      newOffset: startOffset\n    });\n    const track = {\n      type: \"audio\",\n      codecData: { type: \"aac-config\", data: codecPrivate2 },\n      trackId: programId,\n      originalTimescale: MPEG_TIMESCALE,\n      codecEnum: \"aac\",\n      codec: mapAudioObjectTypeToCodecString(audioObjectType),\n      description: codecPrivate2,\n      numberOfChannels: channelConfiguration,\n      sampleRate,\n      startInSeconds: 0,\n      timescale: WEBCODECS_TIMESCALE\n    };\n    await registerAudioTrack({\n      track,\n      container: \"transport-stream\",\n      registerAudioSampleCallback: sampleCallbacks.registerAudioSampleCallback,\n      tracks: sampleCallbacks.tracks,\n      logLevel,\n      onAudioTrack\n    });\n  }\n  const sample = {\n    decodingTimestamp: (streamBuffer.pesHeader.dts ?? streamBuffer.pesHeader.pts) - transportStream.startOffset.getOffset(programId),\n    timestamp: streamBuffer.pesHeader.pts - transportStream.startOffset.getOffset(programId),\n    duration: undefined,\n    data: streamBuffer.getBuffer(),\n    type: \"key\",\n    offset\n  };\n  const audioSample = convertAudioOrVideoSampleToWebCodecsTimestamps({\n    sample,\n    timescale: MPEG_TIMESCALE\n  });\n  await sampleCallbacks.onAudioSample({\n    audioSample,\n    trackId: programId\n  });\n  transportStream.lastEmittedSample.setLastEmittedSample(sample);\n};\n\n// src/containers/transport-stream/process-stream-buffers.ts\nvar makeTransportStreamPacketBuffer = ({\n  buffers,\n  pesHeader,\n  offset\n}) => {\n  let currentBuf = buffers ? [buffers] : [];\n  let subarrayIndex = null;\n  const getBuffer = () => {\n    if (currentBuf.length === 0) {\n      return new Uint8Array;\n    }\n    if (currentBuf.length === 1) {\n      return currentBuf[0];\n    }\n    currentBuf = [combineUint8Arrays(currentBuf)];\n    return currentBuf[0];\n  };\n  let fastFind = null;\n  return {\n    pesHeader,\n    offset,\n    getBuffer,\n    addBuffer: (buffer) => {\n      currentBuf.push(buffer);\n      subarrayIndex = null;\n    },\n    get2ndSubArrayIndex: () => {\n      if (subarrayIndex === null) {\n        const result = findNthSubarrayIndex({\n          array: getBuffer(),\n          subarray: new Uint8Array([0, 0, 1, 9]),\n          n: 2,\n          startIndex: fastFind?.index ?? 0,\n          startCount: fastFind?.count ?? 0\n        });\n        if (result.type === \"found\") {\n          subarrayIndex = result.index;\n          fastFind = null;\n        } else {\n          fastFind = result;\n          return -1;\n        }\n      }\n      return subarrayIndex;\n    }\n  };\n};\nvar processStreamBuffer = async ({\n  streamBuffer,\n  programId,\n  structure,\n  sampleCallbacks,\n  logLevel,\n  onAudioTrack,\n  onVideoTrack,\n  transportStream,\n  makeSamplesStartAtZero,\n  avcState\n}) => {\n  const stream = getStreamForId(structure, programId);\n  if (!stream) {\n    throw new Error(\"No stream found\");\n  }\n  if (stream.streamType === 2) {\n    throw new Error(\"H.262 video stream not supported\");\n  }\n  if (stream.streamType === 27) {\n    await handleAvcPacket({\n      programId,\n      streamBuffer,\n      sampleCallbacks,\n      logLevel,\n      onVideoTrack,\n      offset: streamBuffer.offset,\n      transportStream,\n      makeSamplesStartAtZero,\n      avcState\n    });\n  } else if (stream.streamType === 15) {\n    await handleAacPacket({\n      streamBuffer,\n      programId,\n      offset: streamBuffer.offset,\n      sampleCallbacks,\n      logLevel,\n      onAudioTrack,\n      transportStream,\n      makeSamplesStartAtZero\n    });\n  }\n  if (!sampleCallbacks.tracks.hasAllTracks()) {\n    const tracksRegistered = sampleCallbacks.tracks.getTracks().length;\n    const { streams } = findProgramMapTableOrThrow(structure);\n    if (filterStreamsBySupportedTypes(streams).length === tracksRegistered) {\n      sampleCallbacks.tracks.setIsDone(logLevel);\n    }\n  }\n};\nvar processFinalStreamBuffers = async ({\n  structure,\n  sampleCallbacks,\n  logLevel,\n  onAudioTrack,\n  onVideoTrack,\n  transportStream,\n  makeSamplesStartAtZero,\n  avcState\n}) => {\n  for (const [programId, buffer] of transportStream.streamBuffers) {\n    if (buffer.getBuffer().byteLength > 0) {\n      await processStreamBuffer({\n        streamBuffer: buffer,\n        programId,\n        structure,\n        sampleCallbacks,\n        logLevel,\n        onAudioTrack,\n        onVideoTrack,\n        transportStream,\n        makeSamplesStartAtZero,\n        avcState\n      });\n      transportStream.streamBuffers.delete(programId);\n    }\n  }\n};\n\n// src/containers/transport-stream/parse-stream-packet.ts\nvar parseStream = ({\n  transportStreamEntry,\n  programId,\n  iterator,\n  transportStream\n}) => {\n  const restOfPacket = getRestOfPacket(iterator);\n  const offset = iterator.counter.getOffset();\n  const { streamBuffers, nextPesHeaderStore: nextPesHeader } = transportStream;\n  if (!streamBuffers.has(transportStreamEntry.pid)) {\n    streamBuffers.set(programId, makeTransportStreamPacketBuffer({\n      pesHeader: nextPesHeader.getNextPesHeader(),\n      buffers: null,\n      offset\n    }));\n  }\n  const streamBuffer = streamBuffers.get(transportStreamEntry.pid);\n  streamBuffer.addBuffer(restOfPacket);\n};\n\n// src/containers/transport-stream/parse-packet.ts\nvar parsePacket = ({\n  iterator,\n  structure,\n  transportStream\n}) => {\n  const offset = iterator.counter.getOffset();\n  const syncByte = iterator.getUint8();\n  if (syncByte !== 71) {\n    throw new Error(\"Invalid sync byte\");\n  }\n  iterator.startReadingBits();\n  iterator.getBits(1);\n  const payloadUnitStartIndicator = iterator.getBits(1);\n  iterator.getBits(1);\n  const programId = iterator.getBits(13);\n  iterator.getBits(2);\n  const adaptationFieldControl1 = iterator.getBits(1);\n  iterator.getBits(1);\n  iterator.getBits(4);\n  iterator.stopReadingBits();\n  if (adaptationFieldControl1 === 1) {\n    iterator.startReadingBits();\n    const adaptationFieldLength = iterator.getBits(8);\n    const headerOffset = iterator.counter.getOffset();\n    if (adaptationFieldLength > 0) {\n      iterator.getBits(1);\n      iterator.getBits(1);\n      iterator.getBits(1);\n      iterator.getBits(1);\n      iterator.getBits(1);\n      iterator.getBits(1);\n      iterator.getBits(1);\n      iterator.getBits(1);\n    }\n    const remaining = adaptationFieldLength - (iterator.counter.getOffset() - headerOffset);\n    iterator.stopReadingBits();\n    const toDiscard = Math.max(0, remaining);\n    iterator.discard(toDiscard);\n  }\n  const read = iterator.counter.getOffset() - offset;\n  if (read === 188) {\n    return null;\n  }\n  const pat = structure.boxes.find((b) => b.type === \"transport-stream-pmt-box\");\n  const isPes = payloadUnitStartIndicator && pat?.streams.find((e) => e.pid === programId);\n  if (isPes) {\n    const packetPes = parsePes({ iterator, offset });\n    transportStream.nextPesHeaderStore.setNextPesHeader(packetPes);\n    transportStream.observedPesHeaders.addPesHeader(packetPes);\n  } else if (payloadUnitStartIndicator === 1) {\n    iterator.getUint8();\n  }\n  if (programId === 0) {\n    return parsePat(iterator);\n  }\n  if (programId === 17) {\n    return parseSdt(iterator);\n  }\n  const program = programId === 17 ? null : getProgramForId(structure, programId);\n  if (program) {\n    const pmt = parsePmt(iterator);\n    return pmt;\n  }\n  const transportStreamEntry = getStreamForId(structure, programId);\n  if (transportStreamEntry) {\n    parseStream({\n      transportStreamEntry,\n      iterator,\n      transportStream,\n      programId\n    });\n    return null;\n  }\n  throw new Error(\"Unknown packet identifier\");\n};\n\n// src/containers/transport-stream/process-audio.ts\nvar canProcessAudio = ({\n  streamBuffer\n}) => {\n  const expectedLength = readAdtsHeader(streamBuffer.getBuffer())?.frameLength ?? null;\n  if (expectedLength === null) {\n    return false;\n  }\n  if (expectedLength > streamBuffer.getBuffer().length) {\n    return false;\n  }\n  return true;\n};\nvar processAudio = async ({\n  transportStreamEntry,\n  structure,\n  offset,\n  sampleCallbacks,\n  logLevel,\n  onAudioTrack,\n  onVideoTrack,\n  transportStream,\n  makeSamplesStartAtZero,\n  avcState\n}) => {\n  const { streamBuffers, nextPesHeaderStore: nextPesHeader } = transportStream;\n  const streamBuffer = streamBuffers.get(transportStreamEntry.pid);\n  if (!streamBuffer) {\n    throw new Error(\"Stream buffer not found\");\n  }\n  const expectedLength = readAdtsHeader(streamBuffer.getBuffer())?.frameLength ?? null;\n  if (expectedLength === null) {\n    throw new Error(\"Expected length is null\");\n  }\n  if (expectedLength > streamBuffer.getBuffer().length) {\n    throw new Error(\"Expected length is greater than stream buffer length\");\n  }\n  await processStreamBuffer({\n    streamBuffer: makeTransportStreamPacketBuffer({\n      buffers: streamBuffer.getBuffer().slice(0, expectedLength),\n      offset,\n      pesHeader: streamBuffer.pesHeader\n    }),\n    programId: transportStreamEntry.pid,\n    structure,\n    sampleCallbacks,\n    logLevel,\n    onAudioTrack,\n    onVideoTrack,\n    transportStream,\n    makeSamplesStartAtZero,\n    avcState\n  });\n  const rest = streamBuffer.getBuffer().slice(expectedLength);\n  streamBuffers.set(transportStreamEntry.pid, makeTransportStreamPacketBuffer({\n    buffers: rest,\n    pesHeader: nextPesHeader.getNextPesHeader(),\n    offset\n  }));\n};\n\n// src/containers/transport-stream/process-video.ts\nvar canProcessVideo = ({\n  streamBuffer\n}) => {\n  const indexOfSeparator = streamBuffer.get2ndSubArrayIndex();\n  if (indexOfSeparator === -1 || indexOfSeparator === 0) {\n    return false;\n  }\n  return true;\n};\nvar processVideo = async ({\n  programId,\n  structure,\n  streamBuffer,\n  sampleCallbacks,\n  logLevel,\n  onAudioTrack,\n  onVideoTrack,\n  transportStream,\n  makeSamplesStartAtZero,\n  avcState\n}) => {\n  const indexOfSeparator = streamBuffer.get2ndSubArrayIndex();\n  if (indexOfSeparator === -1 || indexOfSeparator === 0) {\n    throw new Error(\"cannot process avc stream\");\n  }\n  const buf = streamBuffer.getBuffer();\n  const packet = buf.slice(0, indexOfSeparator);\n  const rest = buf.slice(indexOfSeparator);\n  await processStreamBuffer({\n    streamBuffer: makeTransportStreamPacketBuffer({\n      offset: streamBuffer.offset,\n      pesHeader: streamBuffer.pesHeader,\n      buffers: packet\n    }),\n    programId,\n    structure,\n    sampleCallbacks,\n    logLevel,\n    onAudioTrack,\n    onVideoTrack,\n    transportStream,\n    makeSamplesStartAtZero,\n    avcState\n  });\n  return rest;\n};\n\n// src/containers/transport-stream/process-sample-if-possible.ts\nvar processSampleIfPossible = async (state) => {\n  const programMap = findProgramMapOrNull(state.structure.getTsStructure());\n  if (!programMap) {\n    return;\n  }\n  let processed = false;\n  for (const stream of programMap.streams) {\n    const streamBuffer = state.transportStream.streamBuffers.get(stream.pid);\n    if (!streamBuffer) {\n      continue;\n    }\n    if (stream.streamType === 27) {\n      if (canProcessVideo({ streamBuffer })) {\n        const rest = await processVideo({\n          programId: stream.pid,\n          structure: state.structure.getTsStructure(),\n          streamBuffer,\n          sampleCallbacks: state.callbacks,\n          logLevel: state.logLevel,\n          onAudioTrack: state.onAudioTrack,\n          onVideoTrack: state.onVideoTrack,\n          transportStream: state.transportStream,\n          makeSamplesStartAtZero: state.makeSamplesStartAtZero,\n          avcState: state.avc\n        });\n        state.transportStream.streamBuffers.delete(stream.pid);\n        state.transportStream.streamBuffers.set(stream.pid, makeTransportStreamPacketBuffer({\n          pesHeader: state.transportStream.nextPesHeaderStore.getNextPesHeader(),\n          buffers: rest,\n          offset: state.iterator.counter.getOffset()\n        }));\n        processed = true;\n        break;\n      }\n    }\n    if (stream.streamType === 15) {\n      if (canProcessAudio({ streamBuffer })) {\n        await processAudio({\n          structure: state.structure.getTsStructure(),\n          offset: state.iterator.counter.getOffset(),\n          sampleCallbacks: state.callbacks,\n          logLevel: state.logLevel,\n          onAudioTrack: state.onAudioTrack,\n          onVideoTrack: state.onVideoTrack,\n          transportStream: state.transportStream,\n          makeSamplesStartAtZero: state.makeSamplesStartAtZero,\n          transportStreamEntry: stream,\n          avcState: state.avc\n        });\n        processed = true;\n        break;\n      }\n    }\n  }\n  return processed;\n};\n\n// src/containers/transport-stream/parse-transport-stream.ts\nvar parseTransportStream = async (state) => {\n  const structure = state.structure.getTsStructure();\n  const processed = await processSampleIfPossible(state);\n  if (processed) {\n    return Promise.resolve(null);\n  }\n  const { iterator } = state;\n  if (iterator.bytesRemaining() < 188) {\n    return Promise.resolve(null);\n  }\n  const packet = parsePacket({\n    iterator,\n    structure,\n    transportStream: state.transportStream\n  });\n  if (packet) {\n    structure.boxes.push(packet);\n  }\n  if (iterator.bytesRemaining() === 0) {\n    await processFinalStreamBuffers({\n      transportStream: state.transportStream,\n      structure,\n      sampleCallbacks: state.callbacks,\n      logLevel: state.logLevel,\n      onAudioTrack: state.onAudioTrack,\n      onVideoTrack: state.onVideoTrack,\n      makeSamplesStartAtZero: state.makeSamplesStartAtZero,\n      avcState: state.avc\n    });\n  }\n  return Promise.resolve(null);\n};\n\n// src/containers/wav/parse-data.ts\nvar parseData = ({\n  state\n}) => {\n  const { iterator } = state;\n  const ckSize = iterator.getUint32Le();\n  const box = {\n    type: \"wav-data\",\n    dataSize: ckSize\n  };\n  state.structure.getWavStructure().boxes.push(box);\n  state.callbacks.tracks.setIsDone(state.logLevel);\n  state.mediaSection.addMediaSection({\n    size: ckSize,\n    start: iterator.counter.getOffset()\n  });\n  if (maySkipVideoData({ state })) {\n    return Promise.resolve(makeSkip(iterator.counter.getOffset() + ckSize));\n  }\n  return Promise.resolve(null);\n};\n\n// src/containers/wav/parse-fact.ts\nvar parseFact = ({\n  state\n}) => {\n  const { iterator } = state;\n  const size = iterator.getUint32Le();\n  if (size !== 4) {\n    throw new Error(`Expected size 4 for fact box, got ${size}`);\n  }\n  const numberOfSamplesPerChannel = iterator.getUint32Le();\n  const factBox = {\n    type: \"wav-fact\",\n    numberOfSamplesPerChannel\n  };\n  state.structure.getWavStructure().boxes.push(factBox);\n  return Promise.resolve(null);\n};\n\n// src/containers/wav/subformats.ts\nvar WMMEDIASUBTYPE_PCM = [\n  1,\n  0,\n  0,\n  0,\n  0,\n  0,\n  16,\n  0,\n  128,\n  0,\n  0,\n  170,\n  0,\n  56,\n  155,\n  113\n];\nvar KSDATAFORMAT_SUBTYPE_IEEE_FLOAT = [\n  3,\n  0,\n  0,\n  0,\n  0,\n  0,\n  16,\n  0,\n  128,\n  0,\n  0,\n  170,\n  0,\n  56,\n  155,\n  113\n];\nvar subformatIsPcm = (subformat) => {\n  return subformat.every((value, index) => value === WMMEDIASUBTYPE_PCM[index]);\n};\nvar subformatIsIeeeFloat = (subformat) => {\n  return subformat.every((value, index) => value === KSDATAFORMAT_SUBTYPE_IEEE_FLOAT[index]);\n};\n\n// src/containers/wav/parse-fmt.ts\nvar CHANNELS = {\n  0: \"Front Left\",\n  1: \"Front Right\",\n  2: \"Front Center\",\n  3: \"Low Frequency\",\n  4: \"Back Left\",\n  5: \"Back Right\",\n  6: \"Front Left of Center\",\n  7: \"Front Right of Center\",\n  8: \"Back Center\",\n  9: \"Side Left\",\n  10: \"Side Right\",\n  11: \"Top Center\",\n  12: \"Top Front Left\",\n  13: \"Top Front Center\",\n  14: \"Top Front Right\",\n  15: \"Top Back Left\",\n  16: \"Top Back Center\",\n  17: \"Top Back Right\"\n};\nfunction getChannelsFromMask(channelMask) {\n  const channels2 = [];\n  for (let bit = 0;bit < 18; bit++) {\n    if ((channelMask & 1 << bit) !== 0) {\n      const channelName = CHANNELS[bit];\n      if (channelName) {\n        channels2.push(channelName);\n      } else {\n        channels2.push(`Unknown Channel (bit ${bit})`);\n      }\n    }\n  }\n  return channels2;\n}\nvar parseFmt = async ({\n  state\n}) => {\n  const { iterator } = state;\n  const ckSize = iterator.getUint32Le();\n  const box = iterator.startBox(ckSize);\n  const audioFormat = iterator.getUint16Le();\n  if (audioFormat !== 1 && audioFormat !== 65534) {\n    throw new Error(`Only supporting WAVE with PCM audio format, but got ${audioFormat}`);\n  }\n  const numberOfChannels = iterator.getUint16Le();\n  const sampleRate = iterator.getUint32Le();\n  const byteRate = iterator.getUint32Le();\n  const blockAlign = iterator.getUint16Le();\n  const bitsPerSample = iterator.getUint16Le();\n  const format = bitsPerSample === 16 ? \"pcm-s16\" : bitsPerSample === 32 ? \"pcm-s32\" : bitsPerSample === 24 ? \"pcm-s24\" : null;\n  if (format === null) {\n    throw new Error(`Unsupported bits per sample: ${bitsPerSample}`);\n  }\n  const wavHeader = {\n    bitsPerSample,\n    blockAlign,\n    byteRate,\n    numberOfChannels,\n    sampleRate,\n    type: \"wav-fmt\"\n  };\n  state.structure.getWavStructure().boxes.push(wavHeader);\n  if (audioFormat === 65534) {\n    const extraSize = iterator.getUint16Le();\n    if (extraSize !== 22) {\n      throw new Error(`Only supporting WAVE with 22 extra bytes, but got ${extraSize} bytes extra size`);\n    }\n    iterator.getUint16Le();\n    const channelMask = iterator.getUint32Le();\n    const subFormat = iterator.getSlice(16);\n    if (subFormat.length !== 16) {\n      throw new Error(`Only supporting WAVE with PCM audio format, but got ${subFormat.length}`);\n    }\n    if (subformatIsPcm(subFormat)) {} else if (subformatIsIeeeFloat(subFormat)) {} else {\n      throw new Error(`Unsupported subformat: ${subFormat}`);\n    }\n    const channels2 = getChannelsFromMask(channelMask);\n    wavHeader.numberOfChannels = channels2.length;\n  }\n  await registerAudioTrack({\n    track: {\n      type: \"audio\",\n      codec: format,\n      codecData: null,\n      description: undefined,\n      codecEnum: format,\n      numberOfChannels,\n      sampleRate,\n      originalTimescale: 1e6,\n      trackId: 0,\n      startInSeconds: 0,\n      timescale: WEBCODECS_TIMESCALE\n    },\n    container: \"wav\",\n    registerAudioSampleCallback: state.callbacks.registerAudioSampleCallback,\n    tracks: state.callbacks.tracks,\n    logLevel: state.logLevel,\n    onAudioTrack: state.onAudioTrack\n  });\n  box.expectNoMoreBytes();\n  return Promise.resolve(null);\n};\n\n// src/containers/wav/parse-header.ts\nvar parseHeader = ({\n  state\n}) => {\n  const fileSize = state.iterator.getUint32Le();\n  const fileType = state.iterator.getByteString(4, false);\n  if (fileType !== \"WAVE\") {\n    throw new Error(`Expected WAVE, got ${fileType}`);\n  }\n  const header = {\n    type: \"wav-header\",\n    fileSize\n  };\n  state.structure.getWavStructure().boxes.push(header);\n  return Promise.resolve(null);\n};\n\n// src/containers/wav/parse-id3.ts\nvar parseId32 = ({\n  state\n}) => {\n  const { iterator } = state;\n  const id3Size = iterator.getUint32Le();\n  iterator.discard(id3Size);\n  const id3Box = {\n    type: \"wav-id3\"\n  };\n  state.structure.getWavStructure().boxes.push(id3Box);\n  return Promise.resolve(null);\n};\n\n// src/containers/wav/parse-junk.ts\nvar parseJunk = ({\n  state\n}) => {\n  const { iterator } = state;\n  const ckSize = iterator.getUint32Le();\n  Log.trace(state.logLevel, `Skipping JUNK chunk of size ${ckSize}`);\n  iterator.discard(ckSize);\n  return Promise.resolve(null);\n};\n\n// src/containers/wav/parse-list.ts\nvar parseList = ({\n  state\n}) => {\n  const { iterator } = state;\n  const ckSize = iterator.getUint32Le();\n  const box = iterator.startBox(ckSize);\n  const startOffset = iterator.counter.getOffset();\n  const type = iterator.getByteString(4, false);\n  if (type !== \"INFO\") {\n    throw new Error(`Only supporting LIST INFO, but got ${type}`);\n  }\n  const metadata = [];\n  const remainingBytes = () => ckSize - (iterator.counter.getOffset() - startOffset);\n  while (remainingBytes() > 0) {\n    const byte = iterator.getUint8();\n    if (byte === 0) {\n      continue;\n    }\n    iterator.counter.decrement(1);\n    const key = iterator.getByteString(4, false);\n    const size = iterator.getUint32Le();\n    const value = iterator.getByteString(size, true);\n    metadata.push({\n      key,\n      trackId: null,\n      value\n    });\n  }\n  const wavList = {\n    type: \"wav-list\",\n    metadata\n  };\n  state.structure.getWavStructure().boxes.push(wavList);\n  box.expectNoMoreBytes();\n  return Promise.resolve(null);\n};\n\n// src/containers/wav/parse-media-section.ts\nvar parseMediaSection2 = async ({\n  state\n}) => {\n  const { iterator } = state;\n  const structure = state.structure.getWavStructure();\n  const videoSection = state.mediaSection.getMediaSectionAssertOnlyOne();\n  const maxOffset = videoSection.start + videoSection.size;\n  const maxRead = maxOffset - iterator.counter.getOffset();\n  const offset = iterator.counter.getOffset();\n  const fmtBox = structure.boxes.find((box) => box.type === \"wav-fmt\");\n  if (!fmtBox) {\n    throw new Error(\"Expected fmt box\");\n  }\n  const toRead = Math.min(maxRead, fmtBox.sampleRate * fmtBox.blockAlign / WAVE_SAMPLES_PER_SECOND);\n  const duration2 = toRead / (fmtBox.sampleRate * fmtBox.blockAlign);\n  const timestamp = (offset - videoSection.start) / (fmtBox.sampleRate * fmtBox.blockAlign);\n  const data = iterator.getSlice(toRead);\n  const audioSample = convertAudioOrVideoSampleToWebCodecsTimestamps({\n    sample: {\n      decodingTimestamp: timestamp,\n      data,\n      duration: duration2,\n      timestamp,\n      type: \"key\",\n      offset\n    },\n    timescale: 1\n  });\n  await state.callbacks.onAudioSample({\n    audioSample,\n    trackId: 0\n  });\n  return null;\n};\n\n// src/containers/wav/parse-wav.ts\nvar parseWav = (state) => {\n  const { iterator } = state;\n  const insideMediaSection = state.mediaSection.isCurrentByteInMediaSection(iterator);\n  if (insideMediaSection === \"in-section\") {\n    return parseMediaSection2({ state });\n  }\n  const type = iterator.getByteString(4, false).toLowerCase();\n  Log.trace(state.logLevel, `Processing box type ${type}`);\n  if (type === \"riff\") {\n    return parseHeader({ state });\n  }\n  if (type === \"fmt\") {\n    return parseFmt({ state });\n  }\n  if (type === \"data\") {\n    return parseData({ state });\n  }\n  if (type === \"list\") {\n    return parseList({ state });\n  }\n  if (type === \"id3\") {\n    return parseId32({ state });\n  }\n  if (type === \"junk\" || type === \"fllr\") {\n    return parseJunk({ state });\n  }\n  if (type === \"fact\") {\n    return parseFact({ state });\n  }\n  if (type === \"\\x00\") {\n    return Promise.resolve(null);\n  }\n  throw new Error(`Unknown WAV box type ${type}`);\n};\n\n// src/containers/webm/get-byte-for-cues.ts\nvar getByteForSeek = ({\n  seekHeadSegment,\n  offset\n}) => {\n  const value = seekHeadSegment.value.map((v) => {\n    if (v.type !== \"Seek\") {\n      return null;\n    }\n    const seekId2 = v.value.find((_v) => {\n      return _v.type === \"SeekID\" && _v.value === matroskaElements.Cues;\n    });\n    if (!seekId2) {\n      return null;\n    }\n    const seekPosition2 = v.value.find((_v) => {\n      return _v.type === \"SeekPosition\";\n    });\n    if (!seekPosition2) {\n      return false;\n    }\n    return seekPosition2.value;\n  }).filter(truthy);\n  if (value.length === 0) {\n    return null;\n  }\n  return value[0].value + offset;\n};\n\n// src/containers/webm/segments/block-simple-block-flags.ts\nvar parseBlockFlags = (iterator, type) => {\n  if (type === matroskaElements.Block) {\n    iterator.startReadingBits();\n    iterator.getBits(4);\n    const invisible = Boolean(iterator.getBits(1));\n    const lacing = iterator.getBits(2);\n    iterator.getBits(1);\n    iterator.stopReadingBits();\n    return {\n      invisible,\n      lacing,\n      keyframe: null\n    };\n  }\n  if (type === matroskaElements.SimpleBlock) {\n    iterator.startReadingBits();\n    const keyframe = Boolean(iterator.getBits(1));\n    iterator.getBits(3);\n    const invisible = Boolean(iterator.getBits(1));\n    const lacing = iterator.getBits(2);\n    iterator.getBits(1);\n    iterator.stopReadingBits();\n    return {\n      invisible,\n      lacing,\n      keyframe\n    };\n  }\n  throw new Error(\"Unexpected type\");\n};\n\n// src/containers/webm/get-sample-from-block.ts\nvar addAvcToTrackAndActivateTrackIfNecessary = async ({\n  partialVideoSample,\n  codec,\n  structureState: structureState2,\n  webmState,\n  trackNumber: trackNumber2,\n  logLevel,\n  callbacks,\n  onVideoTrack,\n  avcState\n}) => {\n  if (codec !== \"V_MPEG4/ISO/AVC\") {\n    return;\n  }\n  const missingTracks = getTracksFromMatroska({\n    structureState: structureState2,\n    webmState\n  }).missingInfo;\n  if (missingTracks.length === 0) {\n    return;\n  }\n  const parsed = parseAvc(partialVideoSample.data, avcState);\n  for (const parse of parsed) {\n    if (parse.type === \"avc-profile\") {\n      webmState.setAvcProfileForTrackNumber(trackNumber2, parse);\n      const track = missingTracks.find((t) => t.trackId === trackNumber2);\n      if (!track) {\n        throw new Error(\"Could not find track \" + trackNumber2);\n      }\n      const resolvedTracks = getTracksFromMatroska({\n        structureState: structureState2,\n        webmState\n      }).resolved;\n      const resolvedTrack = resolvedTracks.find((t) => t.trackId === trackNumber2);\n      if (!resolvedTrack) {\n        throw new Error(\"Could not find track \" + trackNumber2);\n      }\n      await registerVideoTrack({\n        track: resolvedTrack,\n        container: \"webm\",\n        logLevel,\n        onVideoTrack,\n        registerVideoSampleCallback: callbacks.registerVideoSampleCallback,\n        tracks: callbacks.tracks\n      });\n    }\n  }\n};\nvar getSampleFromBlock = async ({\n  ebml,\n  webmState,\n  offset,\n  structureState: structureState2,\n  callbacks,\n  logLevel,\n  onVideoTrack,\n  avcState\n}) => {\n  const iterator = getArrayBufferIterator({\n    initialData: ebml.value,\n    maxBytes: ebml.value.length,\n    logLevel: \"error\"\n  });\n  const trackNumber2 = iterator.getVint();\n  if (trackNumber2 === null) {\n    throw new Error(\"Not enough data to get track number, should not happen\");\n  }\n  const timecodeRelativeToCluster = iterator.getInt16();\n  const { keyframe } = parseBlockFlags(iterator, ebml.type === \"SimpleBlock\" ? matroskaElements.SimpleBlock : matroskaElements.Block);\n  const { codec, trackTimescale } = webmState.getTrackInfoByNumber(trackNumber2);\n  const clusterOffset = webmState.getTimestampOffsetForByteOffset(offset);\n  const timescale = webmState.getTimescale();\n  if (clusterOffset === undefined) {\n    throw new Error(\"Could not find offset for byte offset \" + offset);\n  }\n  const timecodeInNanoSeconds = (timecodeRelativeToCluster + clusterOffset) * timescale * (trackTimescale ?? 1);\n  const timecodeInMicroseconds = timecodeInNanoSeconds / 1000;\n  if (!codec) {\n    throw new Error(`Could not find codec for track ${trackNumber2}`);\n  }\n  const remainingNow = ebml.value.length - iterator.counter.getOffset();\n  if (codec.startsWith(\"V_\")) {\n    const partialVideoSample = {\n      data: iterator.getSlice(remainingNow),\n      decodingTimestamp: timecodeInMicroseconds,\n      duration: undefined,\n      timestamp: timecodeInMicroseconds,\n      offset\n    };\n    if (keyframe === null) {\n      iterator.destroy();\n      return {\n        type: \"partial-video-sample\",\n        partialVideoSample,\n        trackId: trackNumber2,\n        timescale: WEBCODECS_TIMESCALE\n      };\n    }\n    await addAvcToTrackAndActivateTrackIfNecessary({\n      codec,\n      partialVideoSample,\n      structureState: structureState2,\n      webmState,\n      trackNumber: trackNumber2,\n      callbacks,\n      logLevel,\n      onVideoTrack,\n      avcState\n    });\n    const sample = {\n      ...partialVideoSample,\n      type: keyframe ? \"key\" : \"delta\"\n    };\n    iterator.destroy();\n    return {\n      type: \"video-sample\",\n      videoSample: sample,\n      trackId: trackNumber2,\n      timescale: WEBCODECS_TIMESCALE\n    };\n  }\n  if (codec.startsWith(\"A_\")) {\n    const audioSample = {\n      data: iterator.getSlice(remainingNow),\n      timestamp: timecodeInMicroseconds,\n      type: \"key\",\n      duration: undefined,\n      decodingTimestamp: timecodeInMicroseconds,\n      offset\n    };\n    iterator.destroy();\n    return {\n      type: \"audio-sample\",\n      audioSample,\n      trackId: trackNumber2,\n      timescale: WEBCODECS_TIMESCALE\n    };\n  }\n  iterator.destroy();\n  return {\n    type: \"no-sample\"\n  };\n};\n\n// src/containers/webm/parse-ebml.ts\nvar parseEbml = async (iterator, statesForProcessing, logLevel) => {\n  const hex = iterator.getMatroskaSegmentId();\n  if (hex === null) {\n    throw new Error(\"Not enough bytes left to parse EBML - this should not happen\");\n  }\n  const off = iterator.counter.getOffset();\n  const size = iterator.getVint();\n  const minVintWidth = iterator.counter.getOffset() - off;\n  if (size === null) {\n    throw new Error(\"Not enough bytes left to parse EBML - this should not happen\");\n  }\n  const hasInMap = ebmlMap[hex];\n  if (!hasInMap) {\n    Log.verbose(logLevel, `Unknown EBML hex ID ${JSON.stringify(hex)}`);\n    iterator.discard(size);\n    return null;\n  }\n  if (hasInMap.type === \"uint\") {\n    const beforeUintOffset = iterator.counter.getOffset();\n    const value = size === 0 ? 0 : iterator.getUint(size);\n    const { name } = hasInMap;\n    return {\n      type: name,\n      value: {\n        value,\n        byteLength: iterator.counter.getOffset() - beforeUintOffset\n      },\n      minVintWidth\n    };\n  }\n  if (hasInMap.type === \"string\") {\n    const value = iterator.getByteString(size, true);\n    return {\n      type: hasInMap.name,\n      value,\n      minVintWidth\n    };\n  }\n  if (hasInMap.type === \"float\") {\n    const value = size === 0 ? 0 : size === 4 ? iterator.getFloat32() : iterator.getFloat64();\n    return {\n      type: hasInMap.name,\n      value: {\n        value,\n        size: size === 4 ? \"32\" : \"64\"\n      },\n      minVintWidth\n    };\n  }\n  if (hasInMap.type === \"hex-string\") {\n    return {\n      type: hasInMap.name,\n      value: \"0x\" + [...iterator.getSlice(size)].map((b) => b.toString(16).padStart(2, \"0\")).join(\"\").replace(new RegExp(\"^\" + hex), \"\"),\n      minVintWidth\n    };\n  }\n  if (hasInMap.type === \"uint8array\") {\n    return {\n      type: hasInMap.name,\n      value: iterator.getSlice(size),\n      minVintWidth\n    };\n  }\n  if (hasInMap.type === \"children\") {\n    const children = [];\n    const startOffset = iterator.counter.getOffset();\n    while (true) {\n      if (size === 0) {\n        break;\n      }\n      const offset = iterator.counter.getOffset();\n      const value = await parseEbml(iterator, statesForProcessing, logLevel);\n      if (value) {\n        const remapped = statesForProcessing ? await postprocessEbml({\n          offset,\n          ebml: value,\n          statesForProcessing\n        }) : value;\n        children.push(remapped);\n      }\n      const offsetNow = iterator.counter.getOffset();\n      if (offsetNow - startOffset > size) {\n        throw new Error(`Offset ${offsetNow - startOffset} is larger than the length of the hex ${size}`);\n      }\n      if (offsetNow - startOffset === size) {\n        break;\n      }\n    }\n    return { type: hasInMap.name, value: children, minVintWidth };\n  }\n  throw new Error(`Unknown segment type ${hasInMap.type}`);\n};\nvar postprocessEbml = async ({\n  offset,\n  ebml,\n  statesForProcessing: {\n    webmState,\n    callbacks,\n    logLevel,\n    onAudioTrack,\n    onVideoTrack,\n    structureState: structureState2,\n    avcState\n  }\n}) => {\n  if (ebml.type === \"TimestampScale\") {\n    webmState.setTimescale(ebml.value.value);\n  }\n  if (ebml.type === \"Tracks\") {\n    callbacks.tracks.setIsDone(logLevel);\n  }\n  if (ebml.type === \"TrackEntry\") {\n    webmState.onTrackEntrySegment(ebml);\n    const track = getTrack({\n      track: ebml,\n      timescale: webmState.getTimescale()\n    });\n    if (track && track.type === \"audio\") {\n      await registerAudioTrack({\n        track,\n        container: \"webm\",\n        registerAudioSampleCallback: callbacks.registerAudioSampleCallback,\n        tracks: callbacks.tracks,\n        logLevel,\n        onAudioTrack\n      });\n    }\n    if (track && track.type === \"video\") {\n      if (track.codec !== NO_CODEC_PRIVATE_SHOULD_BE_DERIVED_FROM_SPS) {\n        await registerVideoTrack({\n          track,\n          container: \"webm\",\n          logLevel,\n          onVideoTrack,\n          registerVideoSampleCallback: callbacks.registerVideoSampleCallback,\n          tracks: callbacks.tracks\n        });\n      }\n    }\n  }\n  if (ebml.type === \"Timestamp\") {\n    webmState.setTimestampOffset(offset, ebml.value.value);\n  }\n  if (ebml.type === \"Block\" || ebml.type === \"SimpleBlock\") {\n    const sample = await getSampleFromBlock({\n      ebml,\n      webmState,\n      offset,\n      structureState: structureState2,\n      callbacks,\n      logLevel,\n      onVideoTrack,\n      avcState\n    });\n    if (sample.type === \"video-sample\") {\n      await callbacks.onVideoSample({\n        videoSample: sample.videoSample,\n        trackId: sample.trackId\n      });\n      return {\n        type: \"Block\",\n        value: new Uint8Array([]),\n        minVintWidth: ebml.minVintWidth\n      };\n    }\n    if (sample.type === \"audio-sample\") {\n      await callbacks.onAudioSample({\n        audioSample: sample.audioSample,\n        trackId: sample.trackId\n      });\n      return {\n        type: \"Block\",\n        value: new Uint8Array([]),\n        minVintWidth: ebml.minVintWidth\n      };\n    }\n    if (sample.type === \"no-sample\") {\n      return {\n        type: \"Block\",\n        value: new Uint8Array([]),\n        minVintWidth: ebml.minVintWidth\n      };\n    }\n  }\n  if (ebml.type === \"BlockGroup\") {\n    const block2 = ebml.value.find((c) => c.type === \"SimpleBlock\" || c.type === \"Block\");\n    if (!block2 || block2.type !== \"SimpleBlock\" && block2.type !== \"Block\") {\n      throw new Error(\"Expected block segment\");\n    }\n    const hasReferenceBlock = ebml.value.find((c) => c.type === \"ReferenceBlock\");\n    const sample = block2.value.length === 0 ? null : await getSampleFromBlock({\n      ebml: block2,\n      webmState,\n      offset,\n      structureState: structureState2,\n      callbacks,\n      logLevel,\n      onVideoTrack,\n      avcState\n    });\n    if (sample && sample.type === \"partial-video-sample\") {\n      const completeFrame = {\n        ...sample.partialVideoSample,\n        type: hasReferenceBlock ? \"delta\" : \"key\"\n      };\n      await callbacks.onVideoSample({\n        videoSample: completeFrame,\n        trackId: sample.trackId\n      });\n    }\n    return {\n      type: \"BlockGroup\",\n      value: [],\n      minVintWidth: ebml.minVintWidth\n    };\n  }\n  return ebml;\n};\n\n// src/containers/webm/segments.ts\nvar expectSegment = async ({\n  statesForProcessing,\n  isInsideSegment,\n  iterator,\n  logLevel,\n  mediaSectionState: mediaSectionState2\n}) => {\n  if (iterator.bytesRemaining() === 0) {\n    throw new Error(\"has no bytes\");\n  }\n  const offset = iterator.counter.getOffset();\n  const { returnToCheckpoint } = iterator.startCheckpoint();\n  const segmentId = iterator.getMatroskaSegmentId();\n  if (segmentId === null) {\n    returnToCheckpoint();\n    return null;\n  }\n  const offsetBeforeVInt = iterator.counter.getOffset();\n  const size = iterator.getVint();\n  const offsetAfterVInt = iterator.counter.getOffset();\n  if (size === null) {\n    returnToCheckpoint();\n    return null;\n  }\n  const bytesRemainingNow = iterator.bytesRemaining();\n  Log.trace(logLevel, \"Segment ID:\", ebmlMap[segmentId]?.name, \"Size:\" + size, bytesRemainingNow);\n  if (segmentId === matroskaElements.Segment) {\n    if (!statesForProcessing) {\n      throw new Error(\"States for processing are required\");\n    }\n    statesForProcessing.webmState.addSegment({\n      start: offset,\n      size\n    });\n    const newSegment = {\n      type: \"Segment\",\n      minVintWidth: offsetAfterVInt - offsetBeforeVInt,\n      value: []\n    };\n    return newSegment;\n  }\n  if (segmentId === matroskaElements.Cluster) {\n    if (isInsideSegment === null) {\n      throw new Error(\"Expected to be inside segment\");\n    }\n    if (!statesForProcessing) {\n      throw new Error(\"States for processing are required\");\n    }\n    if (mediaSectionState2) {\n      mediaSectionState2.addMediaSection({\n        start: offset,\n        size\n      });\n    }\n    statesForProcessing.webmState.addCluster({\n      start: offset,\n      size: size + (offsetAfterVInt - offset),\n      segment: isInsideSegment.index\n    });\n    const newSegment = {\n      type: \"Cluster\",\n      minVintWidth: offsetAfterVInt - offsetBeforeVInt,\n      value: []\n    };\n    return newSegment;\n  }\n  if (bytesRemainingNow < size) {\n    returnToCheckpoint();\n    return null;\n  }\n  const segment = await parseSegment({\n    segmentId,\n    length: size,\n    headerReadSoFar: iterator.counter.getOffset() - offset,\n    statesForProcessing,\n    iterator,\n    logLevel\n  });\n  return segment;\n};\nvar parseSegment = async ({\n  segmentId,\n  length,\n  iterator,\n  headerReadSoFar,\n  statesForProcessing,\n  logLevel\n}) => {\n  if (length < 0) {\n    throw new Error(`Expected length of ${segmentId} to be greater or equal 0`);\n  }\n  iterator.counter.decrement(headerReadSoFar);\n  const offset = iterator.counter.getOffset();\n  const ebml = await parseEbml(iterator, statesForProcessing, logLevel);\n  if (ebml === null) {\n    return null;\n  }\n  if (!statesForProcessing) {\n    return ebml;\n  }\n  const remapped = await postprocessEbml({\n    offset,\n    ebml,\n    statesForProcessing\n  });\n  return remapped;\n};\n\n// src/containers/webm/state-for-processing.ts\nvar selectStatesForProcessing = ({\n  callbacks,\n  logLevel,\n  onAudioTrack,\n  onVideoTrack,\n  structure,\n  webm,\n  avc\n}) => {\n  return {\n    webmState: webm,\n    callbacks,\n    logLevel,\n    onAudioTrack,\n    onVideoTrack,\n    structureState: structure,\n    avcState: avc\n  };\n};\n\n// src/containers/webm/parse-webm-header.ts\nvar parseWebm = async (state) => {\n  const structure = state.structure.getMatroskaStructure();\n  const { iterator } = state;\n  const offset = iterator.counter.getOffset();\n  const isInsideSegment = state.webm.isInsideSegment(iterator);\n  const isInsideCluster = state.webm.isInsideCluster(offset);\n  const results = await expectSegment({\n    iterator,\n    logLevel: state.logLevel,\n    statesForProcessing: selectStatesForProcessing(state),\n    isInsideSegment,\n    mediaSectionState: state.mediaSection\n  });\n  if (results?.type === \"SeekHead\") {\n    const position = getByteForSeek({ seekHeadSegment: results, offset });\n    if (position !== null) {\n      state.webm.cues.triggerLoad(position, offset);\n    }\n  }\n  if (results === null) {\n    return null;\n  }\n  if (isInsideCluster) {\n    if (maySkipVideoData({ state })) {\n      return makeSkip(Math.min(state.contentLength, isInsideCluster.size + isInsideCluster.start));\n    }\n    const segments = structure.boxes.filter((box) => box.type === \"Segment\");\n    const segment = segments[isInsideCluster.segment];\n    if (!segment) {\n      throw new Error(\"Expected segment\");\n    }\n    const clusters = segment.value.find((box) => box.type === \"Cluster\");\n    if (!clusters) {\n      throw new Error(\"Expected cluster\");\n    }\n    if (results.type !== \"Block\" && results.type !== \"SimpleBlock\") {\n      clusters.value.push(results);\n    }\n  } else if (isInsideSegment) {\n    const segments = structure.boxes.filter((box) => box.type === \"Segment\");\n    const segment = segments[isInsideSegment.index];\n    if (!segment) {\n      throw new Error(\"Expected segment\");\n    }\n    segment.value.push(results);\n  } else {\n    structure.boxes.push(results);\n  }\n  return null;\n};\n\n// src/init-video.ts\nvar initVideo = async ({ state }) => {\n  const fileType = state.iterator.detectFileType();\n  const { mimeType, name, contentLength } = state;\n  if (fileType.type === \"riff\") {\n    Log.verbose(state.logLevel, \"Detected RIFF container\");\n    state.structure.setStructure({\n      type: \"riff\",\n      boxes: []\n    });\n    return;\n  }\n  if (state.m3uPlaylistContext?.mp4HeaderSegment) {\n    Log.verbose(state.logLevel, \"Detected ISO Base Media segment\");\n    const moovAtom = getMoovFromFromIsoStructure(state.m3uPlaylistContext.mp4HeaderSegment);\n    if (!moovAtom) {\n      throw new Error(\"No moov box found\");\n    }\n    const tracks2 = getTracksFromMoovBox(moovAtom);\n    for (const track of tracks2.filter((t) => t.type === \"video\")) {\n      await registerVideoTrack({\n        track,\n        container: \"mp4\",\n        logLevel: state.logLevel,\n        onVideoTrack: state.onVideoTrack,\n        registerVideoSampleCallback: state.callbacks.registerVideoSampleCallback,\n        tracks: state.callbacks.tracks\n      });\n    }\n    for (const track of tracks2.filter((t) => t.type === \"audio\")) {\n      await registerAudioTrack({\n        track,\n        container: \"mp4\",\n        registerAudioSampleCallback: state.callbacks.registerAudioSampleCallback,\n        tracks: state.callbacks.tracks,\n        logLevel: state.logLevel,\n        onAudioTrack: state.onAudioTrack\n      });\n    }\n    state.callbacks.tracks.setIsDone(state.logLevel);\n    state.structure.setStructure({\n      type: \"iso-base-media\",\n      boxes: []\n    });\n    return;\n  }\n  if (fileType.type === \"iso-base-media\") {\n    Log.verbose(state.logLevel, \"Detected ISO Base Media container\");\n    state.structure.setStructure({\n      type: \"iso-base-media\",\n      boxes: []\n    });\n    return;\n  }\n  if (fileType.type === \"webm\") {\n    Log.verbose(state.logLevel, \"Detected Matroska container\");\n    state.structure.setStructure({\n      boxes: [],\n      type: \"matroska\"\n    });\n    return;\n  }\n  if (fileType.type === \"transport-stream\") {\n    Log.verbose(state.logLevel, \"Detected MPEG-2 Transport Stream\");\n    state.mediaSection.addMediaSection({\n      start: 0,\n      size: contentLength\n    });\n    state.structure.setStructure({\n      boxes: [],\n      type: \"transport-stream\"\n    });\n    return;\n  }\n  if (fileType.type === \"mp3\") {\n    Log.verbose(state.logLevel, \"Detected MP3\");\n    const structure = {\n      boxes: [],\n      type: \"mp3\"\n    };\n    state.structure.setStructure(structure);\n    return;\n  }\n  if (fileType.type === \"wav\") {\n    Log.verbose(state.logLevel, \"Detected WAV\");\n    const structure = {\n      boxes: [],\n      type: \"wav\"\n    };\n    state.structure.setStructure(structure);\n    return;\n  }\n  if (fileType.type === \"flac\") {\n    Log.verbose(state.logLevel, \"Detected FLAC\");\n    const structure = {\n      boxes: [],\n      type: \"flac\"\n    };\n    state.structure.setStructure(structure);\n    return;\n  }\n  if (fileType.type === \"aac\") {\n    Log.verbose(state.logLevel, \"Detected AAC\");\n    state.structure.setStructure({\n      type: \"aac\",\n      boxes: []\n    });\n    return;\n  }\n  if (fileType.type === \"m3u\") {\n    Log.verbose(state.logLevel, \"Detected M3U\");\n    state.structure.setStructure({\n      type: \"m3u\",\n      boxes: []\n    });\n    return;\n  }\n  if (fileType.type === \"pdf\") {\n    return Promise.reject(new IsAPdfError({\n      message: \"GIF files are not supported\",\n      mimeType,\n      sizeInBytes: contentLength,\n      fileName: name\n    }));\n  }\n  if (fileType.type === \"bmp\" || fileType.type === \"jpeg\" || fileType.type === \"png\" || fileType.type === \"webp\" || fileType.type === \"gif\") {\n    return Promise.reject(new IsAnImageError({\n      message: \"Image files are not supported\",\n      imageType: fileType.type,\n      dimensions: fileType.dimensions,\n      mimeType,\n      sizeInBytes: contentLength,\n      fileName: name\n    }));\n  }\n  if (fileType.type === \"unknown\") {\n    return Promise.reject(new IsAnUnsupportedFileTypeError({\n      message: \"Unknown file format\",\n      mimeType,\n      sizeInBytes: contentLength,\n      fileName: name\n    }));\n  }\n  return Promise.reject(new Error(\"Unknown video format \" + fileType));\n};\n\n// src/run-parse-iteration.ts\nvar runParseIteration = async ({\n  state\n}) => {\n  const structure = state.structure.getStructureOrNull();\n  if (structure && structure.type === \"m3u\") {\n    return parseM3u({ state });\n  }\n  if (structure === null) {\n    await initVideo({\n      state\n    });\n    return null;\n  }\n  if (structure.type === \"riff\") {\n    return parseRiff(state);\n  }\n  if (structure.type === \"mp3\") {\n    return parseMp3(state);\n  }\n  if (structure.type === \"iso-base-media\") {\n    return parseIsoBaseMedia(state);\n  }\n  if (structure.type === \"matroska\") {\n    return parseWebm(state);\n  }\n  if (structure.type === \"transport-stream\") {\n    return parseTransportStream(state);\n  }\n  if (structure.type === \"wav\") {\n    return parseWav(state);\n  }\n  if (structure.type === \"aac\") {\n    return parseAac(state);\n  }\n  if (structure.type === \"flac\") {\n    return parseFlac({ state, iterator: state.iterator });\n  }\n  return Promise.reject(new Error(\"Unknown video format \" + structure));\n};\n\n// src/parse-loop.ts\nvar fetchMoreData = async (state) => {\n  await state.controller._internals.checkForAbortAndPause();\n  const result = await state.currentReader.getCurrent().reader.read();\n  if (result.value) {\n    state.iterator.addData(result.value);\n  }\n  return result.done;\n};\nvar parseLoop = async ({\n  state,\n  throttledState,\n  onError\n}) => {\n  let iterationWithThisOffset = 0;\n  while (!await checkIfDone(state)) {\n    await state.controller._internals.checkForAbortAndPause();\n    await workOnSeekRequest(getWorkOnSeekRequestOptions(state));\n    const offsetBefore = state.iterator.counter.getOffset();\n    const readStart = Date.now();\n    while (state.iterator.bytesRemaining() < 0) {\n      const done = await fetchMoreData(state);\n      if (done) {\n        break;\n      }\n    }\n    if (iterationWithThisOffset > 0 || state.iterator.bytesRemaining() <= 1e5) {\n      await fetchMoreData(state);\n    }\n    state.timings.timeReadingData += Date.now() - readStart;\n    throttledState.update?.(() => makeProgressObject(state));\n    if (!state.errored) {\n      Log.trace(state.logLevel, `Continuing parsing of file, currently at position ${state.iterator.counter.getOffset()}/${state.contentLength} (0x${state.iterator.counter.getOffset().toString(16)})`);\n      if (iterationWithThisOffset > 300 && state.structure.getStructure().type !== \"m3u\") {\n        throw new Error(\"Infinite loop detected. The parser is not progressing. This is likely a bug in the parser. You can report this at https://remotion.dev/report and we will fix it as soon as possible.\");\n      }\n      try {\n        await triggerInfoEmit(state);\n        await state.controller._internals.checkForAbortAndPause();\n        const result = await runParseIteration({\n          state\n        });\n        if (result !== null && result.action === \"fetch-more-data\") {\n          Log.verbose(state.logLevel, `Need to fetch ${result.bytesNeeded} more bytes before we can continue`);\n          const startBytesRemaining = state.iterator.bytesRemaining();\n          while (true) {\n            const done = await fetchMoreData(state);\n            if (done) {\n              break;\n            }\n            if (state.iterator.bytesRemaining() - startBytesRemaining >= result.bytesNeeded) {\n              break;\n            }\n          }\n          continue;\n        }\n        if (result !== null && result.action === \"skip\") {\n          state.increaseSkippedBytes(result.skipTo - state.iterator.counter.getOffset());\n          if (result.skipTo === state.contentLength) {\n            state.iterator.discard(result.skipTo - state.iterator.counter.getOffset());\n            Log.verbose(state.logLevel, \"Skipped to end of file, not fetching.\");\n            break;\n          }\n          const seekStart = Date.now();\n          await performSeek({\n            seekTo: result.skipTo,\n            userInitiated: false,\n            controller: state.controller,\n            mediaSection: state.mediaSection,\n            iterator: state.iterator,\n            logLevel: state.logLevel,\n            mode: state.mode,\n            contentLength: state.contentLength,\n            seekInfiniteLoop: state.seekInfiniteLoop,\n            currentReader: state.currentReader,\n            readerInterface: state.readerInterface,\n            fields: state.fields,\n            src: state.src,\n            discardReadBytes: state.discardReadBytes,\n            prefetchCache: state.prefetchCache\n          });\n          state.timings.timeSeeking += Date.now() - seekStart;\n        }\n      } catch (e) {\n        const err = await onError(e);\n        if (!err.action) {\n          throw new Error('onError was used but did not return an \"action\" field. See docs for this API on how to use onError.');\n        }\n        if (err.action === \"fail\") {\n          throw e;\n        }\n        if (err.action === \"download\") {\n          state.errored = e;\n          Log.verbose(state.logLevel, \"Error was handled by onError and deciding to continue.\");\n        }\n      }\n    }\n    const timeFreeStart = Date.now();\n    await state.discardReadBytes(false);\n    state.timings.timeFreeingData += Date.now() - timeFreeStart;\n    const didProgress = state.iterator.counter.getOffset() > offsetBefore;\n    if (!didProgress) {\n      iterationWithThisOffset++;\n    } else {\n      iterationWithThisOffset = 0;\n    }\n  }\n  state.samplesObserved.setLastSampleObserved();\n  await state.callbacks.callTracksDoneCallback();\n  if (state.controller._internals.seekSignal.getSeek() !== null) {\n    Log.verbose(state.logLevel, \"Reached end of samples, but there is a pending seek. Trying to seek...\");\n    await workOnSeekRequest(getWorkOnSeekRequestOptions(state));\n    if (state.controller._internals.seekSignal.getSeek() !== null) {\n      throw new Error(\"Reached the end of the file even though a seek was requested. This is likely a bug in the parser. You can report this at https://remotion.dev/report and we will fix it as soon as possible.\");\n    }\n    await parseLoop({\n      onError,\n      throttledState,\n      state\n    });\n  }\n};\n\n// src/print-timings.ts\nvar printTimings = (state) => {\n  Log.verbose(state.logLevel, `Time iterating over file: ${state.timings.timeIterating}ms`);\n  Log.verbose(state.logLevel, `Time fetching data: ${state.timings.timeReadingData}ms`);\n  Log.verbose(state.logLevel, `Time seeking: ${state.timings.timeSeeking}ms`);\n  Log.verbose(state.logLevel, `Time checking if done: ${state.timings.timeCheckingIfDone}ms`);\n  Log.verbose(state.logLevel, `Time freeing data: ${state.timings.timeFreeingData}ms`);\n};\n\n// src/remotion-license-acknowledge.ts\nvar warningShown = false;\nvar warnIfRemotionLicenseNotAcknowledged = ({\n  acknowledgeRemotionLicense,\n  logLevel,\n  apiName\n}) => {\n  if (acknowledgeRemotionLicense) {\n    return;\n  }\n  if (warningShown) {\n    return;\n  }\n  warningShown = true;\n  Log.warn(logLevel, `Note: Some companies are required to obtain a license to use @remotion/media-parser. See: https://remotion.dev/license\nPass \\`acknowledgeRemotionLicense: true\\` to \\`${apiName}\\` function to make this message disappear.`);\n};\n\n// src/set-seeking-hints.ts\nvar setSeekingHints = ({\n  hints,\n  state\n}) => {\n  if (hints.type === \"iso-base-media-seeking-hints\") {\n    setSeekingHintsForMp4({ hints, state });\n    return;\n  }\n  if (hints.type === \"wav-seeking-hints\") {\n    setSeekingHintsForWav({ hints, state });\n    return;\n  }\n  if (hints.type === \"transport-stream-seeking-hints\") {\n    setSeekingHintsForTransportStream({ hints, state });\n    return;\n  }\n  if (hints.type === \"webm-seeking-hints\") {\n    setSeekingHintsForWebm({ hints, state });\n    return;\n  }\n  if (hints.type === \"flac-seeking-hints\") {\n    setSeekingHintsForFlac({ hints, state });\n    return;\n  }\n  if (hints.type === \"riff-seeking-hints\") {\n    setSeekingHintsForRiff({ hints, state });\n    return;\n  }\n  if (hints.type === \"mp3-seeking-hints\") {\n    setSeekingHintsForMp3({ hints, state });\n    return;\n  }\n  if (hints.type === \"aac-seeking-hints\") {\n    setSeekingHintsForAac();\n    return;\n  }\n  if (hints.type === \"m3u8-seeking-hints\") {\n    return;\n  }\n  throw new Error(`Unknown seeking hints type: ${hints}`);\n};\n\n// src/get-fields-from-callbacks.ts\nvar getFieldsFromCallback = ({\n  fields,\n  callbacks\n}) => {\n  const newFields = {\n    audioCodec: Boolean(callbacks.onAudioCodec),\n    container: Boolean(callbacks.onContainer),\n    dimensions: Boolean(callbacks.onDimensions),\n    durationInSeconds: Boolean(callbacks.onDurationInSeconds),\n    fps: Boolean(callbacks.onFps),\n    internalStats: Boolean(callbacks.onInternalStats),\n    isHdr: Boolean(callbacks.onIsHdr),\n    location: Boolean(callbacks.onLocation),\n    metadata: Boolean(callbacks.onMetadata),\n    mimeType: Boolean(callbacks.onMimeType),\n    name: Boolean(callbacks.onName),\n    rotation: Boolean(callbacks.onRotation),\n    size: Boolean(callbacks.onSize),\n    slowStructure: Boolean(callbacks.onSlowStructure),\n    tracks: Boolean(callbacks.onTracks),\n    unrotatedDimensions: Boolean(callbacks.onUnrotatedDimensions),\n    videoCodec: Boolean(callbacks.onVideoCodec),\n    slowKeyframes: Boolean(callbacks.onSlowKeyframes),\n    slowDurationInSeconds: Boolean(callbacks.onSlowDurationInSeconds),\n    slowFps: Boolean(callbacks.onSlowFps),\n    slowNumberOfFrames: Boolean(callbacks.onSlowNumberOfFrames),\n    keyframes: Boolean(callbacks.onKeyframes),\n    images: Boolean(callbacks.onImages),\n    numberOfAudioChannels: Boolean(callbacks.onNumberOfAudioChannels),\n    sampleRate: Boolean(callbacks.onSampleRate),\n    slowAudioBitrate: Boolean(callbacks.onSlowAudioBitrate),\n    slowVideoBitrate: Boolean(callbacks.onSlowVideoBitrate),\n    m3uStreams: Boolean(callbacks.onM3uStreams),\n    ...fields\n  };\n  return newFields;\n};\n\n// src/state/audio-sample-map.ts\nvar audioSampleMapState = () => {\n  let map = [];\n  const addSample = (audioSampleOffset) => {\n    if (map.find((m) => m.offset === audioSampleOffset.offset)) {\n      return;\n    }\n    map.push(audioSampleOffset);\n  };\n  return {\n    addSample,\n    getSamples: () => map,\n    setFromSeekingHints: (newMap) => {\n      map = newMap;\n    }\n  };\n};\n\n// src/state/aac-state.ts\nvar aacState = () => {\n  const samples = [];\n  const audioSamples = audioSampleMapState();\n  return {\n    addSample: ({ offset, size }) => {\n      const index = samples.findIndex((s) => s.offset === offset);\n      if (index !== -1) {\n        return samples[index];\n      }\n      samples.push({ offset, index: samples.length, size });\n      return samples[samples.length - 1];\n    },\n    getSamples: () => samples,\n    audioSamples\n  };\n};\n\n// src/containers/avc/max-buffer-size.ts\nvar maxMacroblocksByLevel = {\n  10: 396,\n  11: 900,\n  12: 2376,\n  13: 2376,\n  20: 2376,\n  21: 4752,\n  22: 8100,\n  30: 8100,\n  31: 18000,\n  32: 20480,\n  40: 32768,\n  41: 32768,\n  42: 34816,\n  50: 110400,\n  51: 184320,\n  52: 184320,\n  60: 696320,\n  61: 696320,\n  62: 696320\n};\nvar macroBlocksPerFrame = (sps) => {\n  const { pic_width_in_mbs_minus1, pic_height_in_map_units_minus1 } = sps;\n  return (pic_width_in_mbs_minus1 + 1) * (pic_height_in_map_units_minus1 + 1);\n};\nvar maxMacroblockBufferSize = (sps) => {\n  const { level } = sps;\n  const maxMacroblocks = maxMacroblocksByLevel[level];\n  if (maxMacroblocks === undefined) {\n    throw new Error(`Unsupported level: ${level.toString(16)}`);\n  }\n  return maxMacroblocks;\n};\n\n// src/state/avc/avc-state.ts\nvar avcState = () => {\n  let prevPicOrderCntLsb = 0;\n  let prevPicOrderCntMsb = 0;\n  let sps = null;\n  let maxFramesInBuffer = null;\n  return {\n    getPrevPicOrderCntLsb() {\n      return prevPicOrderCntLsb;\n    },\n    getPrevPicOrderCntMsb() {\n      return prevPicOrderCntMsb;\n    },\n    setPrevPicOrderCntLsb(value) {\n      prevPicOrderCntLsb = value;\n    },\n    setPrevPicOrderCntMsb(value) {\n      prevPicOrderCntMsb = value;\n    },\n    setSps(value) {\n      const macroblockBufferSize = macroBlocksPerFrame(value);\n      const maxBufferSize = maxMacroblockBufferSize(value);\n      const maxFrames = Math.min(16, Math.floor(maxBufferSize / macroblockBufferSize));\n      maxFramesInBuffer = maxFrames;\n      sps = value;\n    },\n    getSps() {\n      return sps;\n    },\n    getMaxFramesInBuffer() {\n      return maxFramesInBuffer;\n    },\n    clear() {\n      maxFramesInBuffer = null;\n      sps = null;\n      prevPicOrderCntLsb = 0;\n      prevPicOrderCntMsb = 0;\n    }\n  };\n};\n\n// src/state/current-reader.ts\nvar currentReader = (initialReader) => {\n  let current = initialReader;\n  return {\n    getCurrent: () => current,\n    setCurrent: (newReader) => {\n      current = newReader;\n    }\n  };\n};\n\n// src/state/emitted-fields.ts\nvar emittedState = () => {\n  const emittedFields = {\n    audioCodec: false,\n    container: false,\n    dimensions: false,\n    durationInSeconds: false,\n    fps: false,\n    internalStats: false,\n    isHdr: false,\n    location: false,\n    metadata: false,\n    mimeType: false,\n    name: false,\n    rotation: false,\n    size: false,\n    slowStructure: false,\n    tracks: false,\n    videoCodec: false,\n    unrotatedDimensions: false,\n    slowDurationInSeconds: false,\n    slowFps: false,\n    slowKeyframes: false,\n    slowNumberOfFrames: false,\n    keyframes: false,\n    images: false,\n    numberOfAudioChannels: false,\n    sampleRate: false,\n    slowAudioBitrate: false,\n    slowVideoBitrate: false,\n    m3uStreams: false\n  };\n  return emittedFields;\n};\n\n// src/state/flac-state.ts\nvar flacState = () => {\n  let blockingBitStrategy;\n  const audioSamples = audioSampleMapState();\n  return {\n    setBlockingBitStrategy: (strategy) => {\n      blockingBitStrategy = strategy;\n    },\n    getBlockingBitStrategy: () => blockingBitStrategy,\n    audioSamples\n  };\n};\n\n// src/state/images.ts\nvar imagesState = () => {\n  const images = [];\n  const addImage = (image) => {\n    images.push(image);\n  };\n  return {\n    images,\n    addImage\n  };\n};\n\n// src/containers/iso-base-media/mfra/get-mfra-atom.ts\nvar getMfraAtom = async ({\n  src,\n  contentLength,\n  readerInterface,\n  controller,\n  parentSize,\n  logLevel,\n  prefetchCache\n}) => {\n  const result = await readerInterface.read({\n    controller,\n    range: [contentLength - parentSize, contentLength - 1],\n    src,\n    logLevel,\n    prefetchCache\n  });\n  const iterator = getArrayBufferIterator({\n    initialData: new Uint8Array,\n    maxBytes: parentSize,\n    logLevel: \"error\"\n  });\n  while (true) {\n    const res = await result.reader.reader.read();\n    if (res.value) {\n      iterator.addData(res.value);\n    }\n    if (res.done) {\n      break;\n    }\n  }\n  return iterator;\n};\n\n// src/containers/iso-base-media/mfra/get-mfro-atom.ts\nvar getMfroAtom = async ({\n  src,\n  contentLength,\n  readerInterface,\n  controller,\n  logLevel,\n  prefetchCache\n}) => {\n  const result = await readerInterface.read({\n    controller,\n    range: [contentLength - 16, contentLength - 1],\n    src,\n    logLevel,\n    prefetchCache\n  });\n  const { value } = await result.reader.reader.read();\n  if (!value) {\n    return null;\n  }\n  result.reader.abort();\n  const iterator = getArrayBufferIterator({\n    initialData: value,\n    maxBytes: value.length,\n    logLevel: \"error\"\n  });\n  const size = iterator.getUint32();\n  if (size !== 16) {\n    iterator.destroy();\n    return null;\n  }\n  const atom = iterator.getByteString(4, false);\n  if (atom !== \"mfro\") {\n    iterator.destroy();\n    return null;\n  }\n  const version = iterator.getUint8();\n  if (version !== 0) {\n    iterator.destroy();\n    return null;\n  }\n  iterator.discard(3);\n  const parentSize = iterator.getUint32();\n  iterator.destroy();\n  return parentSize;\n};\n\n// src/containers/iso-base-media/get-mfra-seeking-box.ts\nvar getMfraSeekingBox = async ({\n  contentLength,\n  controller,\n  readerInterface,\n  src,\n  logLevel,\n  prefetchCache\n}) => {\n  const parentSize = await getMfroAtom({\n    contentLength,\n    controller,\n    readerInterface,\n    src,\n    logLevel,\n    prefetchCache\n  });\n  if (!parentSize) {\n    return null;\n  }\n  const mfraAtom = await getMfraAtom({\n    contentLength,\n    controller,\n    readerInterface,\n    src,\n    parentSize,\n    logLevel,\n    prefetchCache\n  });\n  mfraAtom.discard(8);\n  return getIsoBaseMediaChildren({\n    iterator: mfraAtom,\n    logLevel,\n    size: parentSize - 8,\n    onlyIfMoovAtomExpected: null,\n    contentLength\n  });\n};\n\n// src/state/iso-base-media/lazy-mfra-load.ts\nvar lazyMfraLoad = ({\n  contentLength,\n  controller,\n  readerInterface,\n  src,\n  logLevel,\n  prefetchCache\n}) => {\n  let prom = null;\n  let result = null;\n  const triggerLoad = () => {\n    if (prom) {\n      return prom;\n    }\n    Log.verbose(logLevel, \"Moof box found, trying to lazy load mfra\");\n    prom = getMfraSeekingBox({\n      contentLength,\n      controller,\n      readerInterface,\n      src,\n      logLevel,\n      prefetchCache\n    }).then((boxes) => {\n      Log.verbose(logLevel, boxes ? \"Lazily found mfra atom.\" : \"No mfra atom found.\");\n      result = boxes;\n      return boxes;\n    });\n    return prom;\n  };\n  const getIfAlreadyLoaded = () => {\n    if (result) {\n      return result;\n    }\n    return null;\n  };\n  const setFromSeekingHints = (hints) => {\n    result = hints.mfraAlreadyLoaded;\n  };\n  return {\n    triggerLoad,\n    getIfAlreadyLoaded,\n    setFromSeekingHints\n  };\n};\n\n// src/state/iso-base-media/moov-box.ts\nvar moovState = () => {\n  let moovBox = null;\n  return {\n    setMoovBox: (moov) => {\n      moovBox = moov;\n    },\n    getMoovBoxAndPrecomputed: () => moovBox\n  };\n};\n\n// src/state/iso-base-media/timescale-state.ts\nvar movieTimeScaleState = () => {\n  let trackTimescale = null;\n  return {\n    getTrackTimescale: () => trackTimescale,\n    setTrackTimescale: (timescale) => {\n      trackTimescale = timescale;\n    }\n  };\n};\n\n// src/state/iso-base-media/iso-state.ts\nvar isoBaseMediaState = ({\n  contentLength,\n  controller,\n  readerInterface,\n  src,\n  logLevel,\n  prefetchCache\n}) => {\n  return {\n    flatSamples: cachedSamplePositionsState(),\n    moov: moovState(),\n    mfra: lazyMfraLoad({\n      contentLength,\n      controller,\n      readerInterface,\n      src,\n      logLevel,\n      prefetchCache\n    }),\n    moof: precomputedMoofState(),\n    tfra: precomputedTfraState(),\n    movieTimeScale: movieTimeScaleState()\n  };\n};\n\n// src/state/keyframes.ts\nvar keyframesState = () => {\n  const keyframes = [];\n  const addKeyframe = (keyframe) => {\n    if (keyframes.find((k) => k.positionInBytes === keyframe.positionInBytes)) {\n      return;\n    }\n    keyframes.push(keyframe);\n  };\n  const getKeyframes2 = () => {\n    keyframes.sort((a, b) => a.positionInBytes - b.positionInBytes);\n    return keyframes;\n  };\n  const setFromSeekingHints = (keyframesFromHints) => {\n    for (const keyframe of keyframesFromHints) {\n      addKeyframe(keyframe);\n    }\n  };\n  return {\n    addKeyframe,\n    getKeyframes: getKeyframes2,\n    setFromSeekingHints\n  };\n};\n\n// src/containers/m3u/sample-sorter.ts\nvar sampleSorter = ({\n  logLevel,\n  getAllChunksProcessedForPlaylist\n}) => {\n  const streamsWithTracks = [];\n  const audioCallbacks = {};\n  const videoCallbacks = {};\n  let latestSample = {};\n  return {\n    clearSamples: () => {\n      latestSample = {};\n    },\n    addToStreamWithTrack: (src) => {\n      streamsWithTracks.push(src);\n    },\n    addVideoStreamToConsider: (src, callback) => {\n      videoCallbacks[src] = callback;\n    },\n    addAudioStreamToConsider: (src, callback) => {\n      audioCallbacks[src] = callback;\n    },\n    hasAudioStreamToConsider: (src) => {\n      return Boolean(audioCallbacks[src]);\n    },\n    hasVideoStreamToConsider: (src) => {\n      return Boolean(videoCallbacks[src]);\n    },\n    addAudioSample: async (src, sample) => {\n      const callback = audioCallbacks[src];\n      if (!callback) {\n        throw new Error(\"No callback found for audio sample\");\n      }\n      latestSample[src] = sample.decodingTimestamp;\n      await callback(sample);\n    },\n    addVideoSample: async (src, sample) => {\n      const callback = videoCallbacks[src];\n      if (!callback) {\n        throw new Error(\"No callback found for video sample.\");\n      }\n      latestSample[src] = sample.decodingTimestamp;\n      await callback(sample);\n    },\n    getNextStreamToRun: (streams) => {\n      for (const stream of streams) {\n        if (getAllChunksProcessedForPlaylist(stream)) {\n          continue;\n        }\n        if (!streamsWithTracks.includes(stream)) {\n          Log.trace(logLevel, `Did not yet detect track of ${stream}, working on that`);\n          return stream;\n        }\n      }\n      let smallestDts = Infinity;\n      for (const stream of streams) {\n        if (getAllChunksProcessedForPlaylist(stream)) {\n          continue;\n        }\n        if ((latestSample[stream] ?? 0) < smallestDts) {\n          smallestDts = latestSample[stream] ?? 0;\n        }\n      }\n      for (const stream of streams) {\n        if (getAllChunksProcessedForPlaylist(stream)) {\n          continue;\n        }\n        if ((latestSample[stream] ?? 0) === smallestDts) {\n          Log.trace(logLevel, `Working on ${stream} because it has the smallest DTS`);\n          return stream;\n        }\n      }\n      throw new Error(\"should be done with parsing now\");\n    }\n  };\n};\n\n// src/state/m3u-state.ts\nvar m3uState = (logLevel) => {\n  let selectedMainPlaylist = null;\n  let associatedPlaylists = null;\n  const hasEmittedVideoTrack = {};\n  const hasEmittedAudioTrack = {};\n  const hasEmittedDoneWithTracks = {};\n  let hasFinishedManifest = false;\n  const seekToSecondsToProcess = {};\n  const nextSeekShouldSubtractChunks = {};\n  let readyToIterateOverM3u = false;\n  const allChunksProcessed = {};\n  const m3uStreamRuns = {};\n  const tracksDone = {};\n  const getMainPlaylistUrl = () => {\n    if (!selectedMainPlaylist) {\n      throw new Error(\"No main playlist selected\");\n    }\n    const playlistUrl = selectedMainPlaylist.type === \"initial-url\" ? selectedMainPlaylist.url : selectedMainPlaylist.stream.src;\n    return playlistUrl;\n  };\n  const getSelectedPlaylists = () => {\n    return [\n      getMainPlaylistUrl(),\n      ...(associatedPlaylists ?? []).map((p) => p.src)\n    ];\n  };\n  const getAllChunksProcessedForPlaylist = (src) => allChunksProcessed[src];\n  const mp4HeaderSegments = {};\n  const setMp4HeaderSegment = (playlistUrl, structure) => {\n    mp4HeaderSegments[playlistUrl] = structure;\n  };\n  const getMp4HeaderSegment = (playlistUrl) => {\n    return mp4HeaderSegments[playlistUrl];\n  };\n  return {\n    setSelectedMainPlaylist: (stream) => {\n      selectedMainPlaylist = stream;\n    },\n    getSelectedMainPlaylist: () => selectedMainPlaylist,\n    setHasEmittedVideoTrack: (src, callback) => {\n      hasEmittedVideoTrack[src] = callback;\n    },\n    hasEmittedVideoTrack: (src) => {\n      const value = hasEmittedVideoTrack[src];\n      if (value === undefined) {\n        return false;\n      }\n      return value;\n    },\n    setHasEmittedAudioTrack: (src, callback) => {\n      hasEmittedAudioTrack[src] = callback;\n    },\n    hasEmittedAudioTrack: (src) => {\n      const value = hasEmittedAudioTrack[src];\n      if (value === undefined) {\n        return false;\n      }\n      return value;\n    },\n    setHasEmittedDoneWithTracks: (src) => {\n      hasEmittedDoneWithTracks[src] = true;\n    },\n    hasEmittedDoneWithTracks: (src) => hasEmittedDoneWithTracks[src] !== undefined,\n    setReadyToIterateOverM3u: () => {\n      readyToIterateOverM3u = true;\n    },\n    isReadyToIterateOverM3u: () => readyToIterateOverM3u,\n    setAllChunksProcessed: (src) => {\n      allChunksProcessed[src] = true;\n    },\n    clearAllChunksProcessed: () => {\n      Object.keys(allChunksProcessed).forEach((key) => {\n        delete allChunksProcessed[key];\n      });\n    },\n    getAllChunksProcessedForPlaylist,\n    getAllChunksProcessedOverall: () => {\n      if (!selectedMainPlaylist) {\n        return false;\n      }\n      const selectedPlaylists = getSelectedPlaylists();\n      return selectedPlaylists.every((url) => allChunksProcessed[url]);\n    },\n    setHasFinishedManifest: () => {\n      hasFinishedManifest = true;\n    },\n    hasFinishedManifest: () => hasFinishedManifest,\n    setM3uStreamRun: (playlistUrl, run) => {\n      if (!run) {\n        delete m3uStreamRuns[playlistUrl];\n        return;\n      }\n      m3uStreamRuns[playlistUrl] = run;\n    },\n    setTracksDone: (playlistUrl) => {\n      tracksDone[playlistUrl] = true;\n      const selectedPlaylists = getSelectedPlaylists();\n      return selectedPlaylists.every((url) => tracksDone[url]);\n    },\n    getTrackDone: (playlistUrl) => {\n      return tracksDone[playlistUrl];\n    },\n    clearTracksDone: () => {\n      Object.keys(tracksDone).forEach((key) => {\n        delete tracksDone[key];\n      });\n    },\n    getM3uStreamRun: (playlistUrl) => m3uStreamRuns[playlistUrl] ?? null,\n    abortM3UStreamRuns: () => {\n      const values = Object.values(m3uStreamRuns);\n      if (values.length === 0) {\n        return;\n      }\n      Log.trace(logLevel, `Aborting ${values.length} M3U stream runs`);\n      values.forEach((run) => {\n        run.abort();\n      });\n    },\n    setAssociatedPlaylists: (playlists) => {\n      associatedPlaylists = playlists;\n    },\n    getAssociatedPlaylists: () => associatedPlaylists,\n    getSelectedPlaylists,\n    sampleSorter: sampleSorter({ logLevel, getAllChunksProcessedForPlaylist }),\n    setMp4HeaderSegment,\n    getMp4HeaderSegment,\n    setSeekToSecondsToProcess: (playlistUrl, m3uSeek) => {\n      seekToSecondsToProcess[playlistUrl] = m3uSeek;\n    },\n    getSeekToSecondsToProcess: (playlistUrl) => seekToSecondsToProcess[playlistUrl] ?? null,\n    setNextSeekShouldSubtractChunks: (playlistUrl, chunks) => {\n      nextSeekShouldSubtractChunks[playlistUrl] = chunks;\n    },\n    getNextSeekShouldSubtractChunks: (playlistUrl) => nextSeekShouldSubtractChunks[playlistUrl] ?? 0\n  };\n};\n\n// src/containers/webm/seek/format-cues.ts\nvar formatCues = (cues) => {\n  const matroskaCues = [];\n  for (const cue of cues) {\n    if (cue.type === \"Crc32\") {\n      continue;\n    }\n    if (cue.type !== \"CuePoint\") {\n      throw new Error(\"Expected CuePoint\");\n    }\n    const cueTime = cue.value.find((_cue) => _cue.type === \"CueTime\");\n    if (!cueTime) {\n      throw new Error(\"Expected CueTime\");\n    }\n    const cueTrackPositions = cue.value.find((c) => c.type === \"CueTrackPositions\");\n    if (!cueTrackPositions) {\n      throw new Error(\"Expected CueTrackPositions\");\n    }\n    const cueTimeValue = cueTime.value.value;\n    const cueTrack = cueTrackPositions.value.find((_c) => _c.type === \"CueTrack\");\n    if (!cueTrack) {\n      throw new Error(\"Expected CueTrack\");\n    }\n    const cueClusterPosition = cueTrackPositions.value.find((_c) => _c.type === \"CueClusterPosition\");\n    if (!cueClusterPosition) {\n      throw new Error(\"Expected CueClusterPosition\");\n    }\n    const cueRelativePosition = cueTrackPositions.value.find((_c) => _c.type === \"CueRelativePosition\");\n    const matroskaCue = {\n      trackId: cueTrack.value.value,\n      timeInTimescale: cueTimeValue,\n      clusterPositionInSegment: cueClusterPosition.value.value,\n      relativePosition: cueRelativePosition?.value.value ?? 0\n    };\n    matroskaCues.push(matroskaCue);\n  }\n  return matroskaCues;\n};\n\n// src/containers/webm/seek/fetch-web-cues.ts\nvar fetchWebmCues = async ({\n  src,\n  readerInterface,\n  controller,\n  position,\n  logLevel,\n  prefetchCache\n}) => {\n  const result = await readerInterface.read({\n    controller,\n    range: position,\n    src,\n    logLevel,\n    prefetchCache\n  });\n  const { value } = await result.reader.reader.read();\n  if (!value) {\n    return null;\n  }\n  result.reader.abort();\n  const iterator = getArrayBufferIterator({\n    initialData: value,\n    maxBytes: value.length,\n    logLevel: \"error\"\n  });\n  const segment = await expectSegment({\n    iterator,\n    logLevel,\n    statesForProcessing: null,\n    isInsideSegment: null,\n    mediaSectionState: null\n  });\n  iterator.destroy();\n  if (!segment?.value) {\n    return null;\n  }\n  return formatCues(segment.value);\n};\n\n// src/state/matroska/lazy-cues-fetch.ts\nvar lazyCuesFetch = ({\n  controller,\n  logLevel,\n  readerInterface,\n  src,\n  prefetchCache\n}) => {\n  let prom = null;\n  let sOffset = null;\n  let result = null;\n  const triggerLoad = (position, segmentOffset) => {\n    if (result) {\n      return Promise.resolve(result);\n    }\n    if (prom) {\n      return prom;\n    }\n    if (sOffset && sOffset !== segmentOffset) {\n      throw new Error(\"Segment offset mismatch\");\n    }\n    sOffset = segmentOffset;\n    Log.verbose(logLevel, \"Cues box found, trying to lazy load cues\");\n    prom = fetchWebmCues({\n      controller,\n      logLevel,\n      position,\n      readerInterface,\n      src,\n      prefetchCache\n    }).then((cues) => {\n      Log.verbose(logLevel, \"Cues loaded\");\n      result = cues;\n      return cues;\n    });\n    return prom;\n  };\n  const getLoadedCues = async () => {\n    if (!prom) {\n      return null;\n    }\n    if (result) {\n      if (!sOffset) {\n        throw new Error(\"Segment offset not set\");\n      }\n      return {\n        cues: result,\n        segmentOffset: sOffset\n      };\n    }\n    const cues = await prom;\n    if (!cues) {\n      return null;\n    }\n    if (!sOffset) {\n      throw new Error(\"Segment offset not set\");\n    }\n    return {\n      cues,\n      segmentOffset: sOffset\n    };\n  };\n  const getIfAlreadyLoaded = () => {\n    if (result) {\n      if (sOffset === null) {\n        throw new Error(\"Segment offset not set\");\n      }\n      return {\n        cues: result,\n        segmentOffset: sOffset\n      };\n    }\n    return null;\n  };\n  const setFromSeekingHints = (hints) => {\n    result = hints.loadedCues?.cues ?? null;\n    sOffset = hints.loadedCues?.segmentOffset ?? null;\n  };\n  return {\n    triggerLoad,\n    getLoadedCues,\n    getIfAlreadyLoaded,\n    setFromSeekingHints\n  };\n};\n\n// src/state/matroska/webm.ts\nvar webmState = ({\n  controller,\n  logLevel,\n  readerInterface,\n  src,\n  prefetchCache\n}) => {\n  const trackEntries = {};\n  const onTrackEntrySegment = (trackEntry2) => {\n    const trackId = getTrackId(trackEntry2);\n    if (!trackId) {\n      throw new Error(\"Expected track id\");\n    }\n    if (trackEntries[trackId]) {\n      return;\n    }\n    const codec = getTrackCodec(trackEntry2);\n    if (!codec) {\n      throw new Error(\"Expected codec\");\n    }\n    const trackTimescale = getTrackTimestampScale(trackEntry2);\n    trackEntries[trackId] = {\n      codec: codec.value,\n      trackTimescale: trackTimescale?.value ?? null\n    };\n  };\n  let timestampMap = new Map;\n  const getTimestampOffsetForByteOffset = (byteOffset) => {\n    const entries = Array.from(timestampMap.entries());\n    const sortedByByteOffset = entries.sort((a, b) => {\n      return a[0] - b[0];\n    }).reverse();\n    for (const [offset, timestamp] of sortedByByteOffset) {\n      if (offset >= byteOffset) {\n        continue;\n      }\n      return timestamp;\n    }\n    return timestampMap.get(byteOffset);\n  };\n  const setTimestampOffset = (byteOffset, timestamp) => {\n    timestampMap.set(byteOffset, timestamp);\n  };\n  let timescale = null;\n  const setTimescale = (newTimescale) => {\n    timescale = newTimescale;\n  };\n  const getTimescale = () => {\n    if (timescale === null) {\n      return 1e6;\n    }\n    return timescale;\n  };\n  const segments = [];\n  const clusters = [];\n  const avcProfilesMap = {};\n  const setAvcProfileForTrackNumber = (trackNumber2, avcProfile) => {\n    avcProfilesMap[trackNumber2] = avcProfile;\n  };\n  const getAvcProfileForTrackNumber = (trackNumber2) => {\n    return avcProfilesMap[trackNumber2] ?? null;\n  };\n  const cues = lazyCuesFetch({\n    controller,\n    logLevel,\n    readerInterface,\n    src,\n    prefetchCache\n  });\n  const getTimeStampMapForSeekingHints = () => {\n    return timestampMap;\n  };\n  const setTimeStampMapForSeekingHints = (newTimestampMap) => {\n    timestampMap = newTimestampMap;\n  };\n  return {\n    cues,\n    onTrackEntrySegment,\n    getTrackInfoByNumber: (id) => trackEntries[id],\n    setTimestampOffset,\n    getTimestampOffsetForByteOffset,\n    getTimeStampMapForSeekingHints,\n    setTimeStampMapForSeekingHints,\n    getTimescale,\n    setTimescale,\n    addSegment: (seg) => {\n      const segment = {\n        ...seg,\n        index: segments.length\n      };\n      segments.push(segment);\n    },\n    addCluster: (cluster) => {\n      const exists = clusters.some((existingCluster) => existingCluster.start === cluster.start);\n      if (!exists) {\n        clusters.push(cluster);\n      }\n    },\n    getFirstCluster: () => {\n      return clusters.find((cluster) => cluster.segment === 0);\n    },\n    isInsideSegment: (iterator) => {\n      const offset = iterator.counter.getOffset();\n      const insideClusters = segments.filter((cluster) => {\n        return offset >= cluster.start && offset <= cluster.start + cluster.size;\n      });\n      if (insideClusters.length > 1) {\n        throw new Error(\"Expected to only be inside 1 cluster\");\n      }\n      return insideClusters[0] ?? null;\n    },\n    isInsideCluster: (offset) => {\n      for (const cluster of clusters) {\n        if (offset >= cluster.start && offset < cluster.start + cluster.size) {\n          return cluster;\n        }\n      }\n      return null;\n    },\n    setAvcProfileForTrackNumber,\n    getAvcProfileForTrackNumber\n  };\n};\n\n// src/state/mp3.ts\nvar makeMp3State = () => {\n  let mp3Info = null;\n  let bitrateInfo = null;\n  const audioSamples = audioSampleMapState();\n  return {\n    getMp3Info: () => mp3Info,\n    setMp3Info: (info) => {\n      mp3Info = info;\n    },\n    getMp3BitrateInfo: () => bitrateInfo,\n    setMp3BitrateInfo: (info) => {\n      bitrateInfo = info;\n    },\n    audioSamples\n  };\n};\n\n// src/containers/riff/seek/fetch-idx1.ts\nvar fetchIdx1 = async ({\n  src,\n  readerInterface,\n  controller,\n  position,\n  logLevel,\n  prefetchCache,\n  contentLength\n}) => {\n  Log.verbose(logLevel, \"Making request to fetch idx1 from \", src, \"position\", position);\n  const result = await readerInterface.read({\n    controller,\n    range: position,\n    src,\n    logLevel,\n    prefetchCache\n  });\n  if (result.contentLength === null) {\n    throw new Error(\"Content length is null\");\n  }\n  const iterator = getArrayBufferIterator({\n    initialData: new Uint8Array,\n    maxBytes: contentLength - position + 1,\n    logLevel: \"error\"\n  });\n  while (true) {\n    const res = await result.reader.reader.read();\n    if (res.value) {\n      iterator.addData(res.value);\n    }\n    if (res.done) {\n      break;\n    }\n  }\n  const box = await expectRiffBox({\n    iterator,\n    stateIfExpectingSideEffects: null\n  });\n  iterator.destroy();\n  if (box === null || box.type !== \"idx1-box\") {\n    throw new Error(\"Expected idx1-box\");\n  }\n  return {\n    entries: box.entries.filter((entry) => entry.id.endsWith(\"dc\")),\n    videoTrackIndex: box.videoTrackIndex\n  };\n};\n\n// src/state/riff/lazy-idx1-fetch.ts\nvar lazyIdx1Fetch = ({\n  controller,\n  logLevel,\n  readerInterface,\n  src,\n  prefetchCache,\n  contentLength\n}) => {\n  let prom = null;\n  let result = null;\n  const triggerLoad = (position) => {\n    if (result) {\n      return Promise.resolve(result);\n    }\n    if (prom) {\n      return prom;\n    }\n    prom = fetchIdx1({\n      controller,\n      logLevel,\n      position,\n      readerInterface,\n      src,\n      prefetchCache,\n      contentLength\n    }).then((entries) => {\n      prom = null;\n      result = entries;\n      return entries;\n    });\n    return prom;\n  };\n  const getLoadedIdx1 = async () => {\n    if (!prom) {\n      return null;\n    }\n    const entries = await prom;\n    return entries;\n  };\n  const getIfAlreadyLoaded = () => {\n    if (result) {\n      return result;\n    }\n    return null;\n  };\n  const setFromSeekingHints = (hints) => {\n    if (hints.idx1Entries) {\n      result = hints.idx1Entries;\n    }\n  };\n  const waitForLoaded = () => {\n    if (result) {\n      return Promise.resolve(result);\n    }\n    if (prom) {\n      return prom;\n    }\n    return Promise.resolve(null);\n  };\n  return {\n    triggerLoad,\n    getLoadedIdx1,\n    getIfAlreadyLoaded,\n    setFromSeekingHints,\n    waitForLoaded\n  };\n};\n\n// src/state/riff/queued-frames.ts\nvar queuedBFramesState = () => {\n  const queuedFrames = [];\n  const releasedFrames = [];\n  const flush = () => {\n    releasedFrames.push(...queuedFrames);\n    queuedFrames.length = 0;\n  };\n  return {\n    addFrame: ({\n      frame,\n      maxFramesInBuffer,\n      trackId,\n      timescale\n    }) => {\n      if (frame.type === \"key\") {\n        flush();\n        releasedFrames.push({ sample: frame, trackId, timescale });\n        return;\n      }\n      queuedFrames.push({ sample: frame, trackId, timescale });\n      if (queuedFrames.length > maxFramesInBuffer) {\n        releasedFrames.push(queuedFrames.shift());\n      }\n    },\n    flush,\n    getReleasedFrame: () => {\n      if (releasedFrames.length === 0) {\n        return null;\n      }\n      return releasedFrames.shift();\n    },\n    hasReleasedFrames: () => {\n      return releasedFrames.length > 0;\n    },\n    clear: () => {\n      releasedFrames.length = 0;\n      queuedFrames.length = 0;\n    }\n  };\n};\n\n// src/state/riff/riff-keyframes.ts\nvar riffKeyframesState = () => {\n  const keyframes = [];\n  const addKeyframe = (keyframe) => {\n    if (keyframes.find((k) => k.positionInBytes === keyframe.positionInBytes)) {\n      return;\n    }\n    keyframes.push(keyframe);\n    keyframes.sort((a, b) => a.positionInBytes - b.positionInBytes);\n  };\n  const getKeyframes2 = () => {\n    return keyframes;\n  };\n  const setFromSeekingHints = (keyframesFromHints) => {\n    for (const keyframe of keyframesFromHints) {\n      addKeyframe(keyframe);\n    }\n  };\n  return {\n    addKeyframe,\n    getKeyframes: getKeyframes2,\n    setFromSeekingHints\n  };\n};\n\n// src/state/riff/sample-counter.ts\nvar riffSampleCounter = () => {\n  const samplesForTrack = {};\n  const pocsAtKeyframeOffset = {};\n  const riffKeys = riffKeyframesState();\n  const onAudioSample = (trackId, audioSample) => {\n    if (typeof samplesForTrack[trackId] === \"undefined\") {\n      samplesForTrack[trackId] = 0;\n    }\n    if (audioSample.data.length > 0) {\n      samplesForTrack[trackId]++;\n    }\n    samplesForTrack[trackId]++;\n  };\n  const onVideoSample = ({\n    trackId,\n    videoSample\n  }) => {\n    if (typeof samplesForTrack[trackId] === \"undefined\") {\n      samplesForTrack[trackId] = 0;\n    }\n    if (videoSample.type === \"key\") {\n      riffKeys.addKeyframe({\n        trackId,\n        decodingTimeInSeconds: videoSample.decodingTimestamp / WEBCODECS_TIMESCALE,\n        positionInBytes: videoSample.offset,\n        presentationTimeInSeconds: videoSample.timestamp / WEBCODECS_TIMESCALE,\n        sizeInBytes: videoSample.data.length,\n        sampleCounts: { ...samplesForTrack }\n      });\n    }\n    if (videoSample.data.length > 0) {\n      samplesForTrack[trackId]++;\n    }\n  };\n  const getSampleCountForTrack = ({ trackId }) => {\n    return samplesForTrack[trackId] ?? 0;\n  };\n  const setSamplesFromSeek = (samples) => {\n    for (const trackId in samples) {\n      samplesForTrack[trackId] = samples[trackId];\n    }\n  };\n  const setPocAtKeyframeOffset = ({\n    keyframeOffset,\n    poc\n  }) => {\n    if (typeof pocsAtKeyframeOffset[keyframeOffset] === \"undefined\") {\n      pocsAtKeyframeOffset[keyframeOffset] = [];\n    }\n    if (pocsAtKeyframeOffset[keyframeOffset].includes(poc)) {\n      return;\n    }\n    pocsAtKeyframeOffset[keyframeOffset].push(poc);\n    pocsAtKeyframeOffset[keyframeOffset].sort((a, b) => a - b);\n  };\n  const getPocAtKeyframeOffset = ({\n    keyframeOffset\n  }) => {\n    return pocsAtKeyframeOffset[keyframeOffset];\n  };\n  const getKeyframeAtOffset = (sample) => {\n    if (sample.type === \"key\") {\n      return sample.offset;\n    }\n    return riffKeys.getKeyframes().findLast((k) => k.positionInBytes <= sample.offset)?.positionInBytes ?? null;\n  };\n  return {\n    onAudioSample,\n    onVideoSample,\n    getSampleCountForTrack,\n    setSamplesFromSeek,\n    riffKeys,\n    setPocAtKeyframeOffset,\n    getPocAtKeyframeOffset,\n    getKeyframeAtOffset\n  };\n};\n\n// src/state/riff.ts\nvar riffSpecificState = ({\n  controller,\n  logLevel,\n  readerInterface,\n  src,\n  prefetchCache,\n  contentLength\n}) => {\n  let avcProfile = null;\n  let nextTrackIndex = 0;\n  const profileCallbacks = [];\n  const registerOnAvcProfileCallback = (callback) => {\n    profileCallbacks.push(callback);\n  };\n  const onProfile = async (profile) => {\n    avcProfile = profile;\n    for (const callback of profileCallbacks) {\n      await callback(profile);\n    }\n    profileCallbacks.length = 0;\n  };\n  const lazyIdx1 = lazyIdx1Fetch({\n    controller,\n    logLevel,\n    readerInterface,\n    src,\n    prefetchCache,\n    contentLength\n  });\n  const sampleCounter = riffSampleCounter();\n  const queuedBFrames = queuedBFramesState();\n  return {\n    getAvcProfile: () => {\n      return avcProfile;\n    },\n    onProfile,\n    registerOnAvcProfileCallback,\n    getNextTrackIndex: () => {\n      return nextTrackIndex;\n    },\n    queuedBFrames,\n    incrementNextTrackIndex: () => {\n      nextTrackIndex++;\n    },\n    lazyIdx1,\n    sampleCounter\n  };\n};\n\n// src/state/sample-callbacks.ts\nvar callbacksState = ({\n  controller,\n  hasAudioTrackHandlers,\n  hasVideoTrackHandlers,\n  fields,\n  keyframes,\n  emittedFields,\n  samplesObserved,\n  structure,\n  src,\n  seekSignal,\n  logLevel\n}) => {\n  const videoSampleCallbacks = {};\n  const audioSampleCallbacks = {};\n  const onTrackDoneCallback = {};\n  const queuedAudioSamples = {};\n  const queuedVideoSamples = {};\n  const canSkipTracksState = makeCanSkipTracksState({\n    hasAudioTrackHandlers,\n    fields,\n    hasVideoTrackHandlers,\n    structure\n  });\n  const tracksState = makeTracksSectionState(canSkipTracksState, src);\n  return {\n    registerVideoSampleCallback: async (id, callback) => {\n      if (callback === null) {\n        delete videoSampleCallbacks[id];\n        return;\n      }\n      videoSampleCallbacks[id] = callback;\n      for (const queued of queuedVideoSamples[id] ?? []) {\n        await callback(queued);\n      }\n      queuedVideoSamples[id] = [];\n    },\n    onAudioSample: async ({\n      audioSample,\n      trackId\n    }) => {\n      if (controller._internals.signal.aborted) {\n        throw new Error(\"Aborted\");\n      }\n      const callback = audioSampleCallbacks[trackId];\n      if (audioSample.data.length > 0) {\n        if (callback) {\n          if (seekSignal.getSeek() !== null) {\n            Log.trace(logLevel, \"Not emitting sample because seek is processing\");\n          } else {\n            const trackDoneCallback = await callback(audioSample);\n            onTrackDoneCallback[trackId] = trackDoneCallback ?? null;\n          }\n        }\n      }\n      if (needsToIterateOverSamples({ emittedFields, fields })) {\n        samplesObserved.addAudioSample(audioSample);\n      }\n    },\n    onVideoSample: async ({\n      trackId,\n      videoSample\n    }) => {\n      if (controller._internals.signal.aborted) {\n        throw new Error(\"Aborted\");\n      }\n      if (videoSample.data.length > 0) {\n        const callback = videoSampleCallbacks[trackId];\n        if (callback) {\n          if (seekSignal.getSeek() !== null) {\n            Log.trace(logLevel, \"Not emitting sample because seek is processing\");\n          } else {\n            const trackDoneCallback = await callback(videoSample);\n            onTrackDoneCallback[trackId] = trackDoneCallback ?? null;\n          }\n        }\n      }\n      if (videoSample.type === \"key\") {\n        keyframes.addKeyframe({\n          trackId,\n          decodingTimeInSeconds: videoSample.decodingTimestamp / WEBCODECS_TIMESCALE,\n          positionInBytes: videoSample.offset,\n          presentationTimeInSeconds: videoSample.timestamp / WEBCODECS_TIMESCALE,\n          sizeInBytes: videoSample.data.length\n        });\n      }\n      if (needsToIterateOverSamples({\n        fields,\n        emittedFields\n      })) {\n        samplesObserved.addVideoSample(videoSample);\n      }\n    },\n    canSkipTracksState,\n    registerAudioSampleCallback: async (id, callback) => {\n      if (callback === null) {\n        delete audioSampleCallbacks[id];\n        return;\n      }\n      audioSampleCallbacks[id] = callback;\n      for (const queued of queuedAudioSamples[id] ?? []) {\n        await callback(queued);\n      }\n      queuedAudioSamples[id] = [];\n    },\n    tracks: tracksState,\n    audioSampleCallbacks,\n    videoSampleCallbacks,\n    hasAudioTrackHandlers,\n    hasVideoTrackHandlers,\n    callTracksDoneCallback: async () => {\n      for (const callback of Object.values(onTrackDoneCallback)) {\n        if (callback) {\n          await callback();\n        }\n      }\n    }\n  };\n};\n\n// src/state/samples-observed/slow-duration-fps.ts\nvar samplesObservedState = () => {\n  let smallestVideoSample;\n  let largestVideoSample;\n  let smallestAudioSample;\n  let largestAudioSample;\n  let lastSampleObserved = false;\n  const videoSamples = new Map;\n  const audioSamples = new Map;\n  const getSlowVideoDurationInSeconds = () => {\n    return (largestVideoSample ?? 0) - (smallestVideoSample ?? 0);\n  };\n  const getSlowAudioDurationInSeconds = () => {\n    return (largestAudioSample ?? 0) - (smallestAudioSample ?? 0);\n  };\n  const getSlowDurationInSeconds = () => {\n    const smallestSample = Math.min(smallestAudioSample ?? Infinity, smallestVideoSample ?? Infinity);\n    const largestSample = Math.max(largestAudioSample ?? 0, largestVideoSample ?? 0);\n    if (smallestSample === Infinity || largestSample === Infinity) {\n      return 0;\n    }\n    return largestSample - smallestSample;\n  };\n  const addVideoSample = (videoSample) => {\n    videoSamples.set(videoSample.timestamp, videoSample.data.byteLength);\n    const presentationTimeInSeconds = videoSample.timestamp / WEBCODECS_TIMESCALE;\n    const duration2 = (videoSample.duration ?? 0) / WEBCODECS_TIMESCALE;\n    if (largestVideoSample === undefined || presentationTimeInSeconds > largestVideoSample) {\n      largestVideoSample = presentationTimeInSeconds + duration2;\n    }\n    if (smallestVideoSample === undefined || presentationTimeInSeconds < smallestVideoSample) {\n      smallestVideoSample = presentationTimeInSeconds;\n    }\n  };\n  const addAudioSample = (audioSample) => {\n    audioSamples.set(audioSample.timestamp, audioSample.data.byteLength);\n    const presentationTimeInSeconds = audioSample.timestamp / WEBCODECS_TIMESCALE;\n    const duration2 = (audioSample.duration ?? 0) / WEBCODECS_TIMESCALE;\n    if (largestAudioSample === undefined || presentationTimeInSeconds > largestAudioSample) {\n      largestAudioSample = presentationTimeInSeconds + duration2;\n    }\n    if (smallestAudioSample === undefined || presentationTimeInSeconds < smallestAudioSample) {\n      smallestAudioSample = presentationTimeInSeconds;\n    }\n  };\n  const getFps2 = () => {\n    const videoDuration = (largestVideoSample ?? 0) - (smallestVideoSample ?? 0);\n    if (videoDuration === 0) {\n      return 0;\n    }\n    return (videoSamples.size - 1) / videoDuration;\n  };\n  const getSlowNumberOfFrames = () => videoSamples.size;\n  const getAudioBitrate = () => {\n    const audioDuration = getSlowAudioDurationInSeconds();\n    if (audioDuration === 0 || audioSamples.size === 0) {\n      return null;\n    }\n    const audioSizesInBytes = Array.from(audioSamples.values()).reduce((acc, size) => acc + size, 0);\n    return audioSizesInBytes * 8 / audioDuration;\n  };\n  const getVideoBitrate = () => {\n    const videoDuration = getSlowVideoDurationInSeconds();\n    if (videoDuration === 0 || videoSamples.size === 0) {\n      return null;\n    }\n    const videoSizesInBytes = Array.from(videoSamples.values()).reduce((acc, size) => acc + size, 0);\n    return videoSizesInBytes * 8 / videoDuration;\n  };\n  const getLastSampleObserved = () => lastSampleObserved;\n  const setLastSampleObserved = () => {\n    lastSampleObserved = true;\n  };\n  return {\n    addVideoSample,\n    addAudioSample,\n    getSlowDurationInSeconds,\n    getFps: getFps2,\n    getSlowNumberOfFrames,\n    getAudioBitrate,\n    getVideoBitrate,\n    getLastSampleObserved,\n    setLastSampleObserved,\n    getAmountOfSamplesObserved: () => videoSamples.size + audioSamples.size\n  };\n};\n\n// src/state/seek-infinite-loop.ts\nvar seekInfiniteLoopDetectionState = () => {\n  let lastSeek = null;\n  let firstSeekTime = null;\n  return {\n    registerSeek: (byte) => {\n      const now = Date.now();\n      if (!lastSeek || lastSeek.byte !== byte) {\n        lastSeek = { byte, numberOfTimes: 1 };\n        firstSeekTime = now;\n        return;\n      }\n      lastSeek.numberOfTimes++;\n      if (lastSeek.numberOfTimes >= 10 && firstSeekTime && now - firstSeekTime <= 2000) {\n        throw new Error(`Seeking infinite loop detected: Seeked to byte 0x${byte.toString(16)} ${lastSeek.numberOfTimes} times in a row in the last 2 seconds. Check your usage of .seek().`);\n      }\n      if (now - firstSeekTime > 2000) {\n        lastSeek = { byte, numberOfTimes: 1 };\n        firstSeekTime = now;\n      }\n    },\n    reset: () => {\n      lastSeek = null;\n      firstSeekTime = null;\n    }\n  };\n};\n\n// src/state/timings.ts\nvar timingsState = () => {\n  return {\n    timeIterating: 0,\n    timeReadingData: 0,\n    timeSeeking: 0,\n    timeCheckingIfDone: 0,\n    timeFreeingData: 0\n  };\n};\n\n// src/state/transport-stream/last-emitted-sample.ts\nvar lastEmittedSampleState = () => {\n  let lastEmittedSample = null;\n  return {\n    setLastEmittedSample: (sample) => {\n      lastEmittedSample = sample;\n    },\n    getLastEmittedSample: () => lastEmittedSample,\n    resetLastEmittedSample: () => {\n      lastEmittedSample = null;\n    }\n  };\n};\n\n// src/state/transport-stream/next-pes-header-store.ts\nvar makeNextPesHeaderStore = () => {\n  let nextPesHeader = null;\n  return {\n    setNextPesHeader: (pesHeader) => {\n      nextPesHeader = pesHeader;\n    },\n    getNextPesHeader: () => {\n      if (!nextPesHeader) {\n        throw new Error(\"No next PES header found\");\n      }\n      return nextPesHeader;\n    }\n  };\n};\n\n// src/state/transport-stream/pts-start-offset.ts\nvar ptsStartOffsetStore = () => {\n  const offsets = {};\n  return {\n    getOffset: (trackId) => offsets[trackId] || 0,\n    setOffset: ({ newOffset, trackId }) => {\n      offsets[trackId] = newOffset;\n    }\n  };\n};\n\n// src/state/transport-stream/transport-stream.ts\nvar transportStreamState = () => {\n  const streamBuffers = new Map;\n  const startOffset = ptsStartOffsetStore();\n  const lastEmittedSample = lastEmittedSampleState();\n  const state = {\n    nextPesHeaderStore: makeNextPesHeaderStore(),\n    observedPesHeaders: makeObservedPesHeader(),\n    streamBuffers,\n    startOffset,\n    resetBeforeSeek: () => {\n      state.streamBuffers.clear();\n      state.nextPesHeaderStore = makeNextPesHeaderStore();\n    },\n    lastEmittedSample\n  };\n  return state;\n};\n\n// src/state/parser-state.ts\nvar makeParserState = ({\n  hasAudioTrackHandlers,\n  hasVideoTrackHandlers,\n  controller,\n  onAudioTrack,\n  onVideoTrack,\n  contentLength,\n  logLevel,\n  mode,\n  src,\n  readerInterface,\n  onDiscardedData,\n  selectM3uStreamFn,\n  selectM3uAssociatedPlaylistsFn,\n  m3uPlaylistContext,\n  contentType,\n  name,\n  callbacks,\n  fieldsInReturnValue,\n  mimeType,\n  initialReaderInstance,\n  makeSamplesStartAtZero,\n  prefetchCache\n}) => {\n  let skippedBytes = 0;\n  const returnValue = {};\n  const iterator = getArrayBufferIterator({\n    initialData: new Uint8Array([]),\n    maxBytes: contentLength,\n    logLevel\n  });\n  const increaseSkippedBytes = (bytes) => {\n    skippedBytes += bytes;\n  };\n  const structure = structureState();\n  const keyframes = keyframesState();\n  const emittedFields = emittedState();\n  const samplesObserved = samplesObservedState();\n  const mp3 = makeMp3State();\n  const images = imagesState();\n  const timings = timingsState();\n  const seekInfiniteLoop = seekInfiniteLoopDetectionState();\n  const currentReaderState = currentReader(initialReaderInstance);\n  const avc = avcState();\n  const errored = null;\n  const discardReadBytes = async (force) => {\n    const { bytesRemoved, removedData } = iterator.removeBytesRead(force, mode);\n    if (bytesRemoved) {\n      Log.verbose(logLevel, `Freed ${bytesRemoved} bytes`);\n    }\n    if (removedData && onDiscardedData) {\n      await onDiscardedData(removedData);\n    }\n  };\n  const fields = getFieldsFromCallback({\n    fields: fieldsInReturnValue,\n    callbacks\n  });\n  const mediaSection = mediaSectionState();\n  return {\n    riff: riffSpecificState({\n      controller,\n      logLevel,\n      readerInterface,\n      src,\n      prefetchCache,\n      contentLength\n    }),\n    transportStream: transportStreamState(),\n    webm: webmState({\n      controller,\n      logLevel,\n      readerInterface,\n      src,\n      prefetchCache\n    }),\n    iso: isoBaseMediaState({\n      contentLength,\n      controller,\n      readerInterface,\n      src,\n      logLevel,\n      prefetchCache\n    }),\n    mp3,\n    aac: aacState(),\n    flac: flacState(),\n    m3u: m3uState(logLevel),\n    timings,\n    callbacks: callbacksState({\n      controller,\n      hasAudioTrackHandlers,\n      hasVideoTrackHandlers,\n      fields,\n      keyframes,\n      emittedFields,\n      samplesObserved,\n      structure,\n      src,\n      seekSignal: controller._internals.seekSignal,\n      logLevel\n    }),\n    getInternalStats: () => ({\n      skippedBytes,\n      finalCursorOffset: iterator.counter.getOffset() ?? 0\n    }),\n    getSkipBytes: () => skippedBytes,\n    increaseSkippedBytes,\n    keyframes,\n    structure,\n    onAudioTrack,\n    onVideoTrack,\n    emittedFields,\n    fields,\n    samplesObserved,\n    contentLength,\n    images,\n    mediaSection,\n    logLevel,\n    iterator,\n    controller,\n    mode,\n    src,\n    readerInterface,\n    discardReadBytes,\n    selectM3uStreamFn,\n    selectM3uAssociatedPlaylistsFn,\n    m3uPlaylistContext,\n    contentType,\n    name,\n    returnValue,\n    callbackFunctions: callbacks,\n    fieldsInReturnValue,\n    mimeType,\n    errored,\n    currentReader: currentReaderState,\n    seekInfiniteLoop,\n    makeSamplesStartAtZero,\n    prefetchCache,\n    avc\n  };\n};\n\n// src/throttled-progress.ts\nvar throttledStateUpdate = ({\n  updateFn,\n  everyMilliseconds,\n  controller\n}) => {\n  let currentState = {\n    bytes: 0,\n    percentage: null,\n    totalBytes: null\n  };\n  if (!updateFn) {\n    return {\n      get: () => currentState,\n      update: null,\n      stopAndGetLastProgress: () => {}\n    };\n  }\n  let lastUpdated = null;\n  const callUpdateIfChanged = () => {\n    if (currentState === lastUpdated) {\n      return;\n    }\n    updateFn(currentState);\n    lastUpdated = currentState;\n  };\n  let cleanup = () => {};\n  if (everyMilliseconds > 0) {\n    const interval = setInterval(() => {\n      callUpdateIfChanged();\n    }, everyMilliseconds);\n    const onAbort = () => {\n      clearInterval(interval);\n    };\n    controller._internals.signal.addEventListener(\"abort\", onAbort, {\n      once: true\n    });\n    cleanup = () => {\n      clearInterval(interval);\n      controller._internals.signal.removeEventListener(\"abort\", onAbort);\n    };\n  }\n  return {\n    get: () => currentState,\n    update: (fn) => {\n      currentState = fn(currentState);\n      if (everyMilliseconds === 0) {\n        callUpdateIfChanged();\n      }\n    },\n    stopAndGetLastProgress: () => {\n      cleanup();\n      return currentState;\n    }\n  };\n};\n\n// src/internal-parse-media.ts\nvar internalParseMedia = async function({\n  src,\n  fields: _fieldsInReturnValue,\n  reader: readerInterface,\n  onAudioTrack,\n  onVideoTrack,\n  controller = mediaParserController(),\n  logLevel,\n  onParseProgress: onParseProgressDoNotCallDirectly,\n  progressIntervalInMs,\n  mode,\n  onDiscardedData,\n  onError,\n  acknowledgeRemotionLicense,\n  apiName,\n  selectM3uStream: selectM3uStreamFn,\n  selectM3uAssociatedPlaylists: selectM3uAssociatedPlaylistsFn,\n  m3uPlaylistContext,\n  makeSamplesStartAtZero,\n  seekingHints,\n  ...more\n}) {\n  if (!src) {\n    throw new Error('No \"src\" provided');\n  }\n  controller._internals.markAsReadyToEmitEvents();\n  warnIfRemotionLicenseNotAcknowledged({\n    acknowledgeRemotionLicense,\n    logLevel,\n    apiName\n  });\n  Log.verbose(logLevel, `Reading ${typeof src === \"string\" ? src : src instanceof URL ? src.toString() : src instanceof File ? src.name : src.toString()}`);\n  const prefetchCache = new Map;\n  const {\n    reader: readerInstance,\n    contentLength,\n    name,\n    contentType,\n    supportsContentRange,\n    needsContentRange\n  } = await readerInterface.read({\n    src,\n    range: null,\n    controller,\n    logLevel,\n    prefetchCache\n  });\n  if (contentLength === null) {\n    throw new Error(`Cannot read media ${src} without a content length. This is currently not supported. Ensure the media has a \"Content-Length\" HTTP header.`);\n  }\n  if (!supportsContentRange && needsContentRange) {\n    throw new Error('Cannot read media without it supporting the \"Content-Range\" header. This is currently not supported. Ensure the media supports the \"Content-Range\" HTTP header.');\n  }\n  const hasAudioTrackHandlers = Boolean(onAudioTrack);\n  const hasVideoTrackHandlers = Boolean(onVideoTrack);\n  const state = makeParserState({\n    hasAudioTrackHandlers,\n    hasVideoTrackHandlers,\n    controller,\n    onAudioTrack: onAudioTrack ?? null,\n    onVideoTrack: onVideoTrack ?? null,\n    contentLength,\n    logLevel,\n    mode,\n    readerInterface,\n    src,\n    onDiscardedData,\n    selectM3uStreamFn,\n    selectM3uAssociatedPlaylistsFn,\n    m3uPlaylistContext,\n    contentType,\n    name,\n    callbacks: more,\n    fieldsInReturnValue: _fieldsInReturnValue ?? {},\n    mimeType: contentType,\n    initialReaderInstance: readerInstance,\n    makeSamplesStartAtZero,\n    prefetchCache\n  });\n  if (seekingHints) {\n    setSeekingHints({ hints: seekingHints, state });\n  }\n  controller._internals.attachSeekingHintResolution(() => Promise.resolve(getSeekingHints({\n    tracksState: state.callbacks.tracks,\n    keyframesState: state.keyframes,\n    webmState: state.webm,\n    structureState: state.structure,\n    m3uPlaylistContext: state.m3uPlaylistContext,\n    mediaSectionState: state.mediaSection,\n    isoState: state.iso,\n    transportStream: state.transportStream,\n    flacState: state.flac,\n    samplesObserved: state.samplesObserved,\n    riffState: state.riff,\n    mp3State: state.mp3,\n    contentLength: state.contentLength,\n    aacState: state.aac\n  })));\n  controller._internals.attachSimulateSeekResolution((seek2) => {\n    const {\n      aacState: aacState2,\n      avcState: avcState2,\n      flacState: flacState2,\n      isoState,\n      iterator,\n      keyframes,\n      m3uState: m3uState2,\n      mediaSection,\n      mp3State,\n      riffState,\n      samplesObserved,\n      structureState: structureState2,\n      tracksState,\n      transportStream,\n      webmState: webmState2\n    } = getWorkOnSeekRequestOptions(state);\n    return turnSeekIntoByte({\n      aacState: aacState2,\n      seek: seek2,\n      avcState: avcState2,\n      contentLength,\n      flacState: flacState2,\n      isoState,\n      iterator,\n      keyframes,\n      logLevel,\n      m3uPlaylistContext,\n      m3uState: m3uState2,\n      mediaSectionState: mediaSection,\n      mp3State,\n      riffState,\n      samplesObserved,\n      structureState: structureState2,\n      tracksState,\n      transportStream,\n      webmState: webmState2\n    });\n  });\n  if (!hasAudioTrackHandlers && !hasVideoTrackHandlers && Object.values(state.fields).every((v) => !v) && mode === \"query\") {\n    Log.warn(logLevel, new Error(\"Warning - No `fields` and no `on*` callbacks were passed to `parseMedia()`. Specify the data you would like to retrieve.\"));\n  }\n  const throttledState = throttledStateUpdate({\n    updateFn: onParseProgressDoNotCallDirectly ?? null,\n    everyMilliseconds: progressIntervalInMs ?? 100,\n    controller,\n    totalBytes: contentLength\n  });\n  await triggerInfoEmit(state);\n  await parseLoop({ state, throttledState, onError });\n  Log.verbose(logLevel, \"Finished parsing file\");\n  await emitAllInfo(state);\n  printTimings(state);\n  state.currentReader.getCurrent().abort();\n  state.iterator?.destroy();\n  state.callbacks.tracks.ensureHasTracksAtEnd(state.fields);\n  state.m3u.abortM3UStreamRuns();\n  prefetchCache.clear();\n  if (state.errored) {\n    throw state.errored;\n  }\n  if (state.controller._internals.seekSignal.getSeek() !== null) {\n    throw new Error(\"Should not finish while a seek is pending\");\n  }\n  return state.returnValue;\n};\n\n// src/worker/forward-controller-to-worker.ts\nvar forwardMediaParserControllerToWorker = (controller) => {\n  return (message) => {\n    if (message.type === \"request-pause\") {\n      controller.pause();\n      return;\n    }\n    if (message.type === \"request-seek\") {\n      controller.seek(message.payload);\n      return;\n    }\n    if (message.type === \"request-get-seeking-hints\") {\n      controller.getSeekingHints().then((hints) => {\n        postMessage({\n          type: \"response-get-seeking-hints\",\n          payload: hints\n        });\n      }).catch((error) => {\n        postMessage({\n          type: \"response-error\",\n          payload: error\n        });\n      });\n      return;\n    }\n    if (message.type === \"request-simulate-seek\") {\n      controller.simulateSeek(message.payload).then((resolution) => {\n        postMessage({\n          type: \"response-simulate-seek\",\n          nonce: message.nonce,\n          payload: resolution\n        });\n      }).catch((err) => {\n        postMessage({\n          type: \"response-error\",\n          payload: err\n        });\n      });\n      return;\n    }\n    if (message.type === \"request-resume\") {\n      controller.resume();\n      return;\n    }\n    if (message.type === \"request-abort\") {\n      controller.abort();\n      return;\n    }\n    const msg = `Unknown message type: ${message.type}`;\n    Log.error(msg);\n    throw new Error(msg);\n  };\n};\n\n// src/worker/serialize-error.ts\nvar serializeError = ({\n  error,\n  logLevel,\n  seekingHints\n}) => {\n  if (error instanceof IsAnImageError) {\n    return {\n      type: \"response-error\",\n      errorName: \"IsAnImageError\",\n      dimensions: error.dimensions,\n      errorMessage: error.message,\n      errorStack: error.stack ?? \"\",\n      fileName: error.fileName,\n      imageType: error.imageType,\n      mimeType: error.mimeType,\n      sizeInBytes: error.sizeInBytes\n    };\n  }\n  if (error instanceof IsAPdfError) {\n    return {\n      type: \"response-error\",\n      errorName: \"IsAPdfError\",\n      errorMessage: error.message,\n      errorStack: error.stack ?? \"\",\n      mimeType: error.mimeType,\n      sizeInBytes: error.sizeInBytes,\n      fileName: error.fileName\n    };\n  }\n  if (error instanceof MediaParserAbortError) {\n    return {\n      type: \"response-error\",\n      errorName: \"MediaParserAbortError\",\n      errorMessage: error.message,\n      errorStack: error.stack ?? \"\",\n      seekingHints\n    };\n  }\n  if (error instanceof TypeError) {\n    return {\n      type: \"response-error\",\n      errorName: \"TypeError\",\n      errorMessage: error.message,\n      errorStack: error.stack ?? \"\"\n    };\n  }\n  if (error.name === \"AbortError\") {\n    return {\n      type: \"response-error\",\n      errorName: \"AbortError\",\n      errorMessage: error.message,\n      errorStack: error.stack ?? \"\"\n    };\n  }\n  if (error.name === \"NotReadableError\") {\n    return {\n      type: \"response-error\",\n      errorName: \"NotReadableError\",\n      errorMessage: error.message,\n      errorStack: error.stack ?? \"\"\n    };\n  }\n  if (error.name !== \"Error\") {\n    Log.warn(logLevel, `Original error was of type ${error.name} did not properly propagate`);\n  }\n  return {\n    type: \"response-error\",\n    errorName: \"Error\",\n    errorMessage: error.message,\n    errorStack: error.stack ?? \"\"\n  };\n};\n\n// src/worker-server.ts\nvar post = (message) => {\n  postMessage(message);\n};\nvar controller = mediaParserController();\nvar executeCallback = (payload) => {\n  const nonce = String(Math.random());\n  const { promise, resolve, reject } = withResolvers();\n  const cb = (msg) => {\n    const data = msg.data;\n    if (data.type === \"acknowledge-callback\" && data.nonce === nonce) {\n      const { nonce: _, ...pay } = data;\n      controller._internals.checkForAbortAndPause().then(() => {\n        resolve(pay);\n      }).catch((err) => {\n        reject(err);\n      });\n      removeEventListener(\"message\", cb);\n    }\n    if (data.type === \"signal-error-in-callback\") {\n      reject(new Error(\"Error in callback function\"));\n    }\n  };\n  addEventListener(\"message\", cb);\n  post({\n    type: \"response-on-callback-request\",\n    payload,\n    nonce\n  });\n  return promise;\n};\nvar startParsing = async (message, reader) => {\n  const { payload, src } = message;\n  const {\n    fields,\n    acknowledgeRemotionLicense,\n    logLevel: userLogLevel,\n    progressIntervalInMs,\n    m3uPlaylistContext,\n    seekingHints,\n    makeSamplesStartAtZero\n  } = payload;\n  const {\n    postAudioCodec,\n    postContainer,\n    postDimensions,\n    postFps,\n    postImages,\n    postInternalStats,\n    postIsHdr,\n    postKeyframes,\n    postLocation,\n    postM3uStreams,\n    postMetadata,\n    postMimeType,\n    postName,\n    postNumberOfAudioChannels,\n    postRotation,\n    postSampleRate,\n    postSlowAudioBitrate,\n    postSlowNumberOfFrames,\n    postSlowFps,\n    postSlowDurationInSeconds,\n    postSlowVideoBitrate,\n    postSlowStructure,\n    postTracks,\n    postUnrotatedDimensions,\n    postVideoCodec,\n    postSize,\n    postSlowKeyframes,\n    postDurationInSeconds,\n    postParseProgress,\n    postM3uStreamSelection,\n    postM3uAssociatedPlaylistsSelection,\n    postOnAudioTrack,\n    postOnVideoTrack\n  } = message;\n  const logLevel = userLogLevel ?? \"info\";\n  try {\n    const ret = await internalParseMedia({\n      src,\n      reader,\n      acknowledgeRemotionLicense: Boolean(acknowledgeRemotionLicense),\n      onError: () => ({ action: \"fail\" }),\n      logLevel,\n      fields: fields ?? null,\n      apiName: \"parseMediaInWorker()\",\n      controller,\n      mode: \"query\",\n      onAudioCodec: postAudioCodec ? async (codec) => {\n        await executeCallback({\n          callbackType: \"audio-codec\",\n          value: codec\n        });\n      } : null,\n      onContainer: postContainer ? async (container) => {\n        await executeCallback({\n          callbackType: \"container\",\n          value: container\n        });\n      } : null,\n      onDimensions: postDimensions ? async (dimensions) => {\n        await executeCallback({\n          callbackType: \"dimensions\",\n          value: dimensions\n        });\n      } : null,\n      onFps: postFps ? async (fps) => {\n        await executeCallback({\n          callbackType: \"fps\",\n          value: fps\n        });\n      } : null,\n      onImages: postImages ? async (images) => {\n        await executeCallback({\n          callbackType: \"images\",\n          value: images\n        });\n      } : null,\n      onInternalStats: postInternalStats ? async (internalStats) => {\n        await executeCallback({\n          callbackType: \"internal-stats\",\n          value: internalStats\n        });\n      } : null,\n      onIsHdr: postIsHdr ? async (isHdr) => {\n        await executeCallback({\n          callbackType: \"is-hdr\",\n          value: isHdr\n        });\n      } : null,\n      onKeyframes: postKeyframes ? async (keyframes) => {\n        await executeCallback({\n          callbackType: \"keyframes\",\n          value: keyframes\n        });\n      } : null,\n      onLocation: postLocation ? async (location) => {\n        await executeCallback({\n          callbackType: \"location\",\n          value: location\n        });\n      } : null,\n      onM3uStreams: postM3uStreams ? async (streams) => {\n        await executeCallback({\n          callbackType: \"m3u-streams\",\n          value: streams\n        });\n      } : null,\n      onMetadata: postMetadata ? async (metadata) => {\n        await executeCallback({\n          callbackType: \"metadata\",\n          value: metadata\n        });\n      } : null,\n      onMimeType: postMimeType ? async (mimeType) => {\n        await executeCallback({\n          callbackType: \"mime-type\",\n          value: mimeType\n        });\n      } : null,\n      onName: postName ? async (name) => {\n        await executeCallback({\n          callbackType: \"name\",\n          value: name\n        });\n      } : null,\n      onNumberOfAudioChannels: postNumberOfAudioChannels ? async (numberOfChannels) => {\n        await executeCallback({\n          callbackType: \"number-of-audio-channels\",\n          value: numberOfChannels\n        });\n      } : null,\n      onRotation: postRotation ? async (rotation) => {\n        await executeCallback({\n          callbackType: \"rotation\",\n          value: rotation\n        });\n      } : null,\n      onSampleRate: postSampleRate ? async (sampleRate) => {\n        await executeCallback({\n          callbackType: \"sample-rate\",\n          value: sampleRate\n        });\n      } : null,\n      onSize: postSize ? async (size) => {\n        await executeCallback({\n          callbackType: \"size\",\n          value: size\n        });\n      } : null,\n      onSlowAudioBitrate: postSlowAudioBitrate ? async (audioBitrate) => {\n        await executeCallback({\n          callbackType: \"slow-audio-bitrate\",\n          value: audioBitrate\n        });\n      } : null,\n      onSlowDurationInSeconds: postSlowDurationInSeconds ? async (durationInSeconds) => {\n        await executeCallback({\n          callbackType: \"slow-duration-in-seconds\",\n          value: durationInSeconds\n        });\n      } : null,\n      onSlowFps: postSlowFps ? async (fps) => {\n        await executeCallback({\n          callbackType: \"slow-fps\",\n          value: fps\n        });\n      } : null,\n      onSlowKeyframes: postSlowKeyframes ? async (keyframes) => {\n        await executeCallback({\n          callbackType: \"slow-keyframes\",\n          value: keyframes\n        });\n      } : null,\n      onSlowNumberOfFrames: postSlowNumberOfFrames ? async (numberOfFrames) => {\n        await executeCallback({\n          callbackType: \"slow-number-of-frames\",\n          value: numberOfFrames\n        });\n      } : null,\n      onSlowVideoBitrate: postSlowVideoBitrate ? async (videoBitrate) => {\n        await executeCallback({\n          callbackType: \"slow-video-bitrate\",\n          value: videoBitrate\n        });\n      } : null,\n      onSlowStructure: postSlowStructure ? async (structure) => {\n        await executeCallback({\n          callbackType: \"slow-structure\",\n          value: structure\n        });\n      } : null,\n      onTracks: postTracks ? async (tracks2) => {\n        await executeCallback({\n          callbackType: \"tracks\",\n          value: tracks2\n        });\n      } : null,\n      onUnrotatedDimensions: postUnrotatedDimensions ? async (dimensions) => {\n        await executeCallback({\n          callbackType: \"unrotated-dimensions\",\n          value: dimensions\n        });\n      } : null,\n      onVideoCodec: postVideoCodec ? async (codec) => {\n        await executeCallback({\n          callbackType: \"video-codec\",\n          value: codec\n        });\n      } : null,\n      onDurationInSeconds: postDurationInSeconds ? async (durationInSeconds) => {\n        await executeCallback({\n          callbackType: \"duration-in-seconds\",\n          value: durationInSeconds\n        });\n      } : null,\n      onParseProgress: postParseProgress ? async (progress) => {\n        await executeCallback({\n          callbackType: \"parse-progress\",\n          value: progress\n        });\n      } : null,\n      progressIntervalInMs: progressIntervalInMs ?? null,\n      selectM3uStream: postM3uStreamSelection ? async (streamIndex) => {\n        const res = await executeCallback({\n          callbackType: \"m3u-stream-selection\",\n          value: streamIndex\n        });\n        if (res.payloadType !== \"m3u-stream-selection\") {\n          throw new Error(\"Invalid response from callback\");\n        }\n        return res.value;\n      } : defaultSelectM3uStreamFn,\n      m3uPlaylistContext: m3uPlaylistContext ?? null,\n      selectM3uAssociatedPlaylists: postM3uAssociatedPlaylistsSelection ? async (playlists) => {\n        const res = await executeCallback({\n          callbackType: \"m3u-associated-playlists-selection\",\n          value: playlists\n        });\n        if (res.payloadType !== \"m3u-associated-playlists-selection\") {\n          throw new Error(\"Invalid response from callback\");\n        }\n        return res.value;\n      } : defaultSelectM3uAssociatedPlaylists,\n      onAudioTrack: postOnAudioTrack ? async (params) => {\n        const res = await executeCallback({\n          callbackType: \"on-audio-track\",\n          value: params\n        });\n        if (res.payloadType !== \"on-audio-track-response\") {\n          throw new Error(\"Invalid response from callback\");\n        }\n        if (!res.registeredCallback) {\n          return null;\n        }\n        return async (sample) => {\n          const audioSampleRes = await executeCallback({\n            callbackType: \"on-audio-sample\",\n            value: sample,\n            trackId: params.track.trackId\n          });\n          if (audioSampleRes.payloadType !== \"on-sample-response\") {\n            throw new Error(\"Invalid response from callback\");\n          }\n          if (!audioSampleRes.registeredTrackDoneCallback) {\n            return;\n          }\n          return async () => {\n            await executeCallback({\n              callbackType: \"track-done\",\n              trackId: params.track.trackId\n            });\n          };\n        };\n      } : null,\n      onVideoTrack: postOnVideoTrack ? async (params) => {\n        const res = await executeCallback({\n          callbackType: \"on-video-track\",\n          value: params\n        });\n        if (res.payloadType !== \"on-video-track-response\") {\n          throw new Error(\"Invalid response from callback\");\n        }\n        if (!res.registeredCallback) {\n          return null;\n        }\n        return async (sample) => {\n          const videoSampleRes = await executeCallback({\n            callbackType: \"on-video-sample\",\n            value: sample,\n            trackId: params.track.trackId\n          });\n          if (videoSampleRes.payloadType !== \"on-sample-response\") {\n            throw new Error(\"Invalid response from callback\");\n          }\n          if (!videoSampleRes.registeredTrackDoneCallback) {\n            return;\n          }\n          return async () => {\n            await executeCallback({\n              callbackType: \"track-done\",\n              trackId: params.track.trackId\n            });\n          };\n        };\n      } : null,\n      onDiscardedData: null,\n      makeSamplesStartAtZero: makeSamplesStartAtZero ?? true,\n      seekingHints: seekingHints ?? null\n    });\n    post({\n      type: \"response-done\",\n      payload: ret,\n      seekingHints: await controller.getSeekingHints()\n    });\n  } catch (e) {\n    let seekingHintsRes = null;\n    try {\n      seekingHintsRes = await controller.getSeekingHints();\n    } catch {}\n    post(serializeError({\n      error: e,\n      logLevel,\n      seekingHints: seekingHintsRes\n    }));\n  }\n};\nvar onMessageForWorker = forwardMediaParserControllerToWorker(controller);\nvar messageHandler = (message, readerInterface) => {\n  const data = message.data;\n  if (data.type === \"request-worker\") {\n    startParsing(data, readerInterface);\n    return;\n  }\n  if (data.type === \"acknowledge-callback\") {\n    return;\n  }\n  if (data.type === \"signal-error-in-callback\") {\n    return;\n  }\n  onMessageForWorker(data);\n};\n\n// src/worker-web-entry.ts\naddEventListener(\"message\", (message) => {\n  messageHandler(message, webReader);\n});\n"],"names":[],"sourceRoot":""}